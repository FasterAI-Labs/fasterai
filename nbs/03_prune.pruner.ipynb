{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5a33dc9c",
   "metadata": {},
   "source": [
    "---\n",
    "description: Remove useless filters to recreate a dense network\n",
    "output-file: pruner.html\n",
    "title: Pruner\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prune.pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from itertools import cycle\n",
    "from fastcore.basics import store_attr, listify, true\n",
    "from fasterai.core.criteria import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1cd2e-9333-407f-a4e0-390174eab3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Pruner():\n",
    "    def __init__(self, model, context, criteria, layer_type=[nn.Conv2d, nn.Linear, nn.LSTM], example_inputs=torch.randn(1,3,224,224), ignored_layers=None):\n",
    "        store_attr()\n",
    "        self.ignored_layers = []\n",
    "        self.ignored_params = []\n",
    "        if ignored_layers is not None:\n",
    "            for layer in ignored_layers:\n",
    "                if isinstance(layer, nn.Module):\n",
    "                    self.ignored_layers.extend(list(layer.modules()))\n",
    "                elif isinstance(layer, nn.Parameter):\n",
    "                    self.ignored_params.append(layer)\n",
    "\n",
    "        self.DG = tp.DependencyGraph()\n",
    "        self.DG.build_dependency(self.model, example_inputs=example_inputs.to(next(model.parameters()).device), ignored_params=self.ignored_params)\n",
    "        self._save_init_state()\n",
    "        self._reset_threshold()\n",
    "        self.init_num_groups = None\n",
    "\n",
    "    def compute_threshold(self, sparsity):\n",
    "        self.global_importance = {}\n",
    "        for ix, grp in enumerate(self.DG.get_all_groups(root_module_types=self.layer_type, ignored_layers=self.ignored_layers)):\n",
    "            imp = self.group_importance(grp)\n",
    "            self.global_importance[ix] = imp\n",
    "\n",
    "        global_imp = torch.cat(list(self.global_importance.values()), dim=0)\n",
    "\n",
    "        self.init_num_groups = self.init_num_groups or len(global_imp)\n",
    "        n_pruned = np.clip(int((1-sparsity/100)*self.init_num_groups), 1, len(global_imp))\n",
    "        self.global_threshold = torch.topk(global_imp, n_pruned)[0].min()\n",
    "\n",
    "    def prune_group(self, group, ix, sparsity, round_to):\n",
    "        module = group[0][0].target.module\n",
    "        pruning_fn = group[0][0].handler\n",
    "        pruning_idxs = self.prune_method(group, ix, sparsity, round_to)\n",
    "        \n",
    "        group = self.DG.get_pruning_group(module, pruning_fn, pruning_idxs.tolist())\n",
    "        group.prune()\n",
    "    \n",
    "    def prune_model(self, sparsity, round_to=None):\n",
    "        if self.context=='global': self.compute_threshold(sparsity)\n",
    "        for ix, group in enumerate(self.DG.get_all_groups(root_module_types=self.layer_type, ignored_layers=self.ignored_layers)):\n",
    "            self.prune_group(group, ix, sparsity, round_to)\n",
    "\n",
    "    def prune_method(self, group, ix, sparsity, round_to):\n",
    "        if self.context=='global':\n",
    "            imp = self.global_importance[ix]\n",
    "            n_pruned = max(1, int(imp.ge(self.global_threshold).sum()))\n",
    "        else:\n",
    "            imp = self.group_importance(group)\n",
    "            \n",
    "            if self.DG.is_out_channel_pruning_fn(group[0].dep.handler):\n",
    "                prunable_channels = group[0].dep.target.module._init_out_channels\n",
    "            else:\n",
    "                prunable_channels = group[0].dep.target.module._init_in_channels\n",
    "\n",
    "            n_pruned = max(1, int((1-sparsity/100)*prunable_channels))\n",
    " \n",
    "        threshold = torch.topk(imp, int(self._rounded_sparsity(torch.tensor(n_pruned), round_to)))[0].min() if round_to else torch.topk(imp, n_pruned)[0].min()\n",
    "\n",
    "        return imp.lt(threshold).nonzero().view(-1)\n",
    "    \n",
    "                \n",
    "    def updated_sparsity(self, m, sparsity):\n",
    "        init_channels = m._init_out_channels\n",
    "        return sparsity\n",
    "                \n",
    "    def _save_init_state(self):\n",
    "        for m in self.model.modules():\n",
    "            if hasattr(m, 'weight'):\n",
    "                setattr(m, '_init_out_channels', self.DG.get_out_channels(m))\n",
    "                setattr(m, '_init_in_channels', self.DG.get_in_channels(m))\n",
    "\n",
    "    def _rounded_sparsity(self, n_to_prune, round_to):\n",
    "        return max(round_to*torch.floor(n_to_prune/round_to), round_to)\n",
    "    \n",
    "    def _reset_threshold(self):\n",
    "        self.global_threshold=None\n",
    "    \n",
    "    def group_importance(self, group):\n",
    "        handler_map = {\n",
    "            function.prune_conv_out_channels: 'filter',\n",
    "            #function.prune_linear_out_channels: 'row',\n",
    "            #function.prune_linear_in_channels: 'column',\n",
    "            function.prune_conv_in_channels: 'shared_kernel',\n",
    "            # Additional handlers can be added here\n",
    "        }\n",
    "\n",
    "        group_imp = []\n",
    "        group_idxs = []\n",
    "\n",
    "        for i, (dep, idxs) in enumerate(group):\n",
    "            if dep.handler in handler_map:\n",
    "                impo = self.criteria(dep.target.module, handler_map.get(dep.handler), squeeze=True)\n",
    "                group_imp.append(impo)\n",
    "                group_idxs.append(group[i].root_idxs)\n",
    "\n",
    "        reduced_imp = torch.zeros_like(group_imp[0])\n",
    "\n",
    "        for i, (imp, root_idxs) in enumerate(zip(group_imp, group_idxs)):\n",
    "            imp = imp.to('cpu')\n",
    "            reduced_imp = reduced_imp.to('cpu')\n",
    "            reduced_imp.scatter_add_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "\n",
    "        reduced_imp /= len(group_imp)\n",
    "\n",
    "        return reduced_imp.to(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf56b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nathanhubens/fasterai/tree/master/blob/master/fasterai/prune/pruner.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Pruner.prune_model\n",
       "\n",
       ">      Pruner.prune_model (sparsity, round_to=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nathanhubens/fasterai/tree/master/blob/master/fasterai/prune/pruner.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Pruner.prune_model\n",
       "\n",
       ">      Pruner.prune_model (sparsity, round_to=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Pruner.prune_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a113a5a",
   "metadata": {},
   "source": [
    "Let's try the `Pruner` with a VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636541eb-a0ca-4e48-9c40-1cbc652be4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0126)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(torch.randn(1000), int(max(8*torch.floor(torch.tensor(30)/8), 8)))[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cbd9f-c849-4f41-9a94-55dd7fbcb888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0065)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(torch.randn(1000), 30)[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82748477-88b9-45b0-a90c-3099bda69fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(8*torch.floor(torch.tensor(30)/8), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7f2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18().to('cuda:0')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8ac36",
   "metadata": {},
   "source": [
    "The `Pruner`can either remove filters based on `local` criteria (i.e. each layer will be trimmed of the same % of filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(48, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(48, 112, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(112, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(112, 240, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(240, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(240, 488, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=488, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1393209728.0, 10405416)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner = Pruner(model, 'local', large_final, layer_type=[nn.Conv2d])\n",
    "pruner.prune_model(3, round_to=8)\n",
    "print(model)\n",
    "\n",
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(model, torch.randn(1,3,224,224).to('cuda:0')); pruned_macs, pruned_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7476da",
   "metadata": {},
   "source": [
    "The `Pruner`can also remove filters based on `global` criteria (i.e. each layer will be trimmed of a different % of filters, but we specify the sparsity of the whole network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea42e1c-ab28-4515-a2bb-77d4cefd12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb0d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(118, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(82, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(72, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(83, 93, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(93, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9945391172.0, 126347419)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner = Pruner(model, 'global', large_final, layer_type=[nn.Conv2d])\n",
    "pruner.prune_model(50)\n",
    "print(model)\n",
    "\n",
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(model, torch.randn(1,3,224,224)); pruned_macs, pruned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231a311-b9ca-48b5-add4-d251ddc224a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77214735-1c68-4161-a5cd-318dee37ae86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4bda92-a378-4441-9c5d-2fc320aa5d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1ed33-19b8-440f-8b69-51a93eb890b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bea1a6-bee0-4000-9663-24bc7bc688c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3884d398-c0f5-472b-98a1-c33271046f65",
   "metadata": {},
   "source": [
    "# New Pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f2dd3f-3790-4e97-881f-8b98be010a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from itertools import cycle\n",
    "from fastcore.basics import store_attr, listify, true\n",
    "from fasterai.core.criteria import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc54a14-0ba8-4d33-b28b-a0dd8cd2cb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161342e-e548-4b00-8c69-032a3228f246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Pruner():\n",
    "    def __init__(self, model, context, criteria, example_inputs=torch.randn(1,3,224,224), ignored_layers=None):\n",
    "        store_attr()\n",
    "        \n",
    "        self.pruner = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n",
    "            model,\n",
    "            example_inputs,\n",
    "            importance=criteria,\n",
    "            pruning_ratio=0.5,\n",
    "            ignored_layers=ignored_layers,\n",
    "            global_pruning= context,\n",
    "        )\n",
    "    \n",
    "    def prune_model_old(self, sparsity):\n",
    "        for ix, group in enumerate(self.pruner.DG.get_all_groups(root_module_types=self.pruner.root_module_types, ignored_layers=self.pruner.ignored_layers)):\n",
    "            self.prune_group(group, ix, sparsity)\n",
    "\n",
    "    def prune_model(self, sparsity):\n",
    "        for m in self.model.modules():\n",
    "            try: \n",
    "                self.manual_prune(m, sparsity)\n",
    "            except Exception as error: print(error)\n",
    "    \n",
    "    def prune_group(self, group, ix, sparsity):\n",
    "        module = group[0][0].target.module\n",
    "        pruning_fn = group[0][0].handler\n",
    "        pruning_idxs = self.prune_method(group, ix, sparsity, round_to)\n",
    "        \n",
    "        group = self.DG.get_pruning_group(module, pruning_fn, pruning_idxs.tolist())\n",
    "        group.prune()\n",
    "\n",
    "    def manual_prune(self, layer, pruning_ratios_or_idxs):\n",
    "        all_groups = list(self.pruner.DG.get_all_groups(root_module_types=self.pruner.root_module_types, ignored_layers=self.pruner.ignored_layers))\n",
    "        pruning_fn = all_groups[0][0][0].handler\n",
    "        if self.pruner.DG.is_out_channel_pruning_fn(pruning_fn):\n",
    "            prunable_channels = self.pruner.DG.get_out_channels(layer)\n",
    "        else:\n",
    "            prunable_channels = self.pruner.DG.get_in_channels(layer)\n",
    "        full_group = self.pruner.DG.get_pruning_group(layer, pruning_fn, list(range(prunable_channels)))\n",
    "        imp = self.pruner.estimate_importance(full_group)\n",
    "        imp_argsort = torch.argsort(imp)\n",
    "        n_pruned = int(prunable_channels * (1 - pruning_ratios_or_idxs))\n",
    "        pruning_idxs = imp_argsort[:n_pruned]\n",
    "        print(pruning_idxs)\n",
    " \n",
    "        group = self.pruner.DG.get_pruning_group(layer, pruning_fn, pruning_idxs)\n",
    "        group.prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7191732-5eac-4fb1-8660-93ac0102038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import torch_pruning as tp\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "example_inputs = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "pruner = Pruner(model, \"False\", tp.importance.GroupNormImportance(p=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d03146-5321-4565-be4f-85833e90ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "Sequential(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "Sequential(\n",
      "  (0): BasicBlock(\n",
      "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): BasicBlock(\n",
      "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "Sequential(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "BasicBlock(\n",
      "  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "ReLU(inplace=True)\n",
      "tensor([], dtype=torch.int64)\n",
      "'Conv2d' object has no attribute 'out_features'\n",
      "Dimension out of range (expected to be in range of [-1, 0], but got 1)\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "tensor([], dtype=torch.int64)\n"
     ]
    }
   ],
   "source": [
    "pruner.prune_model(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42130389-c47e-4d2e-bad7-24e6ac4671c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb59020-df1b-46e4-938a-87801804b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "import torch_pruning as tp\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "example_inputs = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# 1. Importance criterion\n",
    "imp = tp.importance.GroupNormImportance(p=2) # or GroupTaylorImportance(), GroupHessianImportance(), etc.\n",
    "\n",
    "# 2. Initialize a pruner with the model and the importance criterion\n",
    "ignored_layers = []\n",
    "for m in model.modules():\n",
    "    if isinstance(m, torch.nn.Linear) and m.out_features == 1000:\n",
    "        ignored_layers.append(m) # DO NOT prune the final classifier!\n",
    "\n",
    "pruner = tp.pruner.MetaPruner( # We can always choose MetaPruner if sparse training is not required.\n",
    "    model,\n",
    "    example_inputs,\n",
    "    importance=imp,\n",
    "    pruning_ratio=0.5, # remove 50% channels, ResNet18 = {64, 128, 256, 512} => ResNet18_Half = {32, 64, 128, 256}\n",
    "    ignored_layers=ignored_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794df5c-f495-4db2-8617-ed7fb5c18ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970999b6-2471-44f2-981c-c18db49cb0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer4.0.downsample.0 (Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer4.0.downsample.0 (Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=256\n",
      "[1] prune_out_channels on layer4.0.downsample.0 (Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer4.0.downsample.1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[2] prune_out_channels on layer4.0.downsample.1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_6(AddBackward0), len(idxs)=256\n",
      "[3] prune_out_channels on _ElementWiseOp_6(AddBackward0) => prune_out_channels on layer4.0.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[4] prune_out_channels on _ElementWiseOp_6(AddBackward0) => prune_out_channels on _ElementWiseOp_5(ReluBackward0), len(idxs)=256\n",
      "[5] prune_out_channels on _ElementWiseOp_5(ReluBackward0) => prune_out_channels on _ElementWiseOp_4(AddBackward0), len(idxs)=256\n",
      "[6] prune_out_channels on _ElementWiseOp_5(ReluBackward0) => prune_in_channels on layer4.1.conv1 (Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[7] prune_out_channels on _ElementWiseOp_4(AddBackward0) => prune_out_channels on layer4.1.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[8] prune_out_channels on _ElementWiseOp_4(AddBackward0) => prune_out_channels on _ElementWiseOp_3(ReluBackward0), len(idxs)=256\n",
      "[9] prune_out_channels on _ElementWiseOp_3(ReluBackward0) => prune_out_channels on _ElementWiseOp_2(MeanBackward1), len(idxs)=256\n",
      "[10] prune_out_channels on _ElementWiseOp_2(MeanBackward1) => prune_out_channels on _Reshape_0(), len(idxs)=256\n",
      "[11] prune_out_channels on _Reshape_0() => prune_in_channels on fc (Linear(in_features=512, out_features=1000, bias=True)), len(idxs)=256\n",
      "[12] prune_in_channels on fc (Linear(in_features=512, out_features=1000, bias=True)) => prune_out_channels on _ElementWiseOp_1(TBackward0), len(idxs)=256\n",
      "[13] prune_out_channels on layer4.1.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer4.1.conv2 (Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[14] prune_out_channels on layer4.0.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer4.0.conv2 (Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer3.0.downsample.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer3.0.downsample.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=128\n",
      "[1] prune_out_channels on layer3.0.downsample.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer3.0.downsample.1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[2] prune_out_channels on layer3.0.downsample.1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_10(AddBackward0), len(idxs)=128\n",
      "[3] prune_out_channels on _ElementWiseOp_10(AddBackward0) => prune_out_channels on layer3.0.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[4] prune_out_channels on _ElementWiseOp_10(AddBackward0) => prune_out_channels on _ElementWiseOp_9(ReluBackward0), len(idxs)=128\n",
      "[5] prune_out_channels on _ElementWiseOp_9(ReluBackward0) => prune_out_channels on _ElementWiseOp_8(AddBackward0), len(idxs)=128\n",
      "[6] prune_out_channels on _ElementWiseOp_9(ReluBackward0) => prune_in_channels on layer3.1.conv1 (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[7] prune_out_channels on _ElementWiseOp_8(AddBackward0) => prune_out_channels on layer3.1.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[8] prune_out_channels on _ElementWiseOp_8(AddBackward0) => prune_out_channels on _ElementWiseOp_7(ReluBackward0), len(idxs)=128\n",
      "[9] prune_out_channels on _ElementWiseOp_7(ReluBackward0) => prune_in_channels on layer4.0.downsample.0 (Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=128\n",
      "[10] prune_out_channels on _ElementWiseOp_7(ReluBackward0) => prune_in_channels on layer4.0.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[11] prune_out_channels on layer3.1.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer3.1.conv2 (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[12] prune_out_channels on layer3.0.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer3.0.conv2 (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=64\n",
      "[1] prune_out_channels on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer2.0.downsample.1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[2] prune_out_channels on layer2.0.downsample.1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_14(AddBackward0), len(idxs)=64\n",
      "[3] prune_out_channels on _ElementWiseOp_14(AddBackward0) => prune_out_channels on layer2.0.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[4] prune_out_channels on _ElementWiseOp_14(AddBackward0) => prune_out_channels on _ElementWiseOp_13(ReluBackward0), len(idxs)=64\n",
      "[5] prune_out_channels on _ElementWiseOp_13(ReluBackward0) => prune_out_channels on _ElementWiseOp_12(AddBackward0), len(idxs)=64\n",
      "[6] prune_out_channels on _ElementWiseOp_13(ReluBackward0) => prune_in_channels on layer2.1.conv1 (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[7] prune_out_channels on _ElementWiseOp_12(AddBackward0) => prune_out_channels on layer2.1.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[8] prune_out_channels on _ElementWiseOp_12(AddBackward0) => prune_out_channels on _ElementWiseOp_11(ReluBackward0), len(idxs)=64\n",
      "[9] prune_out_channels on _ElementWiseOp_11(ReluBackward0) => prune_in_channels on layer3.0.downsample.0 (Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=64\n",
      "[10] prune_out_channels on _ElementWiseOp_11(ReluBackward0) => prune_in_channels on layer3.0.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[11] prune_out_channels on layer2.1.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer2.1.conv2 (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[12] prune_out_channels on layer2.0.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer2.0.conv2 (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)), len(idxs)=32\n",
      "[1] prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[2] prune_out_channels on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_20(ReluBackward0), len(idxs)=32\n",
      "[3] prune_out_channels on _ElementWiseOp_20(ReluBackward0) => prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0), len(idxs)=32\n",
      "[4] prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0) => prune_out_channels on _ElementWiseOp_18(AddBackward0), len(idxs)=32\n",
      "[5] prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0) => prune_in_channels on layer1.0.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[6] prune_out_channels on _ElementWiseOp_18(AddBackward0) => prune_out_channels on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[7] prune_out_channels on _ElementWiseOp_18(AddBackward0) => prune_out_channels on _ElementWiseOp_17(ReluBackward0), len(idxs)=32\n",
      "[8] prune_out_channels on _ElementWiseOp_17(ReluBackward0) => prune_out_channels on _ElementWiseOp_16(AddBackward0), len(idxs)=32\n",
      "[9] prune_out_channels on _ElementWiseOp_17(ReluBackward0) => prune_in_channels on layer1.1.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[10] prune_out_channels on _ElementWiseOp_16(AddBackward0) => prune_out_channels on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[11] prune_out_channels on _ElementWiseOp_16(AddBackward0) => prune_out_channels on _ElementWiseOp_15(ReluBackward0), len(idxs)=32\n",
      "[12] prune_out_channels on _ElementWiseOp_15(ReluBackward0) => prune_in_channels on layer2.0.downsample.0 (Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=32\n",
      "[13] prune_out_channels on _ElementWiseOp_15(ReluBackward0) => prune_in_channels on layer2.0.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[14] prune_out_channels on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer1.1.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[15] prune_out_channels on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer1.0.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer1.0.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.0.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[1] prune_out_channels on layer1.0.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.0.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[2] prune_out_channels on layer1.0.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_21(ReluBackward0), len(idxs)=32\n",
      "[3] prune_out_channels on _ElementWiseOp_21(ReluBackward0) => prune_in_channels on layer1.0.conv2 (Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer1.1.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.1.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[1] prune_out_channels on layer1.1.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.1.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[2] prune_out_channels on layer1.1.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_22(ReluBackward0), len(idxs)=32\n",
      "[3] prune_out_channels on _ElementWiseOp_22(ReluBackward0) => prune_in_channels on layer1.1.conv2 (Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer2.0.conv1 (Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer2.0.conv1 (Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[1] prune_out_channels on layer2.0.conv1 (Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer2.0.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[2] prune_out_channels on layer2.0.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_23(ReluBackward0), len(idxs)=64\n",
      "[3] prune_out_channels on _ElementWiseOp_23(ReluBackward0) => prune_in_channels on layer2.0.conv2 (Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer2.1.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer2.1.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[1] prune_out_channels on layer2.1.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer2.1.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[2] prune_out_channels on layer2.1.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_24(ReluBackward0), len(idxs)=64\n",
      "[3] prune_out_channels on _ElementWiseOp_24(ReluBackward0) => prune_in_channels on layer2.1.conv2 (Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer3.0.conv1 (Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer3.0.conv1 (Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[1] prune_out_channels on layer3.0.conv1 (Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer3.0.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[2] prune_out_channels on layer3.0.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_25(ReluBackward0), len(idxs)=128\n",
      "[3] prune_out_channels on _ElementWiseOp_25(ReluBackward0) => prune_in_channels on layer3.0.conv2 (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer3.1.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer3.1.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[1] prune_out_channels on layer3.1.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer3.1.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[2] prune_out_channels on layer3.1.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_26(ReluBackward0), len(idxs)=128\n",
      "[3] prune_out_channels on _ElementWiseOp_26(ReluBackward0) => prune_in_channels on layer3.1.conv2 (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer4.0.conv1 (Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer4.0.conv1 (Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[1] prune_out_channels on layer4.0.conv1 (Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer4.0.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[2] prune_out_channels on layer4.0.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_27(ReluBackward0), len(idxs)=256\n",
      "[3] prune_out_channels on _ElementWiseOp_27(ReluBackward0) => prune_in_channels on layer4.0.conv2 (Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer4.1.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer4.1.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[1] prune_out_channels on layer4.1.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer4.1.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[2] prune_out_channels on layer4.1.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_28(ReluBackward0), len(idxs)=256\n",
      "[3] prune_out_channels on _ElementWiseOp_28(ReluBackward0) => prune_in_channels on layer4.1.conv2 (Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "--------------------------------\n",
      "\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n",
      "487202536.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    for group in pruner.step(interactive=True): # Warning: groups must be handled sequentially. Do not keep them as a list.\n",
    "        print(group) \n",
    "        # do whatever you like with the group \n",
    "        dep, idxs = group[0] # get the idxs\n",
    "        target_module = dep.target.module # get the root module\n",
    "        pruning_fn = dep.handler # get the pruning function\n",
    "        group.prune()\n",
    "        # group.prune(idxs=[0, 2, 6]) # It is even possible to change the pruning behaviour with the idxs parameter\n",
    "    macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "    print(macs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf86121-1fb3-4a0d-bd15-453ea3d06f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487202536.0\n",
      "3055880\n"
     ]
    }
   ],
   "source": [
    "#base_macs, base_nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "pruner.step()\n",
    "macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)\n",
    "print(macs)\n",
    "print(nparams)\n",
    "#print(f\"MACs: {base_macs/1e9} G -> {macs/1e9} G, #Params: {base_nparams/1e6} M -> {nparams/1e6} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad78513-ec37-422d-933f-8790b74b918a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=256, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f8f54-fa76-48ad-ad65-0da48f5f4119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer4.0.downsample.0 (Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer4.0.downsample.0 (Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=256\n",
      "[1] prune_out_channels on layer4.0.downsample.0 (Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer4.0.downsample.1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[2] prune_out_channels on layer4.0.downsample.1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_6(AddBackward0), len(idxs)=256\n",
      "[3] prune_out_channels on _ElementWiseOp_6(AddBackward0) => prune_out_channels on layer4.0.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[4] prune_out_channels on _ElementWiseOp_6(AddBackward0) => prune_out_channels on _ElementWiseOp_5(ReluBackward0), len(idxs)=256\n",
      "[5] prune_out_channels on _ElementWiseOp_5(ReluBackward0) => prune_out_channels on _ElementWiseOp_4(AddBackward0), len(idxs)=256\n",
      "[6] prune_out_channels on _ElementWiseOp_5(ReluBackward0) => prune_in_channels on layer4.1.conv1 (Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[7] prune_out_channels on _ElementWiseOp_4(AddBackward0) => prune_out_channels on layer4.1.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[8] prune_out_channels on _ElementWiseOp_4(AddBackward0) => prune_out_channels on _ElementWiseOp_3(ReluBackward0), len(idxs)=256\n",
      "[9] prune_out_channels on _ElementWiseOp_3(ReluBackward0) => prune_out_channels on _ElementWiseOp_2(MeanBackward1), len(idxs)=256\n",
      "[10] prune_out_channels on _ElementWiseOp_2(MeanBackward1) => prune_out_channels on _Reshape_0(), len(idxs)=256\n",
      "[11] prune_out_channels on _Reshape_0() => prune_in_channels on fc (Linear(in_features=512, out_features=1000, bias=True)), len(idxs)=256\n",
      "[12] prune_in_channels on fc (Linear(in_features=512, out_features=1000, bias=True)) => prune_out_channels on _ElementWiseOp_1(TBackward0), len(idxs)=256\n",
      "[13] prune_out_channels on layer4.1.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer4.1.conv2 (Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[14] prune_out_channels on layer4.0.bn2 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer4.0.conv2 (Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer3.0.downsample.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer3.0.downsample.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=128\n",
      "[1] prune_out_channels on layer3.0.downsample.0 (Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer3.0.downsample.1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[2] prune_out_channels on layer3.0.downsample.1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_10(AddBackward0), len(idxs)=128\n",
      "[3] prune_out_channels on _ElementWiseOp_10(AddBackward0) => prune_out_channels on layer3.0.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[4] prune_out_channels on _ElementWiseOp_10(AddBackward0) => prune_out_channels on _ElementWiseOp_9(ReluBackward0), len(idxs)=128\n",
      "[5] prune_out_channels on _ElementWiseOp_9(ReluBackward0) => prune_out_channels on _ElementWiseOp_8(AddBackward0), len(idxs)=128\n",
      "[6] prune_out_channels on _ElementWiseOp_9(ReluBackward0) => prune_in_channels on layer3.1.conv1 (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[7] prune_out_channels on _ElementWiseOp_8(AddBackward0) => prune_out_channels on layer3.1.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[8] prune_out_channels on _ElementWiseOp_8(AddBackward0) => prune_out_channels on _ElementWiseOp_7(ReluBackward0), len(idxs)=128\n",
      "[9] prune_out_channels on _ElementWiseOp_7(ReluBackward0) => prune_in_channels on layer4.0.downsample.0 (Conv2d(256, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=128\n",
      "[10] prune_out_channels on _ElementWiseOp_7(ReluBackward0) => prune_in_channels on layer4.0.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[11] prune_out_channels on layer3.1.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer3.1.conv2 (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[12] prune_out_channels on layer3.0.bn2 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer3.0.conv2 (Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=64\n",
      "[1] prune_out_channels on layer2.0.downsample.0 (Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)) => prune_out_channels on layer2.0.downsample.1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[2] prune_out_channels on layer2.0.downsample.1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_14(AddBackward0), len(idxs)=64\n",
      "[3] prune_out_channels on _ElementWiseOp_14(AddBackward0) => prune_out_channels on layer2.0.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[4] prune_out_channels on _ElementWiseOp_14(AddBackward0) => prune_out_channels on _ElementWiseOp_13(ReluBackward0), len(idxs)=64\n",
      "[5] prune_out_channels on _ElementWiseOp_13(ReluBackward0) => prune_out_channels on _ElementWiseOp_12(AddBackward0), len(idxs)=64\n",
      "[6] prune_out_channels on _ElementWiseOp_13(ReluBackward0) => prune_in_channels on layer2.1.conv1 (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[7] prune_out_channels on _ElementWiseOp_12(AddBackward0) => prune_out_channels on layer2.1.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[8] prune_out_channels on _ElementWiseOp_12(AddBackward0) => prune_out_channels on _ElementWiseOp_11(ReluBackward0), len(idxs)=64\n",
      "[9] prune_out_channels on _ElementWiseOp_11(ReluBackward0) => prune_in_channels on layer3.0.downsample.0 (Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=64\n",
      "[10] prune_out_channels on _ElementWiseOp_11(ReluBackward0) => prune_in_channels on layer3.0.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[11] prune_out_channels on layer2.1.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer2.1.conv2 (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[12] prune_out_channels on layer2.0.bn2 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer2.0.conv2 (Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)), len(idxs)=32\n",
      "[1] prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[2] prune_out_channels on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_20(ReluBackward0), len(idxs)=32\n",
      "[3] prune_out_channels on _ElementWiseOp_20(ReluBackward0) => prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0), len(idxs)=32\n",
      "[4] prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0) => prune_out_channels on _ElementWiseOp_18(AddBackward0), len(idxs)=32\n",
      "[5] prune_out_channels on _ElementWiseOp_19(MaxPool2DWithIndicesBackward0) => prune_in_channels on layer1.0.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[6] prune_out_channels on _ElementWiseOp_18(AddBackward0) => prune_out_channels on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[7] prune_out_channels on _ElementWiseOp_18(AddBackward0) => prune_out_channels on _ElementWiseOp_17(ReluBackward0), len(idxs)=32\n",
      "[8] prune_out_channels on _ElementWiseOp_17(ReluBackward0) => prune_out_channels on _ElementWiseOp_16(AddBackward0), len(idxs)=32\n",
      "[9] prune_out_channels on _ElementWiseOp_17(ReluBackward0) => prune_in_channels on layer1.1.conv1 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[10] prune_out_channels on _ElementWiseOp_16(AddBackward0) => prune_out_channels on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[11] prune_out_channels on _ElementWiseOp_16(AddBackward0) => prune_out_channels on _ElementWiseOp_15(ReluBackward0), len(idxs)=32\n",
      "[12] prune_out_channels on _ElementWiseOp_15(ReluBackward0) => prune_in_channels on layer2.0.downsample.0 (Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)), len(idxs)=32\n",
      "[13] prune_out_channels on _ElementWiseOp_15(ReluBackward0) => prune_in_channels on layer2.0.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[14] prune_out_channels on layer1.1.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer1.1.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[15] prune_out_channels on layer1.0.bn2 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on layer1.0.conv2 (Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer1.0.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.0.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[1] prune_out_channels on layer1.0.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.0.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[2] prune_out_channels on layer1.0.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_21(ReluBackward0), len(idxs)=32\n",
      "[3] prune_out_channels on _ElementWiseOp_21(ReluBackward0) => prune_in_channels on layer1.0.conv2 (Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer1.1.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.1.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "[1] prune_out_channels on layer1.1.conv1 (Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer1.1.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=32\n",
      "[2] prune_out_channels on layer1.1.bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_22(ReluBackward0), len(idxs)=32\n",
      "[3] prune_out_channels on _ElementWiseOp_22(ReluBackward0) => prune_in_channels on layer1.1.conv2 (Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=32\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer2.0.conv1 (Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer2.0.conv1 (Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[1] prune_out_channels on layer2.0.conv1 (Conv2d(32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer2.0.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[2] prune_out_channels on layer2.0.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_23(ReluBackward0), len(idxs)=64\n",
      "[3] prune_out_channels on _ElementWiseOp_23(ReluBackward0) => prune_in_channels on layer2.0.conv2 (Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer2.1.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer2.1.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "[1] prune_out_channels on layer2.1.conv1 (Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer2.1.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=64\n",
      "[2] prune_out_channels on layer2.1.bn1 (BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_24(ReluBackward0), len(idxs)=64\n",
      "[3] prune_out_channels on _ElementWiseOp_24(ReluBackward0) => prune_in_channels on layer2.1.conv2 (Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=64\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer3.0.conv1 (Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer3.0.conv1 (Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[1] prune_out_channels on layer3.0.conv1 (Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer3.0.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[2] prune_out_channels on layer3.0.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_25(ReluBackward0), len(idxs)=128\n",
      "[3] prune_out_channels on _ElementWiseOp_25(ReluBackward0) => prune_in_channels on layer3.0.conv2 (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer3.1.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer3.1.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "[1] prune_out_channels on layer3.1.conv1 (Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer3.1.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=128\n",
      "[2] prune_out_channels on layer3.1.bn1 (BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_26(ReluBackward0), len(idxs)=128\n",
      "[3] prune_out_channels on _ElementWiseOp_26(ReluBackward0) => prune_in_channels on layer3.1.conv2 (Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=128\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer4.0.conv1 (Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer4.0.conv1 (Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[1] prune_out_channels on layer4.0.conv1 (Conv2d(128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)) => prune_out_channels on layer4.0.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[2] prune_out_channels on layer4.0.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_27(ReluBackward0), len(idxs)=256\n",
      "[3] prune_out_channels on _ElementWiseOp_27(ReluBackward0) => prune_in_channels on layer4.0.conv2 (Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "--------------------------------\n",
      "          Pruning Group\n",
      "--------------------------------\n",
      "[0] prune_out_channels on layer4.1.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer4.1.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "[1] prune_out_channels on layer4.1.conv1 (Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)) => prune_out_channels on layer4.1.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)), len(idxs)=256\n",
      "[2] prune_out_channels on layer4.1.bn1 (BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)) => prune_out_channels on _ElementWiseOp_28(ReluBackward0), len(idxs)=256\n",
      "[3] prune_out_channels on _ElementWiseOp_28(ReluBackward0) => prune_in_channels on layer4.1.conv2 (Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)), len(idxs)=256\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in pruner.step(interactive=True): # Warning: groups must be handled sequentially. Do not keep them as a list.\n",
    "    print(group) \n",
    "    # do whatever you like with the group \n",
    "    dep, idxs = group[0] # get the idxs\n",
    "    target_module = dep.target.module # get the root module\n",
    "    pruning_fn = dep.handler # get the pruning function\n",
    "    group.prune()\n",
    "    # group.prune(idxs=[0, 2, 6]) # It is even possible to change the pruning behaviour with the idxs parameter\n",
    "macs, nparams = tp.utils.count_ops_and_params(model, example_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a06dc6-d340-43dd-a69f-d671bde14fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 0.487202536 G -> 0.487202536 G, #Params: 3.05588 M -> 3.05588 M\n"
     ]
    }
   ],
   "source": [
    "print(f\"MACs: {base_macs/1e9} G -> {macs/1e9} G, #Params: {base_nparams/1e6} M -> {nparams/1e6} M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69fc94-61d9-429c-bcb3-04f4d8e12eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44aeec8-f9ed-4f26-bd0b-45ce2068738b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1b4aa-3790-46d5-b45f-41790fe34571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf61b0e-71a4-4cd5-91a0-18a0802c3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    " return scores[None].mean(dim=dim, keepdim=True).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7118c0d8-4c6f-46a2-8f40-43c988f34b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def group_importance(self, group):\n",
    "        handler_map = {\n",
    "            function.prune_conv_out_channels: 'filter',\n",
    "            function.prune_conv_in_channels: 'shared_kernel',\n",
    "        }\n",
    "\n",
    "        group_imp = []\n",
    "        group_idxs = []\n",
    "\n",
    "        for i, (dep, idxs) in enumerate(group):\n",
    "            if dep.handler in handler_map:\n",
    "                impo = self.criteria(dep.target.module, handler_map.get(dep.handler), squeeze=True)\n",
    "                group_imp.append(impo)\n",
    "                group_idxs.append(group[i].root_idxs)\n",
    "\n",
    "        reduced_imp = torch.zeros_like(group_imp[0])\n",
    "\n",
    "        for i, (imp, root_idxs) in enumerate(zip(group_imp, group_idxs)):\n",
    "            imp = imp.to('cpu')\n",
    "            reduced_imp = reduced_imp.to('cpu')\n",
    "            reduced_imp.scatter_add_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "\n",
    "        reduced_imp /= len(group_imp)\n",
    "\n",
    "        return reduced_imp.to(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eff24f2-75a3-4196-9bdd-4f71a414d775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd70533-5024-4288-a4b0-9edd5fad7447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(self, group_importance, normalizer):\n",
    "        if normalizer is None:\n",
    "            return group_importance\n",
    "        elif isinstance(normalizer, typing.Callable):\n",
    "            return normalizer(group_importance)\n",
    "        elif normalizer == \"sum\":\n",
    "            return group_importance / group_importance.sum()\n",
    "        elif normalizer == \"standarization\":\n",
    "            return (group_importance - group_importance.min()) / (group_importance.max() - group_importance.min()+1e-8)\n",
    "        elif normalizer == \"mean\":\n",
    "            return group_importance / group_importance.mean()\n",
    "        elif normalizer == \"max\":\n",
    "            return group_importance / group_importance.max()\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _reduce(self, group_imp: typing.List[torch.Tensor], group_idxs: typing.List[typing.List[int]]):\n",
    "        if len(group_imp) == 0: return group_imp\n",
    "        if self.group_reduction == 'prod':\n",
    "            reduced_imp = torch.ones_like(group_imp[0])\n",
    "        elif self.group_reduction == 'max':\n",
    "            reduced_imp = torch.ones_like(group_imp[0]) * -99999\n",
    "        else:\n",
    "            reduced_imp = torch.zeros_like(group_imp[0])\n",
    "\n",
    "        for i, (imp, root_idxs) in enumerate(zip(group_imp, group_idxs)):\n",
    "            imp = imp.to(reduced_imp.device)\n",
    "            if self.group_reduction == \"sum\" or self.group_reduction == \"mean\":\n",
    "                reduced_imp.scatter_add_(0, torch.tensor(root_idxs, device=imp.device), imp) # accumulated importance\n",
    "            elif self.group_reduction == 'first':\n",
    "                if i == 0:\n",
    "                    reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "            elif self.group_reduction == 'gate':\n",
    "                if i == len(group_imp)-1:\n",
    "                    reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "            elif self.group_reduction is None:\n",
    "                reduced_imp = torch.stack(group_imp, dim=0) # no reduction\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        \n",
    "        if self.group_reduction == \"mean\":\n",
    "            reduced_imp /= len(group_imp)\n",
    "        return reduced_imp\n",
    "\n",
    "\n",
    "    group_imp = self._reduce(group_imp, group_idxs)\n",
    "    group_imp = self._normalize(group_imp, self.normalizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
