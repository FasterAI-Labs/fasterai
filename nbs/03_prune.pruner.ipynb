{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5a33dc9c",
   "metadata": {},
   "source": [
    "---\n",
    "description: Remove useless filters to recreate a dense network\n",
    "output-file: pruner.html\n",
    "title: Pruner\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp prune.pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from itertools import cycle\n",
    "from fastcore.basics import store_attr, listify, true\n",
    "from fasterai.core.criteria import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da1cd2e-9333-407f-a4e0-390174eab3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Pruner():\n",
    "    def __init__(self, model, context, criteria, layer_type=[nn.Conv2d, nn.Linear, nn.LSTM], example_inputs=torch.randn(1,3,224,224), ignored_layers=None):\n",
    "        store_attr()\n",
    "        self.ignored_layers = []\n",
    "        self.ignored_params = []\n",
    "        if ignored_layers is not None:\n",
    "            for layer in ignored_layers:\n",
    "                if isinstance(layer, nn.Module):\n",
    "                    self.ignored_layers.extend(list(layer.modules()))\n",
    "                elif isinstance(layer, nn.Parameter):\n",
    "                    self.ignored_params.append(layer)\n",
    "\n",
    "        self.DG = tp.DependencyGraph()\n",
    "        self.DG.build_dependency(self.model, example_inputs=example_inputs.to(next(model.parameters()).device), ignored_params=self.ignored_params)\n",
    "        self._save_init_state()\n",
    "        self._reset_threshold()\n",
    "        self.init_num_groups = None\n",
    "\n",
    "    def compute_threshold(self, sparsity):\n",
    "        self.global_importance = {}\n",
    "        for ix, grp in enumerate(self.DG.get_all_groups(root_module_types=self.layer_type, ignored_layers=self.ignored_layers)):\n",
    "            imp = self.group_importance(grp)\n",
    "            self.global_importance[ix] = imp\n",
    "\n",
    "        global_imp = torch.cat(list(self.global_importance.values()), dim=0)\n",
    "\n",
    "        self.init_num_groups = self.init_num_groups or len(global_imp)\n",
    "        n_pruned = np.clip(int((1-sparsity/100)*self.init_num_groups), 1, len(global_imp))\n",
    "        self.global_threshold = torch.topk(global_imp, n_pruned)[0].min()\n",
    "\n",
    "    def prune_group(self, group, ix, sparsity, round_to):\n",
    "        module = group[0][0].target.module\n",
    "        pruning_fn = group[0][0].handler\n",
    "        pruning_idxs = self.prune_method(group, ix, sparsity, round_to)\n",
    "        \n",
    "        group = self.DG.get_pruning_group(module, pruning_fn, pruning_idxs.tolist())\n",
    "        group.prune()\n",
    "    \n",
    "    def prune_model(self, sparsity, round_to=None):\n",
    "        if self.context=='global': self.compute_threshold(sparsity)\n",
    "        for ix, group in enumerate(self.DG.get_all_groups(root_module_types=self.layer_type, ignored_layers=self.ignored_layers)):\n",
    "            self.prune_group(group, ix, sparsity, round_to)\n",
    "\n",
    "    def prune_method(self, group, ix, sparsity, round_to):\n",
    "        if self.context=='global':\n",
    "            imp = self.global_importance[ix]\n",
    "            n_pruned = max(1, int(imp.ge(self.global_threshold).sum()))\n",
    "        else:\n",
    "            imp = self.group_importance(group)\n",
    "            \n",
    "            if self.DG.is_out_channel_pruning_fn(group[0].dep.handler):\n",
    "                prunable_channels = group[0].dep.target.module._init_out_channels\n",
    "            else:\n",
    "                prunable_channels = group[0].dep.target.module._init_in_channels\n",
    "\n",
    "            n_pruned = max(1, int((1-sparsity/100)*prunable_channels))\n",
    " \n",
    "        threshold = torch.topk(imp, int(self._rounded_sparsity(torch.tensor(n_pruned), round_to)))[0].min() if round_to else torch.topk(imp, n_pruned)[0].min()\n",
    "\n",
    "        return imp.lt(threshold).nonzero().view(-1)\n",
    "    \n",
    "                \n",
    "    def updated_sparsity(self, m, sparsity):\n",
    "        init_channels = m._init_out_channels\n",
    "        return sparsity\n",
    "                \n",
    "    def _save_init_state(self):\n",
    "        for m in self.model.modules():\n",
    "            if hasattr(m, 'weight'):\n",
    "                setattr(m, '_init_out_channels', self.DG.get_out_channels(m))\n",
    "                setattr(m, '_init_in_channels', self.DG.get_in_channels(m))\n",
    "\n",
    "    def _rounded_sparsity(self, n_to_prune, round_to):\n",
    "        return max(round_to*torch.floor(n_to_prune/round_to), round_to)\n",
    "    \n",
    "    def _reset_threshold(self):\n",
    "        self.global_threshold=None\n",
    "    \n",
    "    def group_importance(self, group):\n",
    "        handler_map = {\n",
    "            function.prune_conv_out_channels: 'filter',\n",
    "            #function.prune_linear_out_channels: 'row',\n",
    "            #function.prune_linear_in_channels: 'column',\n",
    "            function.prune_conv_in_channels: 'shared_kernel',\n",
    "            # Additional handlers can be added here\n",
    "        }\n",
    "\n",
    "        group_imp = []\n",
    "        group_idxs = []\n",
    "\n",
    "        for i, (dep, idxs) in enumerate(group):\n",
    "            if dep.handler in handler_map:\n",
    "                impo = self.criteria(dep.target.module, handler_map.get(dep.handler), squeeze=True)\n",
    "                group_imp.append(impo)\n",
    "                group_idxs.append(group[i].root_idxs)\n",
    "\n",
    "        reduced_imp = torch.zeros_like(group_imp[0])\n",
    "\n",
    "        for i, (imp, root_idxs) in enumerate(zip(group_imp, group_idxs)):\n",
    "            imp = imp.to('cpu')\n",
    "            reduced_imp = reduced_imp.to('cpu')\n",
    "            reduced_imp.scatter_add_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "\n",
    "        reduced_imp /= len(group_imp)\n",
    "\n",
    "        return reduced_imp.to(default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cf56b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nathanhubens/fasterai/tree/master/blob/master/fasterai/prune/pruner.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Pruner.prune_model\n",
       "\n",
       ">      Pruner.prune_model (sparsity, round_to=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nathanhubens/fasterai/tree/master/blob/master/fasterai/prune/pruner.py#L51){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Pruner.prune_model\n",
       "\n",
       ">      Pruner.prune_model (sparsity, round_to=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Pruner.prune_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a113a5a",
   "metadata": {},
   "source": [
    "Let's try the `Pruner` with a VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636541eb-a0ca-4e48-9c40-1cbc652be4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0126)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(torch.randn(1000), int(max(8*torch.floor(torch.tensor(30)/8), 8)))[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cbd9f-c849-4f41-9a94-55dd7fbcb888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0065)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(torch.randn(1000), 30)[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82748477-88b9-45b0-a90c-3099bda69fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(8*torch.floor(torch.tensor(30)/8), 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7f2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet18().to('cuda:0')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede8ac36",
   "metadata": {},
   "source": [
    "The `Pruner`can either remove filters based on `local` criteria (i.e. each layer will be trimmed of the same % of filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6aba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(48, 112, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(48, 112, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(112, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(112, 240, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(240, 488, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(240, 488, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(488, 488, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=488, out_features=1000, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1393209728.0, 10405416)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner = Pruner(model, 'local', large_final, layer_type=[nn.Conv2d])\n",
    "pruner.prune_model(3, round_to=8)\n",
    "print(model)\n",
    "\n",
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(model, torch.randn(1,3,224,224).to('cuda:0')); pruned_macs, pruned_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7476da",
   "metadata": {},
   "source": [
    "The `Pruner`can also remove filters based on `global` criteria (i.e. each layer will be trimmed of a different % of filters, but we specify the sparsity of the whole network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea42e1c-ab28-4515-a2bb-77d4cefd12d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb0d937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 118, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(118, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(118, 82, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(82, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(82, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(72, 83, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(83, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(83, 93, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(93, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(93, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9945391172.0, 126347419)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruner = Pruner(model, 'global', large_final, layer_type=[nn.Conv2d])\n",
    "pruner.prune_model(50)\n",
    "print(model)\n",
    "\n",
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(model, torch.randn(1,3,224,224)); pruned_macs, pruned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231a311-b9ca-48b5-add4-d251ddc224a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
