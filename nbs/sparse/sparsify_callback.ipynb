{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08159415",
   "metadata": {},
   "source": [
    "---\n",
    "description: Use the sparsifier in fastai Callback system\n",
    "output-file: sparsify_callback.html\n",
    "title: Sparsify Callback\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5148f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp sparse.sparsify_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fasterai.sparse.sparsifier import *\n",
    "from fasterai.core.criteria import *\n",
    "from fasterai.core.schedule import *\n",
    "from typing import Callable, Optional, Union, List, Tuple, Type\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b720750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SparsifyCallback(Callback):\n",
    "    def __init__(self, \n",
    "                 sparsity: Union[float, List[float]],    # Target sparsity level(s)\n",
    "                 granularity: str,                       # Type of pruning granularity (e.g., 'weight', 'filter')\n",
    "                 context: str,                           # Pruning context ('global' or 'local')\n",
    "                 criteria: Criteria,                     # Criteria for determining weights to keep\n",
    "                 schedule: Schedule,                     # Pruning schedule to use\n",
    "                 lth: bool = False,                      # Whether to use Lottery Ticket Hypothesis approach\n",
    "                 rewind_epoch: int = 0,                  # Epoch to rewind weights to for LTH\n",
    "                 reset_end: bool = False,                # Whether to reset weights after pruning\n",
    "                 save_tickets: bool = False,             # Whether to save pruned models as \"winning tickets\"\n",
    "                 model: Optional[nn.Module] = None,      # Model to sparsify (if None, uses learn.model)\n",
    "                 round_to: Optional[int] = None,         # Round pruning to multiple of this value\n",
    "                 nm: bool = False,                       # Whether to use N:M structured sparsity\n",
    "                 layer_type: Type[nn.Module] = nn.Conv2d # Layer type to apply pruning to\n",
    "    ):\n",
    "        \"Callback to sparsify model during training according to a schedule\"\n",
    "        store_attr()\n",
    "        self.sparsity = listify(self.sparsity)\n",
    "\n",
    "    def before_fit(self):\n",
    "        \"Setup sparsifier before training\"\n",
    "        print(f'Pruning of {self.granularity} until a sparsity of {self.sparsity}%')\n",
    "        assert self.schedule.start_pct*self.n_epoch>=self.rewind_epoch, 'You must rewind to an epoch before the start of the pruning process'\n",
    "        model = self.model or self.learn.model\n",
    "        self.sparsifier = Sparsifier(model, self.granularity, self.context, self.criteria, self.nm, self.layer_type)\n",
    "\n",
    "    def before_epoch(self):\n",
    "        \"Save weights at rewind epoch if using LTH\"\n",
    "        if self.epoch == self.rewind_epoch:\n",
    "            print(f'Saving Weights at epoch {self.epoch}')\n",
    "            self.sparsifier._save_weights()\n",
    "\n",
    "    def before_batch(self):\n",
    "        \"Update sparsity level and potentially apply pruning\"\n",
    "        self.current_sparsity = self.schedule(self.sparsity, round(self.pct_train,3))\n",
    "        if self.schedule.pruned and self.training:\n",
    "            if self.lth and self.save_tickets:\n",
    "                print('Saving Intermediate Ticket')\n",
    "                self.sparsifier.save_model(f'winning_ticket_{self.previous_sparsity[0]:.2f}.pth', self.learn.model)\n",
    "            self.sparsifier.sparsify_model(self.current_sparsity, self.round_to)\n",
    "\n",
    "    def after_step(self):\n",
    "        \"Handle post-pruning steps\"\n",
    "        if self.lth and self.schedule.pruned:\n",
    "            print(f'Resetting Weights to their epoch {self.rewind_epoch} values')\n",
    "            self.sparsifier._reset_weights(self.learn.model)\n",
    "        self.schedule.after_pruned()\n",
    "        self.sparsifier._apply_masks()\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Log sparsity after each epoch\"\n",
    "        sparsity_str = [float(f\"%0.2f\"%sp) for sp in self.current_sparsity]\n",
    "        print(f'Sparsity at the end of epoch {self.epoch}: {sparsity_str}%')\n",
    "\n",
    "    def after_fit(self):\n",
    "        \"Clean up after training\"\n",
    "        if self.save_tickets:\n",
    "            print('Saving Final Ticket')\n",
    "            self.sparsifier.save_model(f'winning_ticket_{self.previous_sparsity[0]:.2f}.pth', self.learn.model)\n",
    "        print(f'Final Sparsity: {self.schedule.current_sparsity:}%')\n",
    "        if self.reset_end: self.sparsifier._reset_weights()\n",
    "        self.sparsifier._clean_buffers()\n",
    "        self.schedule.reset()\n",
    "        self.sparsifier.print_sparsity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1921c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/FasterAI-Labs/fasterai/tree/master/blob/master/fasterai/sparse/sparsify_callback.py#L18){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SparsifyCallback\n",
       "\n",
       ">      SparsifyCallback (sparsity:Union[float,List[float]], granularity:str,\n",
       ">                        context:str, criteria:fasterai.core.criteria.Criteria,\n",
       ">                        schedule:fasterai.core.schedule.Schedule,\n",
       ">                        lth:bool=False, rewind_epoch:int=0,\n",
       ">                        reset_end:bool=False, save_tickets:bool=False,\n",
       ">                        model:Optional[torch.nn.modules.module.Module]=None,\n",
       ">                        round_to:Optional[int]=None, nm:bool=False,\n",
       ">                        layer_type:Type[torch.nn.modules.module.Module]=<class\n",
       ">                        'torch.nn.modules.conv.Conv2d'>)\n",
       "\n",
       "*Basic class handling tweaks of the training loop by changing a `Learner` in various events*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| sparsity | Union |  | Target sparsity level(s) |\n",
       "| granularity | str |  | Type of pruning granularity (e.g., 'weight', 'filter') |\n",
       "| context | str |  | Pruning context ('global' or 'local') |\n",
       "| criteria | Criteria |  | Criteria for determining weights to keep |\n",
       "| schedule | Schedule |  | Pruning schedule to use |\n",
       "| lth | bool | False | Whether to use Lottery Ticket Hypothesis approach |\n",
       "| rewind_epoch | int | 0 | Epoch to rewind weights to for LTH |\n",
       "| reset_end | bool | False | Whether to reset weights after pruning |\n",
       "| save_tickets | bool | False | Whether to save pruned models as \"winning tickets\" |\n",
       "| model | Optional | None | Model to sparsify (if None, uses learn.model) |\n",
       "| round_to | Optional | None | Round pruning to multiple of this value |\n",
       "| nm | bool | False | Whether to use N:M structured sparsity |\n",
       "| layer_type | Type | Conv2d | Layer type to apply pruning to |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/FasterAI-Labs/fasterai/tree/master/blob/master/fasterai/sparse/sparsify_callback.py#L18){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SparsifyCallback\n",
       "\n",
       ">      SparsifyCallback (sparsity:Union[float,List[float]], granularity:str,\n",
       ">                        context:str, criteria:fasterai.core.criteria.Criteria,\n",
       ">                        schedule:fasterai.core.schedule.Schedule,\n",
       ">                        lth:bool=False, rewind_epoch:int=0,\n",
       ">                        reset_end:bool=False, save_tickets:bool=False,\n",
       ">                        model:Optional[torch.nn.modules.module.Module]=None,\n",
       ">                        round_to:Optional[int]=None, nm:bool=False,\n",
       ">                        layer_type:Type[torch.nn.modules.module.Module]=<class\n",
       ">                        'torch.nn.modules.conv.Conv2d'>)\n",
       "\n",
       "*Basic class handling tweaks of the training loop by changing a `Learner` in various events*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| sparsity | Union |  | Target sparsity level(s) |\n",
       "| granularity | str |  | Type of pruning granularity (e.g., 'weight', 'filter') |\n",
       "| context | str |  | Pruning context ('global' or 'local') |\n",
       "| criteria | Criteria |  | Criteria for determining weights to keep |\n",
       "| schedule | Schedule |  | Pruning schedule to use |\n",
       "| lth | bool | False | Whether to use Lottery Ticket Hypothesis approach |\n",
       "| rewind_epoch | int | 0 | Epoch to rewind weights to for LTH |\n",
       "| reset_end | bool | False | Whether to reset weights after pruning |\n",
       "| save_tickets | bool | False | Whether to save pruned models as \"winning tickets\" |\n",
       "| model | Optional | None | Model to sparsify (if None, uses learn.model) |\n",
       "| round_to | Optional | None | Round pruning to multiple of this value |\n",
       "| nm | bool | False | Whether to use N:M structured sparsity |\n",
       "| layer_type | Type | Conv2d | Layer type to apply pruning to |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SparsifyCallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c13f6",
   "metadata": {},
   "source": [
    "The most important part of our `Callback` happens in `before_batch`. There, we first compute the sparsity of our network according to our schedule and then we remove the parameters accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f373da5",
   "metadata": {},
   "source": [
    "The `SparsifyCallback` requires a new argument compared to the `Sparsifier`. Indeed, we need to know the pruning schedule that we should follow during training in order to prune the parameters accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d931837",
   "metadata": {},
   "source": [
    "You can use any scheduling function already [available](https://docs.fast.ai/callback.schedule.html#Annealing) in fastai or come up with your own ! For more information about the pruning schedules, take a look at the [Schedules section](https://nathanhubens.github.io/fasterai/schedules.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46323843",
   "metadata": {},
   "source": [
    "On top of that, the `SparsifyCallback`can also take many optionnal arguments: \n",
    "\n",
    "- `lth`: whether training using the Lottery Ticket Hypothesis, i.e. reset the weights to their original value at each pruning step (more information in the Lottery Ticket Hypothesis section)\n",
    "- `rewind_epoch`: the epoch used as a reference for the Lottery Ticket Hypothesis with Rewinding (default to 0)\n",
    "- `reset_end`: whether you want to reset the weights to their original values after training (pruning masks are still applied)\n",
    "- `save_tickets`: whether to save intermediate winning tickets.\n",
    "- `model`: pass a model or a part of the model if you don't want to apply pruning on the whole model trained.\n",
    "- `round_to`: if specified, the weights will be pruned to the closest multiple value of `round_to`.\n",
    "- `layer_type`: specify the type of layer that you want to apply pruning to (default to nn.Conv2d)`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
