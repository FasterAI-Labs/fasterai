{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-floating",
   "metadata": {},
   "source": [
    "# Pruning Schedules\n",
    "\n",
    "> Make your neural network sparse with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-shift",
   "metadata": {},
   "source": [
    "The simplest way to perform pruning is called One-Shot Pruning. It consists of the following three steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-booth",
   "metadata": {},
   "source": [
    "![alt text](imgs/one_shot.pdf \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-browse",
   "metadata": {},
   "source": [
    "1. You first need to train a network\n",
    "2. You then need to remove some weights (depending on your criteria, needs,...)\n",
    "3. You fine-tune the remaining weights to recover from the loss of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-circular",
   "metadata": {},
   "source": [
    "With fasterai, this is really easy to do. Let's illustrate it by an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "from fasterai.sparsifier import *\n",
    "from fasterai.criteria import *\n",
    "from fasterai.sparsify_callback import *\n",
    "from fasterai.schedule import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_image_files(path/\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(f): return f[0].isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-measurement",
   "metadata": {},
   "source": [
    "We will first train a network without any pruning, which will serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-camcorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.655453</td>\n",
       "      <td>0.456962</td>\n",
       "      <td>0.830176</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.347105</td>\n",
       "      <td>0.249341</td>\n",
       "      <td>0.904601</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175726</td>\n",
       "      <td>0.205904</td>\n",
       "      <td>0.920839</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-consideration",
   "metadata": {},
   "source": [
    "## One-Shot Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-chemical",
   "metadata": {},
   "source": [
    "There are two main ways that you can perform One-Shot Pruning with fasterai. \n",
    "\n",
    "1. You already possess a trained network and want to prune it\n",
    "2. You don't possess such a network and have to train it from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-desire",
   "metadata": {},
   "source": [
    "### 1. You possess a trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-printer",
   "metadata": {},
   "source": [
    "In this case, the step 1) of the One-Shot Pruning process is already done. But you still need to prune the network and then fine-tune it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-cleanup",
   "metadata": {},
   "source": [
    "Let's say we want to remove $80 \\%$ of the weights of our network. This can be done as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = Sparsifier(learn.model, 'weight', 'global', l1_norm)\n",
    "sp.prune(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-employee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8464140892028809"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc = learn.validate(); acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-harvard",
   "metadata": {},
   "source": [
    "Obviously, as we removed a good part of trained weights, the perfomance of the network is degraded. This can be solved by retraining our pruned network, making sure that the pruned weights keep their 0 value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-puzzle",
   "metadata": {},
   "source": [
    "We don't want to update the sparsity level anymore so we have to create a schedule that returns a constant value. Such a schedule exists in fasterai and is called `one_shot` and is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot(start, end, pos): return end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-quick",
   "metadata": {},
   "source": [
    "We can pass the same arguments to our callback than those used by the Sparsifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=one_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-swimming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.189826</td>\n",
       "      <td>0.228184</td>\n",
       "      <td>0.901218</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.174893</td>\n",
       "      <td>0.206082</td>\n",
       "      <td>0.923545</td>\n",
       "      <td>01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.087448</td>\n",
       "      <td>0.189777</td>\n",
       "      <td>0.932341</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 80.00%\n",
      "Sparsity at the end of epoch 1: 80.00%\n",
      "Sparsity at the end of epoch 2: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-sarah",
   "metadata": {},
   "source": [
    "We can also check where the pruned weights are in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-momentum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in Conv2d 2: 38.84%\n",
      "Sparsity in Conv2d 8: 55.45%\n",
      "Sparsity in Conv2d 11: 50.12%\n",
      "Sparsity in Conv2d 14: 48.30%\n",
      "Sparsity in Conv2d 17: 49.84%\n",
      "Sparsity in Conv2d 21: 53.56%\n",
      "Sparsity in Conv2d 24: 60.95%\n",
      "Sparsity in Conv2d 27: 42.13%\n",
      "Sparsity in Conv2d 30: 60.09%\n",
      "Sparsity in Conv2d 33: 62.34%\n",
      "Sparsity in Conv2d 37: 65.65%\n",
      "Sparsity in Conv2d 40: 70.78%\n",
      "Sparsity in Conv2d 43: 60.77%\n",
      "Sparsity in Conv2d 46: 74.65%\n",
      "Sparsity in Conv2d 49: 77.25%\n",
      "Sparsity in Conv2d 53: 77.68%\n",
      "Sparsity in Conv2d 56: 82.73%\n",
      "Sparsity in Conv2d 59: 59.90%\n",
      "Sparsity in Conv2d 62: 80.71%\n",
      "Sparsity in Conv2d 65: 91.69%\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(learn.model.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(f\"Sparsity in {m.__class__.__name__} {k}: {100. * float(torch.sum(m.weight == 0))/ float(m.weight.nelement()):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-warren",
   "metadata": {},
   "source": [
    "> Note: Using Sparsifier to prune the network is not necessary as it will also be called in the Callback. This was used here to better illustrate all the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-removal",
   "metadata": {},
   "source": [
    "### 2. You don't possess a trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-remove",
   "metadata": {},
   "source": [
    "In this case, your network needs to be trained before pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-depression",
   "metadata": {},
   "source": [
    "You only need to create the Callback with the `one_shot` schedule and set the `start_epoch` argument, i.e. how many epochs you want to train your network before pruning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=one_shot, start_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-factor",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.668028</td>\n",
       "      <td>0.732009</td>\n",
       "      <td>0.832206</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.406280</td>\n",
       "      <td>0.355843</td>\n",
       "      <td>0.864005</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.254012</td>\n",
       "      <td>0.234607</td>\n",
       "      <td>0.901894</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156341</td>\n",
       "      <td>0.181618</td>\n",
       "      <td>0.933694</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072821</td>\n",
       "      <td>0.194896</td>\n",
       "      <td>0.934371</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048527</td>\n",
       "      <td>0.203621</td>\n",
       "      <td>0.926928</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.00%\n",
      "Sparsity at the end of epoch 1: 0.00%\n",
      "Sparsity at the end of epoch 2: 0.00%\n",
      "Sparsity at the end of epoch 3: 80.00%\n",
      "Sparsity at the end of epoch 4: 80.00%\n",
      "Sparsity at the end of epoch 5: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-extent",
   "metadata": {},
   "source": [
    "Actually, doing the training and pruning in a single cycle works even better !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-headquarters",
   "metadata": {},
   "source": [
    "We can check if we get similar sparsity values across the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-wagner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in Conv2d 2: 38.58%\n",
      "Sparsity in Conv2d 8: 55.26%\n",
      "Sparsity in Conv2d 11: 49.96%\n",
      "Sparsity in Conv2d 14: 47.94%\n",
      "Sparsity in Conv2d 17: 49.40%\n",
      "Sparsity in Conv2d 21: 53.08%\n",
      "Sparsity in Conv2d 24: 60.51%\n",
      "Sparsity in Conv2d 27: 41.58%\n",
      "Sparsity in Conv2d 30: 59.75%\n",
      "Sparsity in Conv2d 33: 62.18%\n",
      "Sparsity in Conv2d 37: 65.47%\n",
      "Sparsity in Conv2d 40: 70.64%\n",
      "Sparsity in Conv2d 43: 60.69%\n",
      "Sparsity in Conv2d 46: 74.53%\n",
      "Sparsity in Conv2d 49: 77.17%\n",
      "Sparsity in Conv2d 53: 77.64%\n",
      "Sparsity in Conv2d 56: 82.78%\n",
      "Sparsity in Conv2d 59: 59.83%\n",
      "Sparsity in Conv2d 62: 80.76%\n",
      "Sparsity in Conv2d 65: 91.83%\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(learn.model.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(f\"Sparsity in {m.__class__.__name__} {k}: {100. * float(torch.sum(m.weight == 0))/ float(m.weight.nelement()):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-saturn",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-webmaster",
   "metadata": {},
   "source": [
    "## Iterative Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-elder",
   "metadata": {},
   "source": [
    "Researchers have come up with a better way to do pruning than pruning all the weigths in once (as in One-Shot Pruning). The idea is to perform several iterations of pruning and fine-tuning and is thus called Iterative Pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-creature",
   "metadata": {},
   "source": [
    "![alt text](imgs/iterative.pdf \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-browse",
   "metadata": {},
   "source": [
    "1. You first need to train a network\n",
    "2. You then need to remove a part of the weights weights (depending on your criteria, needs,...)\n",
    "3. You fine-tune the remaining weights to recover from the loss of parameters.\n",
    "4. Back to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-chemical",
   "metadata": {},
   "source": [
    "There are two main ways that you can perform Iterative Pruning with fasterai. \n",
    "\n",
    "1. You already possess a trained network and want to prune it\n",
    "2. You don't possess such a network and have to train it from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-remove",
   "metadata": {},
   "source": [
    "In this case, your network needs to be trained before pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-depression",
   "metadata": {},
   "source": [
    "You only need to create the Callback with the `iterative` schedule and set the `start_epoch` argument, i.e. how many epochs you want to train your network before pruning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative(start, end, pos, n_steps=3):\n",
    "    \"Perform iterative pruning, and pruning in `n_steps` steps\"\n",
    "    return start + ((end-start)/n_steps)*(np.ceil((pos)*n_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-witness",
   "metadata": {},
   "source": [
    "The `iterative` schedules has a `n_steps`parameter, i.e. how many iterations of pruning/fine-tuning you want to perform. To modify its value, we can use the `partial` function like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-speed",
   "metadata": {},
   "source": [
    "```\n",
    "iterative = partial(iterative, n_steps=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=iterative, start_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-factor",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.707019</td>\n",
       "      <td>0.753476</td>\n",
       "      <td>0.792963</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.421993</td>\n",
       "      <td>0.341725</td>\n",
       "      <td>0.857916</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.271612</td>\n",
       "      <td>0.234841</td>\n",
       "      <td>0.901218</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157437</td>\n",
       "      <td>0.185066</td>\n",
       "      <td>0.933694</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093744</td>\n",
       "      <td>0.164622</td>\n",
       "      <td>0.938430</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.074952</td>\n",
       "      <td>0.179888</td>\n",
       "      <td>0.928958</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.00%\n",
      "Sparsity at the end of epoch 1: 0.00%\n",
      "Sparsity at the end of epoch 2: 0.00%\n",
      "Sparsity at the end of epoch 3: 26.67%\n",
      "Sparsity at the end of epoch 4: 53.33%\n",
      "Sparsity at the end of epoch 5: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-extent",
   "metadata": {},
   "source": [
    "As you can see, the network sparsity changes over the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-criterion",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-consideration",
   "metadata": {},
   "source": [
    "## Gradual Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=sched_agp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-factor",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.666568</td>\n",
       "      <td>0.774074</td>\n",
       "      <td>0.841678</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.408887</td>\n",
       "      <td>0.269850</td>\n",
       "      <td>0.888363</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.256823</td>\n",
       "      <td>0.250144</td>\n",
       "      <td>0.891069</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162672</td>\n",
       "      <td>0.195018</td>\n",
       "      <td>0.928958</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106435</td>\n",
       "      <td>0.176864</td>\n",
       "      <td>0.935724</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057881</td>\n",
       "      <td>0.166701</td>\n",
       "      <td>0.940460</td>\n",
       "      <td>01:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 33.70%\n",
      "Sparsity at the end of epoch 1: 56.30%\n",
      "Sparsity at the end of epoch 2: 70.00%\n",
      "Sparsity at the end of epoch 3: 77.04%\n",
      "Sparsity at the end of epoch 4: 79.63%\n",
      "Sparsity at the end of epoch 5: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, cbs=sp_cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
