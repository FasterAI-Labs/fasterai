{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fiscal-spencer",
   "metadata": {},
   "source": [
    "# Pruning Schedules\n",
    "\n",
    "> Make your neural network sparse with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-soldier",
   "metadata": {},
   "source": [
    "The simplest way to perform pruning is called One-Shot Pruning. It consists of the following three steps:\n",
    "\n",
    "![alt text](imgs/one_shot.pdf \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-transfer",
   "metadata": {},
   "source": [
    "1. You first need to train a network\n",
    "2. You then need to remove some weights (depending on your criteria, needs,...)\n",
    "3. You fine-tune the remaining weights to recover from the loss of parameters.\n",
    "\n",
    "With fasterai, this is really easy to do. Let's illustrate it by an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "from fasterai.sparsifier import *\n",
    "from fasterai.criteria import *\n",
    "from fasterai.sparsify_callback import *\n",
    "from fasterai.schedule import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-ordinary",
   "metadata": {},
   "source": [
    "We will first train a network without any pruning, which will serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-convention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.640964</td>\n",
       "      <td>0.633472</td>\n",
       "      <td>0.846414</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.331340</td>\n",
       "      <td>0.272124</td>\n",
       "      <td>0.895129</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181170</td>\n",
       "      <td>0.211167</td>\n",
       "      <td>0.912720</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()\n",
    "\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-pulse",
   "metadata": {},
   "source": [
    "## One-Shot Pruning\n",
    "\n",
    "There are two main ways that you can perform One-Shot Pruning with fasterai. \n",
    "\n",
    "1. You already possess a trained network and want to prune it\n",
    "2. You don't possess such a network and have to train it from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-harvey",
   "metadata": {},
   "source": [
    "### 1. You possess a trained network\n",
    "\n",
    "In this case, the step 1) of the One-Shot Pruning process is already done. But you still need to prune the network and then fine-tune it.\n",
    "\n",
    "Let's say we want to remove $80 \\%$ of the weights of our network. This can be done as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = Sparsifier(learn.model, 'weight', 'global', l1_norm)\n",
    "sp.prune(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-handbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8179972767829895"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, acc = learn.validate(); acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-buffalo",
   "metadata": {},
   "source": [
    "Obviously, as we removed a good part of trained weights, the perfomance of the network is degraded. This can be solved by retraining our pruned network, making sure that the pruned weights keep their 0 value.\n",
    "\n",
    "We don't want to update the sparsity level anymore so we have to create a schedule that returns a constant value. Such a schedule exists in fasterai and is called `one_shot` and is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-rabbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot(start, end, pos): return end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-pierce",
   "metadata": {},
   "source": [
    "We can pass the same arguments to our callback than those used by the Sparsifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.199193</td>\n",
       "      <td>0.281678</td>\n",
       "      <td>0.903248</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.167149</td>\n",
       "      <td>0.207365</td>\n",
       "      <td>0.916103</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.083820</td>\n",
       "      <td>0.196808</td>\n",
       "      <td>0.928281</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 80.00%\n",
      "Sparsity at the end of epoch 1: 80.00%\n",
      "Sparsity at the end of epoch 2: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=one_shot)\n",
    "\n",
    "learn.fit_one_cycle(3, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-walker",
   "metadata": {},
   "source": [
    "We can also check where the pruned weights are in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in Conv2d 2: 38.85%\n",
      "Sparsity in Conv2d 8: 55.18%\n",
      "Sparsity in Conv2d 11: 50.22%\n",
      "Sparsity in Conv2d 14: 48.10%\n",
      "Sparsity in Conv2d 17: 49.92%\n",
      "Sparsity in Conv2d 21: 53.43%\n",
      "Sparsity in Conv2d 24: 60.85%\n",
      "Sparsity in Conv2d 27: 42.36%\n",
      "Sparsity in Conv2d 30: 60.02%\n",
      "Sparsity in Conv2d 33: 62.29%\n",
      "Sparsity in Conv2d 37: 65.71%\n",
      "Sparsity in Conv2d 40: 70.78%\n",
      "Sparsity in Conv2d 43: 61.05%\n",
      "Sparsity in Conv2d 46: 74.60%\n",
      "Sparsity in Conv2d 49: 77.16%\n",
      "Sparsity in Conv2d 53: 77.67%\n",
      "Sparsity in Conv2d 56: 82.73%\n",
      "Sparsity in Conv2d 59: 59.82%\n",
      "Sparsity in Conv2d 62: 80.74%\n",
      "Sparsity in Conv2d 65: 91.73%\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(learn.model.modules()):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(f\"Sparsity in {m.__class__.__name__} {k}: {100. * float(torch.sum(m.weight == 0))/ float(m.weight.nelement()):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-shame",
   "metadata": {},
   "source": [
    "> Note: Using Sparsifier to prune the network is not necessary as it will also be called in the Callback. This was used here to better illustrate all the steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-wrapping",
   "metadata": {},
   "source": [
    "### 2. You don't possess a trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-authority",
   "metadata": {},
   "source": [
    "In this case, your network needs to be trained before pruning.\n",
    "\n",
    "You only need to create the Callback with the `one_shot` schedule and set the `start_epoch` argument, i.e. how many epochs you want to train your network before pruning it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facial-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=one_shot, start_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-presence",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-sculpture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.702169</td>\n",
       "      <td>0.456472</td>\n",
       "      <td>0.870095</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.410011</td>\n",
       "      <td>0.288117</td>\n",
       "      <td>0.881597</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250258</td>\n",
       "      <td>0.252269</td>\n",
       "      <td>0.889716</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.145373</td>\n",
       "      <td>0.176909</td>\n",
       "      <td>0.933694</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083379</td>\n",
       "      <td>0.201312</td>\n",
       "      <td>0.929635</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054683</td>\n",
       "      <td>0.208249</td>\n",
       "      <td>0.933694</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.00%\n",
      "Sparsity at the end of epoch 1: 0.00%\n",
      "Sparsity at the end of epoch 2: 0.00%\n",
      "Sparsity at the end of epoch 3: 80.00%\n",
      "Sparsity at the end of epoch 4: 80.00%\n",
      "Sparsity at the end of epoch 5: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-corpus",
   "metadata": {},
   "source": [
    "Actually, doing the training and pruning in a single cycle works even better !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-italic",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-craps",
   "metadata": {},
   "source": [
    "## Iterative Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-mouse",
   "metadata": {},
   "source": [
    "Researchers have come up with a better way to do pruning than pruning all the weigths in once (as in One-Shot Pruning). The idea is to perform several iterations of pruning and fine-tuning and is thus called Iterative Pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-weight",
   "metadata": {},
   "source": [
    "![alt text](imgs/iterative.pdf \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-sandwich",
   "metadata": {},
   "source": [
    "1. You first need to train a network\n",
    "2. You then need to remove a part of the weights weights (depending on your criteria, needs,...)\n",
    "3. You fine-tune the remaining weights to recover from the loss of parameters.\n",
    "4. Back to step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-climb",
   "metadata": {},
   "source": [
    "In this case, your network needs to be trained before pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-cinema",
   "metadata": {},
   "source": [
    "You only need to create the Callback with the `iterative` schedule and set the `start_epoch` argument, i.e. how many epochs you want to train your network before pruning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative(start, end, pos, n_steps=3):\n",
    "    \"Perform iterative pruning, and pruning in `n_steps` steps\"\n",
    "    return start + ((end-start)/n_steps)*(np.ceil((pos)*n_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-tuning",
   "metadata": {},
   "source": [
    "The `iterative` schedules has a `n_steps`parameter, i.e. how many iterations of pruning/fine-tuning you want to perform. To modify its value, we can use the `partial` function like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-stereo",
   "metadata": {},
   "source": [
    "```\n",
    "iterative = partial(iterative, n_steps=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=iterative, start_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-preference",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.678416</td>\n",
       "      <td>0.811682</td>\n",
       "      <td>0.843031</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.448310</td>\n",
       "      <td>0.305697</td>\n",
       "      <td>0.878214</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243350</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>0.905954</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140957</td>\n",
       "      <td>0.207141</td>\n",
       "      <td>0.929635</td>\n",
       "      <td>01:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082162</td>\n",
       "      <td>0.199370</td>\n",
       "      <td>0.927605</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.171238</td>\n",
       "      <td>0.930988</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.00%\n",
      "Sparsity at the end of epoch 1: 0.00%\n",
      "Sparsity at the end of epoch 2: 0.00%\n",
      "Sparsity at the end of epoch 3: 26.67%\n",
      "Sparsity at the end of epoch 4: 53.33%\n",
      "Sparsity at the end of epoch 5: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-commander",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-abraham",
   "metadata": {},
   "source": [
    "## Gradual Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-corrections",
   "metadata": {},
   "source": [
    "![alt text](imgs/gradual.pdf \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-principle",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=sched_agp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-plenty",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-investing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.620968</td>\n",
       "      <td>0.493531</td>\n",
       "      <td>0.855886</td>\n",
       "      <td>01:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.395395</td>\n",
       "      <td>0.336614</td>\n",
       "      <td>0.877537</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255663</td>\n",
       "      <td>0.199090</td>\n",
       "      <td>0.921516</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.157263</td>\n",
       "      <td>0.181541</td>\n",
       "      <td>0.924222</td>\n",
       "      <td>01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.099781</td>\n",
       "      <td>0.169471</td>\n",
       "      <td>0.933694</td>\n",
       "      <td>01:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.062961</td>\n",
       "      <td>0.175360</td>\n",
       "      <td>0.937077</td>\n",
       "      <td>01:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 33.70%\n",
      "Sparsity at the end of epoch 1: 56.30%\n",
      "Sparsity at the end of epoch 2: 70.00%\n",
      "Sparsity at the end of epoch 3: 77.04%\n",
      "Sparsity at the end of epoch 4: 79.63%\n",
      "Sparsity at the end of epoch 5: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, cbs=sp_cb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
