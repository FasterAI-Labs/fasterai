{
 "cells": [
  {
   "cell_type": "raw",
   "id": "452d040d",
   "metadata": {},
   "source": [
    "---\n",
    "description: Factorize heavy FC layers into smaller ones\n",
    "output-file: fc_decomposer.html\n",
    "title: Fully-Connected Layers Decomposer\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd975549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp misc.fc_decomposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6802a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f88207",
   "metadata": {},
   "source": [
    "We can factorize our big fully-connected layers and replace them by an approximation of two smaller layers. The idea is to make an SVD decomposition of the weight matrix, which will express the original matrix in a product of 3 matrices: $U \\Sigma V^T$\n",
    "With $\\Sigma$ being a diagonal matrix with non-negative values along its diagonal (the singular values). We then define a value $k$ of singular values to keep and modify matrices $U$ and $V^T$ accordingly. The resulting will be an approximation of the initial matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d50bd48",
   "metadata": {},
   "source": [
    "![](imgs/svd.png \"SVD Decomposition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbccd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan/opt/miniconda3/envs/nbdev/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FC_Decomposer:\n",
    "    \"Decompose fully-connected layers using SVD to reduce parameters\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def decompose(self, \n",
    "                  model: nn.Module,            # The model to decompose\n",
    "                  percent_removed: float = 0.5 # Fraction of singular values to remove [0, 1)\n",
    "    ) -> nn.Module:\n",
    "        \"Recursively decompose all Linear layers in the model using SVD\"\n",
    "        if not (0 <= percent_removed < 1):\n",
    "            raise ValueError(f\"percent_removed must be in range [0, 1), got {percent_removed}\")\n",
    "\n",
    "        new_model = copy.deepcopy(model)\n",
    "        module_names = list(new_model._modules)\n",
    "\n",
    "        for k, name in enumerate(module_names):\n",
    "            if len(list(new_model._modules[name]._modules)) > 0:\n",
    "                new_model._modules[name] = self.decompose(new_model._modules[name], percent_removed)\n",
    "            else:\n",
    "                if isinstance(new_model._modules[name], nn.Linear):\n",
    "                    layer = self.SVD(new_model._modules[name], percent_removed)\n",
    "                    new_model._modules[name] = layer\n",
    "        return new_model\n",
    "\n",
    "\n",
    "    def SVD(self, \n",
    "            layer: nn.Linear,       # The Linear layer to decompose\n",
    "            percent_removed: float  # Fraction of singular values to remove\n",
    "    ) -> nn.Sequential:\n",
    "        \"Perform SVD decomposition on a single Linear layer\"\n",
    "        W = layer.weight.data\n",
    "        U, S, V = torch.svd(W)\n",
    "        L = int((1.-percent_removed)*U.shape[0])\n",
    "        W1 = U[:,:L]\n",
    "        W2 = torch.diag(S[:L]) @ V[:,:L].t()\n",
    "        layer_1 = nn.Linear(in_features=layer.in_features, \n",
    "                    out_features=L, bias=False)\n",
    "        layer_1.weight.data = W2\n",
    "\n",
    "        layer_2 = nn.Linear(in_features=L, \n",
    "                    out_features=layer.out_features, bias=True)\n",
    "        layer_2.weight.data = W1\n",
    "\n",
    "        if layer.bias.data is None: \n",
    "            layer_2.bias.data = torch.zeros(layer.out_features)\n",
    "        else:\n",
    "            layer_2.bias.data = layer.bias.data\n",
    "\n",
    "        return nn.Sequential(layer_1, layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50222d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### FC_Decomposer.decompose\n",
       "\n",
       ">      FC_Decomposer.decompose (model, percent_removed=0.5)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### FC_Decomposer.decompose\n",
       "\n",
       ">      FC_Decomposer.decompose (model, percent_removed=0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FC_Decomposer.decompose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca024eed",
   "metadata": {},
   "source": [
    "A tutorial about how to use the `FC_Decomposer` functionalities can be found [here](https://nathanhubens.github.io/fasterai/tutorial.fc_decomposer.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
