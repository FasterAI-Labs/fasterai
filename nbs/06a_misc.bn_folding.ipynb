{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cf2cd234",
   "metadata": {},
   "source": [
    "---\n",
    "description: Fold the batchnorm and the conv layers together to reduce computation\n",
    "output-file: bn_folding.html\n",
    "title: Batch Norm Folding\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c581ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp misc.bn_folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-preparation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan/opt/miniconda3/envs/nbdev/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943e5d3",
   "metadata": {},
   "source": [
    "Batch Normalization is a technique which takes care of normalizing the input of each layer to make the training process faster and more stable. In practice, it is an extra layer that we generally add after the computation layer and before the non-linearity.\n",
    "\n",
    "It consists of 2 steps:\n",
    "\n",
    "1. Normalize the batch by first subtracting its mean $\\mu$, then dividing it by its standard deviation $\\sigma$.\n",
    "2. Further scale by a factor $\\gamma$ and shift by a factor $\\beta$. Those are the parameters of the batch normalization layer, required in case of the network not needing the data to have a mean of $0$ and a standard deviation of $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c79f29",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\\mu_{\\mathcal{B}} & \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m} x_{i} \\\\ \\sigma_{\\mathcal{B}}^{2} & \\leftarrow \\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}-\\mu_{\\mathcal{B}}\\right)^{2} \\\\ \\widehat{x}_{i} & \\leftarrow \\frac{x_{i}-\\mu_{\\mathcal{B}}}{\\sqrt{\\sigma_{\\mathcal{B}}^{2}+\\epsilon}} \\\\ y_{i} & \\leftarrow \\gamma \\widehat{x}_{i}+\\beta \\equiv \\mathrm{BN}_{\\gamma, \\beta}\\left(x_{i}\\right) \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d3efa1",
   "metadata": {},
   "source": [
    "Due to its efficiency for training neural networks, batch normalization is now widely used. But how useful is it at inference time?\n",
    "\n",
    "Once the training has ended, each batch normalization layer possesses a specific set of $\\gamma$ and $\\beta$, but also $\\mu$ and $\\sigma$, the latter being computed using an exponentially weighted average during training. It means that during inference, the batch normalization acts as a simple linear transformation of what comes out of the previous layer, often a convolution.\n",
    "\n",
    "As a convolution is also a linear transformation, it also means that both operations can be merged into a single linear transformation!\n",
    "\n",
    "This would remove some unnecessary parameters but also reduce the number of operations to be performed at inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52dc9f4",
   "metadata": {},
   "source": [
    "With a little bit of math, we can easily rearrange the terms of the convolution to take the batch normalization into account.\n",
    "\n",
    "As a little reminder, the convolution operation followed by the batch normalization operation can be expressed, for an input $x$, as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86a673",
   "metadata": {},
   "source": [
    "$$\\begin{aligned} z &=W * x+b \\\\ \\mathrm{out} &=\\gamma \\cdot \\frac{z-\\mu}{\\sqrt{\\sigma^{2}+\\epsilon}}+\\beta \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6f798",
   "metadata": {},
   "source": [
    "So, if we re-arrange the $W$ and $b$ of the convolution to take the parameters of the batch normalization into account, as such:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801af65",
   "metadata": {},
   "source": [
    "$$\\begin{aligned} w_{\\text {fold }} &=\\gamma \\cdot \\frac{W}{\\sqrt{\\sigma^{2}+\\epsilon}} \\\\ b_{\\text {fold }} &=\\gamma \\cdot \\frac{b-\\mu}{\\sqrt{\\sigma^{2}+\\epsilon}}+\\beta \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474bf03d",
   "metadata": {},
   "source": [
    "In practice, this can be achieved in FasterAI with the `BN_folder` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83000749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BN_Folder():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def fold(self, model):\n",
    "\n",
    "        new_model = copy.deepcopy(model)\n",
    "\n",
    "        module_names = list(new_model._modules)\n",
    "\n",
    "        for k, name in enumerate(module_names):\n",
    "\n",
    "            if len(list(new_model._modules[name]._modules)) > 0:\n",
    "                new_model._modules[name] = self.fold(new_model._modules[name])\n",
    "\n",
    "            else:\n",
    "                if isinstance(new_model._modules[name], nn.BatchNorm2d):\n",
    "                    if isinstance(new_model._modules[module_names[k-1]], nn.Conv2d):\n",
    "\n",
    "                        # Folded BN\n",
    "                        folded_conv = self._fold_conv_bn_eval(new_model._modules[module_names[k-1]], new_model._modules[name])\n",
    "\n",
    "                        # Replace old weight values\n",
    "                        #new_model._modules.pop(name) # Remove the BN layer\n",
    "                        new_model._modules[module_names[k]] = nn.Identity()\n",
    "                        new_model._modules[module_names[k-1]] = folded_conv # Replace the Convolutional Layer by the folded version\n",
    "\n",
    "        return new_model\n",
    "\n",
    "\n",
    "    def _bn_folding(self, conv_w, conv_b, bn_rm, bn_rv, bn_eps, bn_w, bn_b):\n",
    "        if conv_b is None:\n",
    "            conv_b = bn_rm.new_zeros(bn_rm.shape)\n",
    "        bn_var_rsqrt = torch.rsqrt(bn_rv + bn_eps)\n",
    "\n",
    "        w_fold = conv_w * (bn_w * bn_var_rsqrt).view(-1, 1, 1, 1)\n",
    "        b_fold = (conv_b - bn_rm) * bn_var_rsqrt * bn_w + bn_b\n",
    "\n",
    "        return torch.nn.Parameter(w_fold), torch.nn.Parameter(b_fold)\n",
    "\n",
    "\n",
    "    def _fold_conv_bn_eval(self, conv, bn):\n",
    "        assert(not (conv.training or bn.training)), \"Fusion only for eval!\"\n",
    "        fused_conv = copy.deepcopy(conv)\n",
    "\n",
    "        fused_conv.weight, fused_conv.bias = self._bn_folding(fused_conv.weight, fused_conv.bias,\n",
    "                                 bn.running_mean, bn.running_var, bn.eps, bn.weight, bn.bias)\n",
    "\n",
    "        return fused_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb9efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### BN_Folder.fold\n",
       "\n",
       ">      BN_Folder.fold (model)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### BN_Folder.fold\n",
       "\n",
       ">      BN_Folder.fold (model)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BN_Folder.fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d40e87",
   "metadata": {},
   "source": [
    "A tutorial about how to use the `BN_Folder` functionalities can be found [here](https://nathanhubens.github.io/fasterai/tutorial.bn_folding.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
