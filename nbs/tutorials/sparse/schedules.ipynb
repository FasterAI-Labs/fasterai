{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7a3bd9e5",
   "metadata": {},
   "source": [
    "---\n",
    "description: Make your neural network sparse with fastai\n",
    "output-file: tutorial.schedules.html\n",
    "title: Schedules\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-night",
   "metadata": {},
   "source": [
    "Neural Network Pruning usually follows one of the next 3 schedules:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-shannon",
   "metadata": {},
   "source": [
    "![](../../imgs/schedules.png \"Schedules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-fusion",
   "metadata": {},
   "source": [
    "In fasterai, all those 3 schedules can be applied from the **same** callback. We'll cover each below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2339b363",
   "metadata": {},
   "source": [
    "In the SparsifyCallback, there are several parameters to 'shape' our pruning schedule:\n",
    "* `start_sparsity`: the initial sparsity of our model, generally kept at 0 as after initialization, our weights are generally non-zero.\n",
    "* `end_sparsity`: the target sparsity at the end of the training \n",
    "* `start_epoch`: we can decide to start pruning right from the beginning or let it train a bit before removing weights.\n",
    "* `sched_func`: this is where the general shape of the schedule is specified as it specifies how the sparsity evolves along the training. You can either use a schedule [available](https://docs.fast.ai/callback.schedule.html#Annealing) in fastai our even coming with your own !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-sherman",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-miller",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/miniconda3/envs/dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "from fasterai.sparse.all import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(context='poster', style='white',\n",
    "        font='sans-serif', font_scale=1, color_codes=True, rc=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-passing",
   "metadata": {},
   "source": [
    "We will first train a network without any pruning, which will serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdb98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.696587</td>\n",
       "      <td>0.398289</td>\n",
       "      <td>0.858593</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.446161</td>\n",
       "      <td>0.596597</td>\n",
       "      <td>0.841001</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.311823</td>\n",
       "      <td>0.447651</td>\n",
       "      <td>0.788904</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.221294</td>\n",
       "      <td>0.325151</td>\n",
       "      <td>0.882273</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.168570</td>\n",
       "      <td>0.210183</td>\n",
       "      <td>0.914073</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.113579</td>\n",
       "      <td>0.247422</td>\n",
       "      <td>0.916103</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.092339</td>\n",
       "      <td>0.213218</td>\n",
       "      <td>0.924899</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.059152</td>\n",
       "      <td>0.182308</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.030035</td>\n",
       "      <td>0.190679</td>\n",
       "      <td>0.939784</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019936</td>\n",
       "      <td>0.190289</td>\n",
       "      <td>0.939107</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()\n",
    "\n",
    "learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-passion",
   "metadata": {},
   "source": [
    "## One-Shot Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-reset",
   "metadata": {},
   "source": [
    "The simplest way to perform pruning is called One-Shot Pruning. It consists of the following three steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-ceremony",
   "metadata": {},
   "source": [
    "1. You first need to train a network\n",
    "2. You then need to remove some weights (depending on your criteria, needs,...)\n",
    "3. You fine-tune the remaining weights to recover from the loss of parameters.\n",
    "\n",
    "With fasterai, this is really easy to do. Let's illustrate it by an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-entry",
   "metadata": {},
   "source": [
    "In this case, your network needs to be trained before pruning. This training can be done independently from the pruning callback, or simulated by the `start_epoch` that will delay the pruning process.\n",
    "\n",
    "You thus only need to create the Callback with the `one_shot` schedule and set the `start_epoch` argument, i.e. how many epochs you want to train your network before pruning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=90, granularity='weight', context='local', criteria=large_final, schedule=one_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-panama",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of [90]%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='6' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.00% [6/10 00:12&lt;00:08]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.584210</td>\n",
       "      <td>0.401200</td>\n",
       "      <td>0.826116</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.357988</td>\n",
       "      <td>0.349748</td>\n",
       "      <td>0.841678</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.254447</td>\n",
       "      <td>0.250878</td>\n",
       "      <td>0.895129</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.206469</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0.872801</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.223192</td>\n",
       "      <td>0.402789</td>\n",
       "      <td>0.841678</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.254638</td>\n",
       "      <td>0.253465</td>\n",
       "      <td>0.886333</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/92 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: [0.0]%\n",
      "Sparsity at the end of epoch 1: [0.0]%\n",
      "Sparsity at the end of epoch 2: [0.0]%\n",
      "Sparsity at the end of epoch 3: [0.0]%\n",
      "Sparsity at the end of epoch 4: [90.0]%\n",
      "Sparsity at the end of epoch 5: [90.0]%\n"
     ]
    }
   ],
   "source": [
    "learn.fit(10, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-channels",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-simon",
   "metadata": {},
   "source": [
    "## Iterative Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-indonesia",
   "metadata": {},
   "source": [
    "Researchers have come up with a better way to do pruning than pruning all the weigths in once (as in One-Shot Pruning). The idea is to perform several iterations of pruning and fine-tuning and is thus called Iterative Pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-symphony",
   "metadata": {},
   "source": [
    "1. You first need to train a network\n",
    "2. You then need to remove a part of the weights weights (depending on your criteria, needs,...)\n",
    "3. You fine-tune the remaining weights to recover from the loss of parameters.\n",
    "4. Back to step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-peeing",
   "metadata": {},
   "source": [
    "In this case, your network needs to be trained before pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-parent",
   "metadata": {},
   "source": [
    "You only need to create the Callback with the `iterative` schedule and set the `start_epoch` argument, i.e. how many epochs you want to train your network before pruning it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-authority",
   "metadata": {},
   "source": [
    "The `iterative` schedules has a `n_steps`parameter, i.e. how many iterations of pruning/fine-tuning you want to perform. To modify its value, we can use the `partial` function like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-friday",
   "metadata": {},
   "source": [
    "```\n",
    "iterative = partial(iterative, n_steps=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=90, granularity='weight', context='local', criteria=large_final, schedule=iterative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-sullivan",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-edition",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-conditioning",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-detail",
   "metadata": {},
   "source": [
    "## Gradual Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9763a794",
   "metadata": {},
   "source": [
    "Here is for example how to implement the [Automated Gradual Pruning](https://arxiv.org/pdf/1710.01878.pdf) schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-navigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=90, granularity='weight', context='local', criteria=large_final, schedule=agp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-dispute",
   "metadata": {},
   "source": [
    "Let's start pruning after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(10, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-backup",
   "metadata": {},
   "source": [
    "Even though they are often considered as different pruning methods, those 3 schedules can be captured by the same Callback. Here is how the sparsity in the network evolves for those methods;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-preparation",
   "metadata": {},
   "source": [
    "Let's take an example here. Let's say that we want to train our network for 3 epochs without pruning and then 7 epochs with pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "train = np.zeros(300)\n",
    "prune = np.linspace(0,1, 700) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-mapping",
   "metadata": {},
   "source": [
    "Then this is what our different pruning schedules will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8,5), dpi=100)\n",
    "fig.patch.set_alpha(0.)\n",
    "ax.patch.set_alpha(0.)\n",
    "plt.plot(np.concatenate([train, sched_iterative(0,90, prune)]), label='Iterative', linestyle='-.', c='#89d6c9')\n",
    "plt.plot(np.concatenate([train, [sched_oneshot(0,90, p) for p in prune]]), label='One-Shot', linestyle=':', c='#89d6c9')\n",
    "plt.plot(np.concatenate([train, sched_agp(0,90, prune)]), label='Gradual', c='#89d6c9')\n",
    "ax.spines['bottom'].set_color('#808080')\n",
    "ax.spines['top'].set_color('#808080') \n",
    "ax.spines['right'].set_color('#808080')\n",
    "ax.spines['left'].set_color('#808080')\n",
    "ax.tick_params(axis='x', colors='#808080')\n",
    "ax.tick_params(axis='y', colors='#808080')\n",
    "ax.yaxis.label.set_color('#808080')\n",
    "ax.xaxis.label.set_color('#808080')\n",
    "plt.legend(framealpha=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-nudist",
   "metadata": {},
   "source": [
    "**You can also come up with your own pruning schedule !**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
