{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08159415",
   "metadata": {},
   "source": [
    "---\n",
    "description: Use the sparsifier in fastai Callback system\n",
    "output-file: tutorial.sparsify_callback.html\n",
    "title: Sparsify Callback\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1749ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qc9w2hlgtd",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Sparsification** sets individual weights to zero during training, creating sparse networks that can be more efficient for inference. Unlike structured pruning (which removes entire filters), sparsification maintains the original architecture while introducing zeros.\n",
    "\n",
    "### Why Use Sparsification?\n",
    "\n",
    "| Approach | What's Removed | Architecture | Hardware Support |\n",
    "|----------|----------------|--------------|------------------|\n",
    "| **Sparsification** | Individual weights | Unchanged | Sparse accelerators |\n",
    "| Structured Pruning | Entire filters/channels | Changed | Standard hardware |\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "- **Gradual sparsity** - Weights are progressively zeroed during training\n",
    "- **Maintained accuracy** - Network adapts to sparsity during training\n",
    "- **Flexible targeting** - Choose which layers and how much to sparsify\n",
    "- **Schedule control** - Use one-cycle, cosine, or custom schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fasterai.sparse.all import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yjqwox6h64h",
   "metadata": {},
   "source": [
    "## 1. Setup and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c13f6",
   "metadata": {},
   "source": [
    "## 2. Baseline: Dense Model\n",
    "\n",
    "First, let's train a standard dense model to establish baseline accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90051f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.732612</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.839648</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.394582</td>\n",
       "      <td>0.260210</td>\n",
       "      <td>0.887686</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218636</td>\n",
       "      <td>0.235590</td>\n",
       "      <td>0.907307</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.118740</td>\n",
       "      <td>0.200626</td>\n",
       "      <td>0.922869</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078772</td>\n",
       "      <td>0.187712</td>\n",
       "      <td>0.922869</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4aa2b",
   "metadata": {},
   "source": [
    "## 3. Training with SparsifyCallback\n",
    "\n",
    "Now let's train with 50% sparsity. The `SparsifyCallback` gradually introduces zeros during training according to the specified schedule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1821ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f373da5",
   "metadata": {},
   "source": [
    "The callback requires a `schedule` parameter that controls how sparsity increases over training. You can use any [fastai annealing function](https://docs.fast.ai/callback.schedule.html#Annealing) or define your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb = SparsifyCallback(sparsity=50, granularity='weight', context='local', criteria=large_final, schedule=one_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3044be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 50%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.662926</td>\n",
       "      <td>1.296763</td>\n",
       "      <td>0.810555</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.376402</td>\n",
       "      <td>0.278251</td>\n",
       "      <td>0.883627</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243227</td>\n",
       "      <td>0.213432</td>\n",
       "      <td>0.911367</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130433</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>0.930311</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.079553</td>\n",
       "      <td>0.165558</td>\n",
       "      <td>0.934371</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 1.96%\n",
      "Sparsity at the end of epoch 1: 20.07%\n",
      "Sparsity at the end of epoch 2: 45.86%\n",
      "Sparsity at the end of epoch 3: 49.74%\n",
      "Sparsity at the end of epoch 4: 50.00%\n",
      "Final Sparsity: 50.00%\n",
      "\n",
      "Sparsity Report:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer                          Type            Params     Zeros      Sparsity  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0                            Conv2d          9,408      4,704         50.00%\n",
      "0.4.0.conv1                    Conv2d          36,864     18,432        50.00%\n",
      "0.4.0.conv2                    Conv2d          36,864     18,432        50.00%\n",
      "0.4.1.conv1                    Conv2d          36,864     18,432        50.00%\n",
      "0.4.1.conv2                    Conv2d          36,864     18,432        50.00%\n",
      "0.5.0.conv1                    Conv2d          73,728     36,864        50.00%\n",
      "0.5.0.conv2                    Conv2d          147,456    73,727        50.00%\n",
      "0.5.0.downsample.0             Conv2d          8,192      4,096         50.00%\n",
      "0.5.1.conv1                    Conv2d          147,456    73,727        50.00%\n",
      "0.5.1.conv2                    Conv2d          147,456    73,727        50.00%\n",
      "0.6.0.conv1                    Conv2d          294,912    147,455       50.00%\n",
      "0.6.0.conv2                    Conv2d          589,824    294,909       50.00%\n",
      "0.6.0.downsample.0             Conv2d          32,768     16,384        50.00%\n",
      "0.6.1.conv1                    Conv2d          589,824    294,909       50.00%\n",
      "0.6.1.conv2                    Conv2d          589,824    294,909       50.00%\n",
      "0.7.0.conv1                    Conv2d          1,179,648  589,818       50.00%\n",
      "0.7.0.conv2                    Conv2d          2,359,296  1,179,637     50.00%\n",
      "0.7.0.downsample.0             Conv2d          131,072    65,535        50.00%\n",
      "0.7.1.conv1                    Conv2d          2,359,296  1,179,637     50.00%\n",
      "0.7.1.conv2                    Conv2d          2,359,296  1,179,637     50.00%\n",
      "--------------------------------------------------------------------------------\n",
      "Overall                        all             11,166,912 5,583,403     50.00%\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0077b",
   "metadata": {},
   "source": [
    "Despite having 50% of weights set to zero, the sparse model performs comparably to the dense baseline!\n",
    "\n",
    "## 3b. Per-Layer Sparsity\n",
    "\n",
    "Different layers have different sensitivities to sparsification. Early layers often need more weights to preserve low-level features, while deeper layers can tolerate higher sparsity. You can specify per-layer targets using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46n84nke18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different sparsity targets for different layers\n",
    "per_layer_sparsity = {\n",
    "    '0.4.0.conv1': 30,   # Early layers: lower sparsity (more sensitive)\n",
    "    '0.4.0.conv2': 30,\n",
    "    '0.4.1.conv1': 30,\n",
    "    '0.4.1.conv2': 30,\n",
    "    '0.5.0.conv1': 50,   # Middle layers: medium sparsity\n",
    "    '0.5.0.conv2': 50,\n",
    "    '0.5.1.conv1': 50,\n",
    "    '0.5.1.conv2': 50,\n",
    "    '0.6.0.conv1': 70,   # Deeper layers: higher sparsity (more redundant)\n",
    "    '0.6.0.conv2': 70,\n",
    "    '0.6.1.conv1': 70,\n",
    "    '0.6.1.conv2': 70,\n",
    "    '0.7.0.conv1': 80,   # Deepest layers: highest sparsity\n",
    "    '0.7.0.conv2': 80,\n",
    "    '0.7.1.conv1': 80,\n",
    "    '0.7.1.conv2': 80,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hsv25oaanju",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of {'0.4.0.conv1': 30, '0.4.0.conv2': 30, '0.4.1.conv1': 30, '0.4.1.conv2': 30, '0.5.0.conv1': 50, '0.5.0.conv2': 50, '0.5.1.conv1': 50, '0.5.1.conv2': 50, '0.6.0.conv1': 70, '0.6.0.conv2': 70, '0.6.1.conv1': 70, '0.6.1.conv2': 70, '0.7.0.conv1': 80, '0.7.0.conv2': 80, '0.7.1.conv1': 80, '0.7.1.conv2': 80}%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.702893</td>\n",
       "      <td>0.432825</td>\n",
       "      <td>0.829499</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.395077</td>\n",
       "      <td>0.314297</td>\n",
       "      <td>0.887010</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.229694</td>\n",
       "      <td>0.263221</td>\n",
       "      <td>0.892422</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132596</td>\n",
       "      <td>0.182942</td>\n",
       "      <td>0.930311</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.077698</td>\n",
       "      <td>0.172972</td>\n",
       "      <td>0.935724</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: avg=5.49%\n",
      "Sparsity at the end of epoch 1: avg=19.87%\n",
      "Sparsity at the end of epoch 2: avg=37.63%\n",
      "Sparsity at the end of epoch 3: avg=52.01%\n",
      "Sparsity at the end of epoch 4: avg=57.50%\n",
      "Final Sparsity: {'0.4.0.conv1': 30.0, '0.4.0.conv2': 30.0, '0.4.1.conv1': 30.0, '0.4.1.conv2': 30.0, '0.5.0.conv1': 50.0, '0.5.0.conv2': 50.0, '0.5.1.conv1': 50.0, '0.5.1.conv2': 50.0, '0.6.0.conv1': 70.0, '0.6.0.conv2': 70.0, '0.6.1.conv1': 70.0, '0.6.1.conv2': 70.0, '0.7.0.conv1': 80.0, '0.7.0.conv2': 80.0, '0.7.1.conv1': 80.0, '0.7.1.conv2': 80.0}\n",
      "\n",
      "Sparsity Report:\n",
      "--------------------------------------------------------------------------------\n",
      "Layer                          Type            Params     Zeros      Sparsity  \n",
      "--------------------------------------------------------------------------------\n",
      "0.0                            Conv2d          9,408      0              0.00%\n",
      "0.4.0.conv1                    Conv2d          36,864     11,059        30.00%\n",
      "0.4.0.conv2                    Conv2d          36,864     11,059        30.00%\n",
      "0.4.1.conv1                    Conv2d          36,864     11,059        30.00%\n",
      "0.4.1.conv2                    Conv2d          36,864     11,059        30.00%\n",
      "0.5.0.conv1                    Conv2d          73,728     36,864        50.00%\n",
      "0.5.0.conv2                    Conv2d          147,456    73,727        50.00%\n",
      "0.5.0.downsample.0             Conv2d          8,192      0              0.00%\n",
      "0.5.1.conv1                    Conv2d          147,456    73,727        50.00%\n",
      "0.5.1.conv2                    Conv2d          147,456    73,727        50.00%\n",
      "0.6.0.conv1                    Conv2d          294,912    206,436       70.00%\n",
      "0.6.0.conv2                    Conv2d          589,824    412,872       70.00%\n",
      "0.6.0.downsample.0             Conv2d          32,768     0              0.00%\n",
      "0.6.1.conv1                    Conv2d          589,824    412,872       70.00%\n",
      "0.6.1.conv2                    Conv2d          589,824    412,872       70.00%\n",
      "0.7.0.conv1                    Conv2d          1,179,648  943,709       80.00%\n",
      "0.7.0.conv2                    Conv2d          2,359,296  1,887,418     80.00%\n",
      "0.7.0.downsample.0             Conv2d          131,072    0              0.00%\n",
      "0.7.1.conv1                    Conv2d          2,359,296  1,887,418     80.00%\n",
      "0.7.1.conv2                    Conv2d          2,359,296  1,887,418     80.00%\n",
      "--------------------------------------------------------------------------------\n",
      "Overall                        all             11,166,912 8,353,296     74.80%\n"
     ]
    }
   ],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()\n",
    "\n",
    "# Use dict for per-layer sparsity - requires 'local' context\n",
    "sp_cb = SparsifyCallback(\n",
    "    sparsity=per_layer_sparsity, \n",
    "    granularity='weight', \n",
    "    context='local',  # Required for per-layer sparsity\n",
    "    criteria=large_final, \n",
    "    schedule=cos\n",
    ")\n",
    "\n",
    "learn.fit_one_cycle(5, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vry66tdv6ze",
   "metadata": {},
   "source": [
    "**Key points about per-layer sparsity:**\n",
    "\n",
    "- Use a **dict** mapping layer names to sparsity percentages\n",
    "- Requires `context='local'` (global context doesn't support non-uniform sparsity)\n",
    "- Layer names match those shown in the Sparsity Report (e.g., `'0.4.0.conv1'`)\n",
    "- Layers not in the dict are left dense (0% sparsity)\n",
    "- The schedule applies uniformly - all layers progress from 0% to their target together\n",
    "\n",
    "**Tip**: Use `learn.model` to explore layer names, or run a uniform sparsity first to see the Sparsity Report with all layer names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46323843",
   "metadata": {},
   "source": [
    "## 4. Parameter Reference\n",
    "\n",
    "### Core Parameters\n",
    "\n",
    "| Parameter | Description | Example |\n",
    "|-----------|-------------|---------|\n",
    "| `sparsity` | Target sparsity % (float or dict for per-layer) | `50` or `{'layer1': 30, 'layer2': 70}` |\n",
    "| `granularity` | Level of sparsification | `'weight'`, `'vector'`, `'kernel'`, `'filter'` |\n",
    "| `context` | How to compute importance | `'local'` (per-layer) or `'global'` (whole model) |\n",
    "| `criteria` | Importance measure | `large_final`, `small_final`, `magnitude` |\n",
    "| `schedule` | How sparsity increases over training | `one_cycle`, `cos`, `lin` |\n",
    "\n",
    "### Advanced Parameters\n",
    "\n",
    "| Parameter | Description |\n",
    "|-----------|-------------|\n",
    "| `lth` | Enable Lottery Ticket Hypothesis (reset weights after pruning) |\n",
    "| `rewind_epoch` | Epoch to rewind weights to (for LTH) |\n",
    "| `reset_end` | Reset weights to original values after training |\n",
    "| `save_tickets` | Save intermediate winning tickets |\n",
    "| `model` | Apply to specific submodule instead of whole model |\n",
    "| `round_to` | Round sparsity to nearest multiple |\n",
    "| `layer_type` | Type of layers to sparsify (default: `nn.Conv2d`) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39090448",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Sparsification** | Setting individual weights to zero while maintaining architecture |\n",
    "| **SparsifyCallback** | fastai callback for gradual sparsification during training |\n",
    "| **Schedule** | Controls how sparsity increases over training (`one_cycle`, `cos`, etc.) |\n",
    "| **Per-layer sparsity** | Different sparsity targets for different layers |\n",
    "| **Typical result** | 50%+ sparsity with minimal accuracy loss |\n",
    "\n",
    "---\n",
    "\n",
    "## See Also\n",
    "\n",
    "- [Sparsifier](../../sparse/sparsifier.html) - Lower-level API for one-shot sparsification\n",
    "- [Schedules](../../core/schedules.html) - Available sparsity schedules\n",
    "- [Criteria](../../core/criteria.html) - Weight importance measures\n",
    "- [Lottery Ticket Tutorial](lottery_ticket.html) - Using LTH with sparsification\n",
    "- [Pruner](../../prune/pruner.html) - For structured pruning (removing entire filters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
