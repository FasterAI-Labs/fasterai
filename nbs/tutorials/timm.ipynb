{
 "cells": [
  {
   "cell_type": "raw",
   "id": "685b253e-fd46-462e-a53c-46acd3ffad50",
   "metadata": {},
   "source": [
    "---\n",
    "description: TIMM Pruning\n",
    "output-file: timm_pruning.html\n",
    "title: TIMM Pruning\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0835765a-6022-4896-b04a-86993a3c628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fasterai.core.criteria import *\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "import torch_pruning as tp\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b587a-93c6-47cd-8ca7-0c73245c1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onecycle_scheduler(pruning_ratio_dict, steps, start=0, end=1, α=14, β=6):\n",
    "    return [\n",
    "        sched_onecycle(start, end, i / float(steps), α, β) * pruning_ratio_dict\n",
    "        for i in range(steps + 1)\n",
    "    ]\n",
    "\n",
    "def sched_onecycle(start, end, pos, α=14, β=6):\n",
    "    out = (1 + np.exp(-α + β)) / (1 + np.exp((-α * pos) + β))\n",
    "    return start + (end - start) * out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55f136c-16fb-442a-be21-f572f692c7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1725a08-aecf-4253-a0bc-f1d754bbf3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(size, bs):\n",
    "    path = URLs.IMAGENETTE_160\n",
    "    source = untar_data(path)\n",
    "    blocks=(ImageBlock, CategoryBlock)\n",
    "    tfms = [RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)]\n",
    "    batch_tfms = [Normalize.from_stats(*imagenet_stats)]\n",
    "\n",
    "    csv_file = 'noisy_imagenette.csv'\n",
    "    inp = pd.read_csv(source/csv_file)\n",
    "    dblock = DataBlock(blocks=blocks,\n",
    "               splitter=ColSplitter(),\n",
    "               get_x=ColReader('path', pref=source),\n",
    "               get_y=ColReader(f'noisy_labels_0'),\n",
    "               item_tfms=tfms,\n",
    "               batch_tfms=batch_tfms)\n",
    "\n",
    "    return dblock.dataloaders(inp, path=source, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea31be-e73f-43d9-b3bb-c0e8b986e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet18', pretrained=False, no_jit=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b51141b-56d1-4df7-b287-1ae464647804",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(model.default_cfg['input_size'][2], 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f8edb7-d2de-4bef-9a00-5db38ac60ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Attention layer:  Linear(in_features=768, out_features=2304, bias=False) 12\n",
      "Ignore classifier layer:  Linear(in_features=768, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "#learn = vision_learner(dls, 'bat_resnext26ts', metrics = [accuracy])\n",
    "#learn.unfreeze()\n",
    "\n",
    "model = timm.create_model('beit_base_patch16_224', pretrained=False, no_jit=True).eval()\n",
    "\n",
    "ignored_layers = []\n",
    "num_heads = {}\n",
    "pruning_ratio_dict = {}\n",
    "#ratios = [0.265625,0.234375,0.265625,0.265625,0.93359375,0.328125,0.2265625,0.58984375,0.54296875,0.701171875,0.919921875,0.04296875,0.796875,0.240966796875,0.07763671875]\n",
    "\n",
    "\n",
    "#k = 0\n",
    "for m in model.modules():\n",
    "    #if hasattr(m, 'head'): #isinstance(m, nn.Linear) and m.out_features == model.num_classes:\n",
    "    if isinstance(m, nn.Linear) and m.out_features == model.num_classes:\n",
    "        ignored_layers.append(m)\n",
    "        print(\"Ignore classifier layer: \", m)\n",
    "\n",
    "    # Attention layers\n",
    "    if hasattr(m, 'num_heads'):\n",
    "        if hasattr(m, 'qkv'):\n",
    "            num_heads[m.qkv] = m.num_heads\n",
    "            print(\"Attention layer: \", m.qkv, m.num_heads)\n",
    "        elif hasattr(m, 'qkv_proj'):\n",
    "            num_heads[m.qkv_proj] = m.num_heads\n",
    "    \n",
    "    #elif isinstance(m, nn.Conv2d):\n",
    "    #    pruning_ratio_dict[m] = ratios[k]\n",
    "    #    print(k)\n",
    "    #    k+=1\n",
    "\n",
    "learn = Learner(dls, model, metrics = [accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45775057-7ee9-4c39-9ee6-b756865aa349",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xb, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdls\u001b[49m\u001b[38;5;241m.\u001b[39mone_batch()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dls' is not defined"
     ]
    }
   ],
   "source": [
    "xb, _ = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8324b-22c9-4045-904d-6fa0207f6e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.302582</td>\n",
       "      <td>1.146651</td>\n",
       "      <td>0.622166</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.953016</td>\n",
       "      <td>0.809723</td>\n",
       "      <td>0.741147</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.828404</td>\n",
       "      <td>0.692629</td>\n",
       "      <td>0.775796</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d3226-cb67-4ca0-916d-109c2cbbe235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HubensN/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch_pruning/dependency.py:697: UserWarning: Unwrapped parameters detected: ['cls_token', 'blocks.1.attn.v_bias', 'blocks.6.attn.relative_position_bias_table', 'blocks.0.attn.v_bias', 'blocks.3.gamma_2', 'blocks.3.attn.q_bias', 'blocks.4.attn.relative_position_bias_table', 'blocks.5.attn.relative_position_bias_table', 'blocks.9.gamma_2', 'blocks.9.attn.q_bias', 'blocks.11.attn.relative_position_bias_table', 'blocks.2.attn.relative_position_bias_table', 'blocks.4.gamma_2', 'blocks.6.attn.q_bias', 'blocks.7.attn.q_bias', 'blocks.7.attn.relative_position_bias_table', 'blocks.9.attn.v_bias', 'blocks.10.gamma_2', 'blocks.10.attn.relative_position_bias_table', 'blocks.0.attn.q_bias', 'blocks.0.attn.relative_position_bias_table', 'blocks.1.gamma_2', 'blocks.4.attn.q_bias', 'blocks.8.attn.q_bias', 'blocks.8.attn.v_bias', 'blocks.10.attn.q_bias', 'blocks.11.gamma_1', 'blocks.11.gamma_2', 'blocks.0.gamma_2', 'blocks.5.gamma_1', 'blocks.6.gamma_1', 'blocks.6.attn.v_bias', 'blocks.8.gamma_2', 'blocks.8.attn.relative_position_bias_table', 'blocks.3.gamma_1', 'blocks.0.gamma_1', 'blocks.1.attn.relative_position_bias_table', 'blocks.2.gamma_1', 'blocks.3.attn.relative_position_bias_table', 'blocks.9.attn.relative_position_bias_table', 'blocks.11.attn.v_bias', 'blocks.1.gamma_1', 'blocks.2.attn.v_bias', 'blocks.3.attn.v_bias', 'blocks.4.attn.v_bias', 'blocks.5.gamma_2', 'blocks.5.attn.v_bias', 'blocks.7.attn.v_bias', 'blocks.10.gamma_1', 'blocks.10.attn.v_bias', 'blocks.11.attn.q_bias', 'blocks.1.attn.q_bias', 'blocks.2.gamma_2', 'blocks.2.attn.q_bias', 'blocks.4.gamma_1', 'blocks.5.attn.q_bias', 'blocks.6.gamma_2', 'blocks.7.gamma_1', 'blocks.7.gamma_2', 'blocks.8.gamma_1', 'blocks.9.gamma_1'].\n",
      " Torch-Pruning will prune the last non-singleton dimension of these parameters. If you wish to change this behavior, please provide an unwrapped_parameters argument.\n",
      "  warnings.warn(warning_str)\n"
     ]
    }
   ],
   "source": [
    "pruner = tp.pruner.MetaPruner(\n",
    "                        model, \n",
    "                        xb.to('cpu'), \n",
    "                        global_pruning=False,\n",
    "                        importance=tp.importance.GroupNormImportance(), \n",
    "                        iterative_steps=10000,\n",
    "                        pruning_ratio=0.5,\n",
    "                        #pruning_ratio_dict=pruning_ratio_dict,\n",
    "                        num_heads=num_heads,\n",
    "                        ignored_layers=ignored_layers,\n",
    "                    )\n",
    "#for g in pruner.step(interactive=True):\n",
    "#    g.prune()\n",
    "pruner.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44332be1-c236-4da3-9d31-b07d8d52a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    # Attention layers\n",
    "    if hasattr(m, 'num_heads'):\n",
    "        if hasattr(m, 'qkv'):\n",
    "            m.num_heads = num_heads[m.qkv]\n",
    "            m.head_dim = m.qkv.out_features // (3 * m.num_heads)\n",
    "        elif hasattr(m, 'qkv_proj'):\n",
    "            m.num_heads = num_heads[m.qqkv_projkv]\n",
    "            m.head_dim = m.qkv_proj.out_features // (3 * m.num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef09402-e838-4358-9f1c-079512227a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_old = timm.create_model('convnext_xxlarge', pretrained=False, no_jit=True).eval()\n",
    "base_macs, base_params = tp.utils.count_ops_and_params(model_old, xb.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbdc44-abfb-4cdb-bef1-61b5053cfccb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3152x767 and 768x2304)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pruned_macs, pruned_params \u001b[38;5;241m=\u001b[39m \u001b[43mtp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_ops_and_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch_pruning/utils/op_counter.py:35\u001b[0m, in \u001b[0;36mcount_ops_and_params\u001b[0;34m(model, example_inputs, layer_wise)\u001b[0m\n\u001b[1;32m     33\u001b[0m     _ \u001b[38;5;241m=\u001b[39m flops_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexample_inputs)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 35\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mflops_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m flops_count, params_count, _layer_flops, _layer_params \u001b[38;5;241m=\u001b[39m flops_model\u001b[38;5;241m.\u001b[39mcompute_average_flops_cost()\n\u001b[1;32m     37\u001b[0m layer_flops \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1603\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1600\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1601\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1603\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1605\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1607\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1608\u001b[0m     ):\n\u001b[1;32m   1609\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/timm/models/beit.py:521\u001b[0m, in \u001b[0;36mBeit.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 521\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/timm/models/beit.py:509\u001b[0m, in \u001b[0;36mBeit.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    507\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint(blk, x, shared_rel_pos_bias\u001b[38;5;241m=\u001b[39mrel_pos_bias)\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_rel_pos_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrel_pos_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/timm/models/beit.py:248\u001b[0m, in \u001b[0;36mBlock.forward\u001b[0;34m(self, x, shared_rel_pos_bias)\u001b[0m\n\u001b[1;32m    246\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)))\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_1 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_rel_pos_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshared_rel_pos_bias\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    249\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma_2 \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x)))\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/timm/models/beit.py:149\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, x, shared_rel_pos_bias)\u001b[0m\n\u001b[1;32m    147\u001b[0m         qkv \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m qkv_bias\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m         qkv \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqkv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqkv_bias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m qkv \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    151\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# B, num_heads, N, head_dim\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/fastai/torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 382\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/_tensor.py:1437\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1436\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1437\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1439\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3152x767 and 768x2304)"
     ]
    }
   ],
   "source": [
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(model, xb.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb10d6d0-638c-4a41-a1ca-35e2111389aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 151.5881 G => 7.0919 G\n",
      "Params: 846.4710 M => 58.2010 M\n"
     ]
    }
   ],
   "source": [
    "print(\"MACs: %.4f G => %.4f G\"%(base_macs/1e9, pruned_macs/1e9))\n",
    "print(\"Params: %.4f M => %.4f M\"%(base_params/1e6, pruned_params/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574790ea-cc63-4af4-87f6-1df0401b6ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d73804-57f7-4109-ac4c-f770bab6f1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466a3b2b-1335-4f1f-aa4d-99d372018100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17945b76-2228-45e7-9742-725a67f198bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7255784-1329-4691-890e-566adc45ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruneCallback(Callback):\n",
    "    def __init__(self, pruning_ratio, schedule, criteria, ignored_layers, *args, **kwargs):\n",
    "        store_attr()\n",
    "        self.sparsity_levels = []\n",
    "        self.extra_args = args\n",
    "        self.extra_kwargs = kwargs\n",
    "\n",
    "    def before_fit(self):\n",
    "        n_batches_per_epoch = len(self.learn.dls.train)\n",
    "        total_training_steps = n_batches_per_epoch * self.learn.n_epoch\n",
    "\n",
    "        self.total_training_steps = total_training_steps \n",
    "        print(self.total_training_steps)\n",
    "        self.example_inputs, _ = self.learn.dls.one_batch()\n",
    "        self.sparsity_levels = self.schedule(self.pruning_ratio, total_training_steps)\n",
    "\n",
    "        self.pruner = tp.pruner.MetaPruner(\n",
    "        self.learn.model,\n",
    "        example_inputs= torch.randn(self.example_inputs.shape).to('cuda:0'),\n",
    "        importance=self.criteria,\n",
    "        pruning_ratio=self.pruning_ratio, \n",
    "        ignored_layers=self.ignored_layers,\n",
    "        iterative_steps= self.total_training_steps, \n",
    "        #iterative_steps= 1, \n",
    "        #iterative_pruning_ratio_scheduler=self.schedule,\n",
    "        #global_pruning=self.context, \n",
    "        *self.extra_args, \n",
    "        **self.extra_kwargs\n",
    "        )\n",
    "        \n",
    "    def before_step(self):\n",
    "        if self.training: \n",
    "           #self.pruner.step()\n",
    "            for g in self.pruner.step(interactive=True):\n",
    "                g.prune()\n",
    "            \n",
    "        #for m in self.pruner.model.modules():\n",
    "        #    # Attention layers\n",
    "        #    if hasattr(m, 'num_heads'):\n",
    "        #        if hasattr(m, 'qkv'):\n",
    "        #            m.num_heads = num_heads[m.qkv]\n",
    "        #            m.head_dim = m.qkv.out_features // (3 * m.num_heads)\n",
    "        #        elif hasattr(m, 'qkv_proj'):\n",
    "        #            m.num_heads = num_heads[m.qqkv_projkv]\n",
    "        #            m.head_dim = m.qkv_proj.out_features // (3 * m.num_heads)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        completed_steps = (self.epoch + 1) * len(self.learn.dls.train)\n",
    "        current_sparsity = self.sparsity_levels[completed_steps - 1]\n",
    "        print(f'Sparsity at the end of epoch {self.epoch}: {current_sparsity*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f177c932-caff-4671-aac4-5aeef5e509ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2695c9-8d0e-4a10-898c-8be84317f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore classifier layer:  Linear(in_features=512, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model('resnet18', pretrained=True, no_jit=True).eval()\n",
    "\n",
    "ignored_layers = []\n",
    "num_heads = {}\n",
    "\n",
    "#k = 0\n",
    "for m in model.modules():\n",
    "    if isinstance(m, nn.Linear) and m.out_features == model.num_classes:\n",
    "        ignored_layers.append(m)\n",
    "        print(\"Ignore classifier layer: \", m)\n",
    "\n",
    "    # Attention layers\n",
    "    if hasattr(m, 'num_heads'):\n",
    "        if hasattr(m, 'qkv'):\n",
    "            num_heads[m.qkv] = m.num_heads\n",
    "            print(\"Attention layer: \", m.qkv, m.num_heads)\n",
    "        elif hasattr(m, 'qkv_proj'):\n",
    "            num_heads[m.qkv_proj] = m.num_heads\n",
    "\n",
    "learn = Learner(dls, model, metrics = [accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c13b65-ebad-4468-b79b-d898fd76573b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.291440</td>\n",
       "      <td>0.907771</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378970</td>\n",
       "      <td>0.237411</td>\n",
       "      <td>0.920764</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.254743</td>\n",
       "      <td>0.161710</td>\n",
       "      <td>0.946752</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.195507</td>\n",
       "      <td>0.142778</td>\n",
       "      <td>0.954395</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.124310</td>\n",
       "      <td>0.112485</td>\n",
       "      <td>0.965350</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb5235e-e3a1-4173-b476-c5f9eeb9cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5910\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      40.00% [4/10 00:58&lt;01:27]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.190778</td>\n",
       "      <td>0.223286</td>\n",
       "      <td>0.929172</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.906825</td>\n",
       "      <td>0.996437</td>\n",
       "      <td>0.685605</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.154549</td>\n",
       "      <td>2.038115</td>\n",
       "      <td>0.295796</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.019212</td>\n",
       "      <td>1.988954</td>\n",
       "      <td>0.316688</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='165' class='' max='591' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      27.92% [165/591 00:03&lt;00:09 2.0123]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.25%\n",
      "Sparsity at the end of epoch 1: 0.98%\n",
      "Sparsity at the end of epoch 2: 3.54%\n",
      "Sparsity at the end of epoch 3: 10.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr_cb = PruneCallback(pruning_ratio=0.25, schedule=onecycle_scheduler, global_pruning=True, criteria=tp.importance.GroupNormImportance(normalizer=None, target_types=[nn.modules.conv._ConvNd, nn.Linear]), num_heads=num_heads, ignored_layers=ignored_layers)\n",
    "learn.fit_one_cycle(10, 1e-4, cbs=pr_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392dfe2-e7cc-439c-bfed-6e67200be32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96bd5f-c2d9-408d-8daf-f2dace590cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.118367</td>\n",
       "      <td>0.963057</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.128137</td>\n",
       "      <td>0.115662</td>\n",
       "      <td>0.962038</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122357</td>\n",
       "      <td>0.126387</td>\n",
       "      <td>0.960255</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142834</td>\n",
       "      <td>0.112623</td>\n",
       "      <td>0.966115</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.124087</td>\n",
       "      <td>0.115061</td>\n",
       "      <td>0.964076</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.134429</td>\n",
       "      <td>0.125728</td>\n",
       "      <td>0.960510</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.128918</td>\n",
       "      <td>0.143516</td>\n",
       "      <td>0.954650</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.131373</td>\n",
       "      <td>0.176553</td>\n",
       "      <td>0.958217</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.135654</td>\n",
       "      <td>0.177501</td>\n",
       "      <td>0.954395</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180335</td>\n",
       "      <td>0.197476</td>\n",
       "      <td>0.946497</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.207450</td>\n",
       "      <td>0.194991</td>\n",
       "      <td>0.935796</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.233158</td>\n",
       "      <td>0.203113</td>\n",
       "      <td>0.937325</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.231163</td>\n",
       "      <td>0.219680</td>\n",
       "      <td>0.932484</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.314865</td>\n",
       "      <td>0.245912</td>\n",
       "      <td>0.926369</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.311438</td>\n",
       "      <td>0.276028</td>\n",
       "      <td>0.922038</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.16%\n",
      "Sparsity at the end of epoch 1: 0.39%\n",
      "Sparsity at the end of epoch 2: 0.98%\n",
      "Sparsity at the end of epoch 3: 2.35%\n",
      "Sparsity at the end of epoch 4: 5.21%\n",
      "Sparsity at the end of epoch 5: 10.03%\n",
      "Sparsity at the end of epoch 6: 15.75%\n",
      "Sparsity at the end of epoch 7: 20.31%\n",
      "Sparsity at the end of epoch 8: 22.93%\n",
      "Sparsity at the end of epoch 9: 24.15%\n",
      "Sparsity at the end of epoch 10: 24.66%\n",
      "Sparsity at the end of epoch 11: 24.87%\n",
      "Sparsity at the end of epoch 12: 24.95%\n",
      "Sparsity at the end of epoch 13: 24.99%\n",
      "Sparsity at the end of epoch 14: 25.00%\n"
     ]
    }
   ],
   "source": [
    "pr_cb = PruneCallback(pruning_ratio=0.25, schedule=onecycle_scheduler, global_pruning=True, criteria=GroupNormImportance(normalizer=None, target_types=[nn.modules.conv._ConvNd, nn.Linear]), num_heads=num_heads, ignored_layers=ignored_layers)\n",
    "learn.fit_one_cycle(15, 1e-4, cbs=pr_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab7cdc-c14e-48a0-be7c-629f3bdf1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('tf_efficientnet_b3', pretrained=False, no_jit=True).eval()\n",
    "base_macs, base_params = tp.utils.count_ops_and_params(model, xb.to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff1b898-a769-40e7-8d9f-d6fdbadb8e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(learn.model, xb.to('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f0e372-302a-4287-a7b9-80d19171dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACs: 0.9399 G => 0.5407 G\n",
      "Params: 12.2332 M => 7.2501 M\n"
     ]
    }
   ],
   "source": [
    "print(\"MACs: %.4f G => %.4f G\"%(base_macs/1e9, pruned_macs/1e9))\n",
    "print(\"Params: %.4f M => %.4f M\"%(base_params/1e6, pruned_params/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb12d6f8-498d-405d-be61-4e982aa87b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ecc6c-1825-4458-a5a4-594a1e448953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dd4cfa-4a7f-414b-8514-36eab964da7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6555532a-e433-4774-a7a2-710b736b8a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299a495-675d-4bde-85ce-f922acf4a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import typing\n",
    "\n",
    "from torch_pruning import function\n",
    "from torch_pruning.dependency import Group\n",
    "\n",
    "class Importance(abc.ABC):\n",
    "    \"\"\" Estimate the importance of a tp.Dependency.Group, and return an 1-D per-channel importance score.\n",
    "\n",
    "        It should accept a group as inputs, and return a 1-D tensor with the same length as the number of channels.\n",
    "        All groups must be pruned simultaneously and thus their importance should be accumulated across channel groups.\n",
    "\n",
    "        Example:\n",
    "            ```python\n",
    "            DG = tp.DependencyGraph().build_dependency(model, example_inputs=torch.randn(1,3,224,224)) \n",
    "            group = DG.get_pruning_group( model.conv1, tp.prune_conv_out_channels, idxs=[2, 6, 9] )    \n",
    "            scorer = MagnitudeImportance()    \n",
    "            imp_score = scorer(group)    \n",
    "            #imp_score is a 1-D tensor with length 3 for channels [2, 6, 9]  \n",
    "            min_score = imp_score.min() \n",
    "            ``` \n",
    "    \"\"\"\n",
    "    @abc.abstractclassmethod\n",
    "    def __call__(self, group: Group) -> torch.Tensor: \n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class GroupNormImportance(Importance):\n",
    "\n",
    "    def __init__(self, \n",
    "                 p: int=2, \n",
    "                 group_reduction: str=\"mean\", \n",
    "                 normalizer: str='mean', \n",
    "                 bias=False,\n",
    "                 target_types:list=[nn.modules.conv._ConvNd, nn.Linear, nn.modules.batchnorm._BatchNorm, nn.LayerNorm]):\n",
    "        self.p = p\n",
    "        self.group_reduction = group_reduction\n",
    "        self.normalizer = normalizer\n",
    "        self.target_types = target_types\n",
    "        self.bias = bias\n",
    "\n",
    "    def _lamp(self, scores): # Layer-adaptive Sparsity for the Magnitude-based Pruning\n",
    "        \"\"\"\n",
    "        Normalizing scheme for LAMP.\n",
    "        \"\"\"\n",
    "        # sort scores in an ascending order\n",
    "        sorted_scores,sorted_idx = scores.view(-1).sort(descending=False)\n",
    "        # compute cumulative sum\n",
    "        scores_cumsum_temp = sorted_scores.cumsum(dim=0)\n",
    "        scores_cumsum = torch.zeros(scores_cumsum_temp.shape,device=scores.device)\n",
    "        scores_cumsum[1:] = scores_cumsum_temp[:len(scores_cumsum_temp)-1]\n",
    "        # normalize by cumulative sum\n",
    "        sorted_scores /= (scores.sum() - scores_cumsum)\n",
    "        # tidy up and output\n",
    "        new_scores = torch.zeros(scores_cumsum.shape,device=scores.device)\n",
    "        new_scores[sorted_idx] = sorted_scores\n",
    "        \n",
    "        return new_scores.view(scores.shape)\n",
    "    \n",
    "    def _normalize(self, group_importance, normalizer):\n",
    "        if normalizer is None:\n",
    "            return group_importance\n",
    "        elif isinstance(normalizer, typing.Callable):\n",
    "            return normalizer(group_importance)\n",
    "        elif normalizer == \"sum\":\n",
    "            return group_importance / group_importance.sum()\n",
    "        elif normalizer == \"standarization\":\n",
    "            return (group_importance - group_importance.min()) / (group_importance.max() - group_importance.min()+1e-8)\n",
    "        elif normalizer == \"mean\":\n",
    "            return group_importance / group_importance.mean()\n",
    "        elif normalizer == \"max\":\n",
    "            return group_importance / group_importance.max()\n",
    "        elif normalizer == 'gaussian':\n",
    "            return (group_importance - group_importance.mean()) / (group_importance.std()+1e-8)\n",
    "        elif normalizer.startswith('sentinel'): # normalize the score with the k-th smallest element. e.g. sentinel_0.5 means median normalization\n",
    "            sentinel = float(normalizer.split('_')[1]) * len(group_importance)\n",
    "            sentinel = torch.argsort(group_importance, dim=0, descending=False)[int(sentinel)]\n",
    "            return group_importance / (group_importance[sentinel]+1e-8)\n",
    "        elif normalizer=='lamp':\n",
    "            return self._lamp(group_importance)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _reduce(self, group_imp: typing.List[torch.Tensor], group_idxs: typing.List[typing.List[int]]):\n",
    "        if len(group_imp) == 0: return group_imp\n",
    "        if self.group_reduction == 'prod':\n",
    "            reduced_imp = torch.ones_like(group_imp[0])\n",
    "        elif self.group_reduction == 'max':\n",
    "            reduced_imp = torch.ones_like(group_imp[0]) * -99999\n",
    "        else:\n",
    "            reduced_imp = torch.zeros_like(group_imp[0])\n",
    "\n",
    "        for i, (imp, root_idxs) in enumerate(zip(group_imp, group_idxs)):\n",
    "            imp = imp.to(reduced_imp.device)\n",
    "            if self.group_reduction == \"sum\" or self.group_reduction == \"mean\":\n",
    "                reduced_imp.scatter_add_(0, torch.tensor(root_idxs, device=imp.device), imp) # accumulated importance\n",
    "            elif self.group_reduction == \"max\": # keep the max importance\n",
    "                selected_imp = torch.index_select(reduced_imp, 0, torch.tensor(root_idxs, device=imp.device))\n",
    "                selected_imp = torch.maximum(input=selected_imp, other=imp)\n",
    "                reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), selected_imp)\n",
    "            elif self.group_reduction == \"prod\": # product of importance\n",
    "                selected_imp = torch.index_select(reduced_imp, 0, torch.tensor(root_idxs, device=imp.device))\n",
    "                torch.mul(selected_imp, imp, out=selected_imp)\n",
    "                reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), selected_imp)\n",
    "            elif self.group_reduction == 'first':\n",
    "                if i == 0:\n",
    "                    reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "            elif self.group_reduction == 'gate':\n",
    "                if i == len(group_imp)-1:\n",
    "                    reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "            elif self.group_reduction is None:\n",
    "                reduced_imp = torch.stack(group_imp, dim=0) # no reduction\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        \n",
    "        if self.group_reduction == \"mean\":\n",
    "            reduced_imp /= len(group_imp)\n",
    "        return reduced_imp\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, group: Group):\n",
    "        group_imp = []\n",
    "        group_idxs = []\n",
    "        # Iterate over all groups and estimate group importance\n",
    "        for i, (dep, idxs) in enumerate(group):\n",
    "            layer = dep.layer\n",
    "            prune_fn = dep.pruning_fn\n",
    "            root_idxs = group[i].root_idxs\n",
    "            if not isinstance(layer, tuple(self.target_types)):\n",
    "                continue\n",
    "            ####################\n",
    "            # Conv/Linear Output\n",
    "            ####################\n",
    "            if prune_fn in [\n",
    "                function.prune_conv_out_channels,\n",
    "                function.prune_linear_out_channels,\n",
    "            ]:\n",
    "                if hasattr(layer, \"transposed\") and layer.transposed:\n",
    "                    w = layer.weight.data.transpose(1, 0)[idxs].flatten(1)\n",
    "                else:\n",
    "                    w = layer.weight.data[idxs].flatten(1)\n",
    "                #local_imp = w.abs().pow(self.p).sum(1)\n",
    "                local_imp = w.abs().pow(self.p).mean(1)\n",
    "                group_imp.append(local_imp)\n",
    "                group_idxs.append(root_idxs)\n",
    "\n",
    "                if self.bias and layer.bias is not None:\n",
    "                    local_imp = layer.bias.data[idxs].abs().pow(self.p)\n",
    "                    group_imp.append(local_imp)\n",
    "                    group_idxs.append(root_idxs)\n",
    "\n",
    "            ####################\n",
    "            # Conv/Linear Input\n",
    "            ####################\n",
    "            elif prune_fn in [\n",
    "                function.prune_conv_in_channels,\n",
    "                function.prune_linear_in_channels,\n",
    "            ]:\n",
    "                if hasattr(layer, \"transposed\") and layer.transposed:\n",
    "                    w = (layer.weight.data).flatten(1)\n",
    "                else:\n",
    "                    w = (layer.weight.data).transpose(0, 1).flatten(1)\n",
    "                #local_imp = w.abs().pow(self.p).sum(1)\n",
    "                local_imp = w.abs().pow(self.p).mean(1)\n",
    "\n",
    "                # repeat importance for group convolutions\n",
    "                if prune_fn == function.prune_conv_in_channels and layer.groups != layer.in_channels and layer.groups != 1:\n",
    "                    local_imp = local_imp.repeat(layer.groups)\n",
    "                \n",
    "                local_imp = local_imp[idxs]\n",
    "                group_imp.append(local_imp)\n",
    "                group_idxs.append(root_idxs)\n",
    "\n",
    "            ####################\n",
    "            # BatchNorm\n",
    "            ####################\n",
    "            elif prune_fn == function.prune_batchnorm_out_channels:\n",
    "                # regularize BN\n",
    "                if layer.affine:\n",
    "                    w = layer.weight.data[idxs]\n",
    "                    local_imp = w.abs().pow(self.p)\n",
    "                    group_imp.append(local_imp)\n",
    "                    group_idxs.append(root_idxs)\n",
    "\n",
    "                    if self.bias and layer.bias is not None:\n",
    "                        local_imp = layer.bias.data[idxs].abs().pow(self.p)\n",
    "                        group_imp.append(local_imp)\n",
    "                        group_idxs.append(root_idxs)\n",
    "            ####################\n",
    "            # LayerNorm\n",
    "            ####################\n",
    "            elif prune_fn == function.prune_layernorm_out_channels:\n",
    "\n",
    "                if layer.elementwise_affine:\n",
    "                    w = layer.weight.data[idxs]\n",
    "                    local_imp = w.abs().pow(self.p)\n",
    "                    group_imp.append(local_imp)\n",
    "                    group_idxs.append(root_idxs)\n",
    "\n",
    "                    if self.bias and layer.bias is not None:\n",
    "                        local_imp = layer.bias.data[idxs].abs().pow(self.p)\n",
    "                        group_imp.append(local_imp)\n",
    "                        group_idxs.append(root_idxs)\n",
    "\n",
    "        if len(group_imp) == 0: # skip groups without parameterized layers\n",
    "            return None\n",
    "\n",
    "        group_imp = self._reduce(group_imp, group_idxs)\n",
    "        group_imp = self._normalize(group_imp, self.normalizer)\n",
    "        return group_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a68c78-ba82-4355-b34d-b7ef25b283a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e0d38-ae15-41ad-b894-a77cc060fba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd348d-1201-4d1f-9610-c06ce9124aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8b7f9-3fa9-4060-9cec-b62863fa8fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eeb162-9e8b-465d-ade7-a9b2dacce192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d5bc62-d0eb-4ece-9db3-5071950efe18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff06e9-35bf-4623-97ba-3326c7a29b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm_models = timm.list_models(module='resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c292803-0387-4de3-bcb6-f0960e7fd958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'caformer_b36',\n",
       " 'caformer_m36',\n",
       " 'caformer_s18',\n",
       " 'caformer_s36',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_medium',\n",
       " 'coat_lite_medium_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_small',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw2_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_2_rw_384',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convformer_b36',\n",
       " 'convformer_m36',\n",
       " 'convformer_s18',\n",
       " 'convformer_s36',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264d',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn48b',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'eva02_base_patch14_224',\n",
       " 'eva02_base_patch14_448',\n",
       " 'eva02_base_patch16_clip_224',\n",
       " 'eva02_enormous_patch14_clip_224',\n",
       " 'eva02_large_patch14_224',\n",
       " 'eva02_large_patch14_448',\n",
       " 'eva02_large_patch14_clip_224',\n",
       " 'eva02_large_patch14_clip_336',\n",
       " 'eva02_small_patch14_224',\n",
       " 'eva02_small_patch14_336',\n",
       " 'eva02_tiny_patch14_224',\n",
       " 'eva02_tiny_patch14_336',\n",
       " 'eva_giant_patch14_224',\n",
       " 'eva_giant_patch14_336',\n",
       " 'eva_giant_patch14_560',\n",
       " 'eva_giant_patch14_clip_224',\n",
       " 'eva_large_patch14_196',\n",
       " 'eva_large_patch14_336',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'focalnet_base_lrf',\n",
       " 'focalnet_base_srf',\n",
       " 'focalnet_huge_fl3',\n",
       " 'focalnet_huge_fl4',\n",
       " 'focalnet_large_fl3',\n",
       " 'focalnet_large_fl4',\n",
       " 'focalnet_small_lrf',\n",
       " 'focalnet_small_srf',\n",
       " 'focalnet_tiny_lrf',\n",
       " 'focalnet_tiny_srf',\n",
       " 'focalnet_xlarge_fl3',\n",
       " 'focalnet_xlarge_fl4',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'ghostnetv2_100',\n",
       " 'ghostnetv2_130',\n",
       " 'ghostnetv2_160',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hgnet_base',\n",
       " 'hgnet_small',\n",
       " 'hgnet_tiny',\n",
       " 'hgnetv2_b0',\n",
       " 'hgnetv2_b1',\n",
       " 'hgnetv2_b2',\n",
       " 'hgnetv2_b3',\n",
       " 'hgnetv2_b4',\n",
       " 'hgnetv2_b5',\n",
       " 'hgnetv2_b6',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w18_ssld',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w48_ssld',\n",
       " 'hrnet_w64',\n",
       " 'inception_next_base',\n",
       " 'inception_next_small',\n",
       " 'inception_next_tiny',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'legacy_xception',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobileone_s0',\n",
       " 'mobileone_s1',\n",
       " 'mobileone_s2',\n",
       " 'mobileone_s3',\n",
       " 'mobileone_s4',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_base_jx',\n",
       " 'nest_small',\n",
       " 'nest_small_jx',\n",
       " 'nest_tiny',\n",
       " 'nest_tiny_jx',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'poolformerv2_m36',\n",
       " 'poolformerv2_m48',\n",
       " 'poolformerv2_s12',\n",
       " 'poolformerv2_s24',\n",
       " 'poolformerv2_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_004_tv',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_008_tv',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040_sgn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_080_tv',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnety_640',\n",
       " 'regnety_1280',\n",
       " 'regnety_2560',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040_h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repghostnet_050',\n",
       " 'repghostnet_058',\n",
       " 'repghostnet_080',\n",
       " 'repghostnet_100',\n",
       " 'repghostnet_111',\n",
       " 'repghostnet_130',\n",
       " 'repghostnet_150',\n",
       " 'repghostnet_200',\n",
       " 'repvgg_a0',\n",
       " 'repvgg_a1',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'repvgg_d2se',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net50d',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2net101d',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50c',\n",
       " 'resnet50d',\n",
       " 'resnet50s',\n",
       " 'resnet50t',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101c',\n",
       " 'resnet101d',\n",
       " 'resnet101s',\n",
       " 'resnet152',\n",
       " 'resnet152c',\n",
       " 'resnet152d',\n",
       " 'resnet152s',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa34d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit',\n",
       " 'resnetv2_50x3_bit',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bit',\n",
       " 'resnetv2_101x3_bit',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit',\n",
       " 'resnetv2_152x4_bit',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnet_300',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'rexnetr_300',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101_64x4d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'seresnextaa201d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_m',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'volo_d1_224',\n",
       " 'volo_d1_384',\n",
       " 'volo_d2_224',\n",
       " 'volo_d2_384',\n",
       " 'volo_d3_224',\n",
       " 'volo_d3_448',\n",
       " 'volo_d4_224',\n",
       " 'volo_d4_448',\n",
       " 'volo_d5_224',\n",
       " 'volo_d5_448',\n",
       " 'volo_d5_512',\n",
       " 'vovnet39a',\n",
       " 'vovnet57a',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception41',\n",
       " 'xception41p',\n",
       " 'xception65',\n",
       " 'xception65p',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_384',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_384',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_384',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_384',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_384',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_384',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_384',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_384',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_384',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_384',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_384',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_384',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_384',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_384']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(exclude_filters='*vit*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ba020-7d16-43e6-ad69-ffb21d0be4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee8fa4-fd07-4098-80af-0b177e0429ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b6751-76ff-414d-b0e4-c0ce00b88f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b256f1-42df-4edd-ac27-8862d5bc1648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4908c777-042c-4337-9ba0-57f4d5be4234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20e1a1-3aa5-48f2-8017-2deda97ff3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962358c6-8cdf-4db7-bdf6-792436f1080d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7234a-1711-42ca-a333-2abf4852cec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e1992-1f22-4e90-9383-99e362d258b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = timm.create_model('seresnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991ffa7c-15a4-4f24-a6ae-ad9f6ab3c702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (se): SEModule(\n",
       "        (fc1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "        (act): ReLU(inplace=True)\n",
       "        (fc2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (gate): Sigmoid()\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e805623-0226-4efc-97bf-38c61cff6ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasterai.prune.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d105013-4076-4a3f-9d8e-c62274e57a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(16, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f228819-fbae-47ad-8562-f2a144460223",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = timm.create_model('seresnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e7daa-a62d-4526-9389-e83851178310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time CPU (ms/image):6.694 ms +/- 0.092 ms\n",
      "FPS CPU: 149.3904126039974\n",
      "Inference time GPU (ms/image): 0.267 ms +/- 0.003 ms\n",
      "FPS GPU: 3743.6464639069623\n",
      "Nombre de paramètres: 11.780 M\n",
      "Taille du modèle: 44.936 MiB\n",
      "Nombre de MACs: 1817.400 M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107.10191986960126, 1.479711068861181, 4.27390784740448, 0.05194234267945458)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(m, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa95998-1a99-498d-a58a-60b80975c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = Pruner(m, 'local', large_final, layer_type=[nn.Conv2d])\n",
    "pr.prune_model(30, round_to=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df100666-0a6e-4e54-87fa-fc26a3eb52e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time CPU (ms/image):3.316 ms +/- 0.040 ms\n",
      "FPS CPU: 301.55608187204695\n",
      "Inference time GPU (ms/image): 0.183 ms +/- 0.003 ms\n",
      "FPS GPU: 5469.600455484674\n",
      "Nombre de paramètres: 5.657 M\n",
      "Taille du modèle: 21.580 MiB\n",
      "Nombre de MACs: 836.963 M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(53.058124050003244,\n",
       " 0.6349589479868257,\n",
       " 2.9252593731880188,\n",
       " 0.04034922064140752)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(m, dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6067115-2d3f-4a19-8c50-e2d2f862330a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c70a55-5afe-4d9e-820c-af7b58eedc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbebb3f2-f85f-4fe4-ab0d-7d96e10fe542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b5271-62d0-429e-86bd-a19f70f726b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb931e0-6956-41c9-b46e-f6e634bc446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import typing\n",
    "\n",
    "from torch_pruning import function\n",
    "from torch_pruning.dependency import Group\n",
    "\n",
    "class Importance(abc.ABC):\n",
    "    \"\"\" Estimate the importance of a tp.Dependency.Group, and return an 1-D per-channel importance score.\n",
    "\n",
    "        It should accept a group as inputs, and return a 1-D tensor with the same length as the number of channels.\n",
    "        All groups must be pruned simultaneously and thus their importance should be accumulated across channel groups.\n",
    "\n",
    "        Example:\n",
    "            ```python\n",
    "            DG = tp.DependencyGraph().build_dependency(model, example_inputs=torch.randn(1,3,224,224)) \n",
    "            group = DG.get_pruning_group( model.conv1, tp.prune_conv_out_channels, idxs=[2, 6, 9] )    \n",
    "            scorer = MagnitudeImportance()    \n",
    "            imp_score = scorer(group)    \n",
    "            #imp_score is a 1-D tensor with length 3 for channels [2, 6, 9]  \n",
    "            min_score = imp_score.min() \n",
    "            ``` \n",
    "    \"\"\"\n",
    "    @abc.abstractclassmethod\n",
    "    def __call__(self, group: Group) -> torch.Tensor: \n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class GroupNormImportance(Importance):\n",
    "\n",
    "    def __init__(self, \n",
    "                 p: int=2, \n",
    "                 group_reduction: str=\"mean\", \n",
    "                 normalizer: str='mean', \n",
    "                 bias=False,\n",
    "                 target_types:list=[nn.modules.conv._ConvNd, nn.Linear, nn.modules.batchnorm._BatchNorm, nn.LayerNorm]):\n",
    "        self.p = p\n",
    "        self.group_reduction = group_reduction\n",
    "        self.normalizer = normalizer\n",
    "        self.target_types = target_types\n",
    "        self.bias = bias\n",
    "\n",
    "    def _lamp(self, scores): # Layer-adaptive Sparsity for the Magnitude-based Pruning\n",
    "        \"\"\"\n",
    "        Normalizing scheme for LAMP.\n",
    "        \"\"\"\n",
    "        # sort scores in an ascending order\n",
    "        sorted_scores,sorted_idx = scores.view(-1).sort(descending=False)\n",
    "        # compute cumulative sum\n",
    "        scores_cumsum_temp = sorted_scores.cumsum(dim=0)\n",
    "        scores_cumsum = torch.zeros(scores_cumsum_temp.shape,device=scores.device)\n",
    "        scores_cumsum[1:] = scores_cumsum_temp[:len(scores_cumsum_temp)-1]\n",
    "        # normalize by cumulative sum\n",
    "        sorted_scores /= (scores.sum() - scores_cumsum)\n",
    "        # tidy up and output\n",
    "        new_scores = torch.zeros(scores_cumsum.shape,device=scores.device)\n",
    "        new_scores[sorted_idx] = sorted_scores\n",
    "        \n",
    "        return new_scores.view(scores.shape)\n",
    "    \n",
    "    def _normalize(self, group_importance, normalizer):\n",
    "        if normalizer is None:\n",
    "            return group_importance\n",
    "        elif isinstance(normalizer, typing.Callable):\n",
    "            return normalizer(group_importance)\n",
    "        elif normalizer == \"sum\":\n",
    "            return group_importance / group_importance.sum()\n",
    "        elif normalizer == \"standarization\":\n",
    "            return (group_importance - group_importance.min()) / (group_importance.max() - group_importance.min()+1e-8)\n",
    "        elif normalizer == \"mean\":\n",
    "            return group_importance / group_importance.mean()\n",
    "        elif normalizer == \"max\":\n",
    "            return group_importance / group_importance.max()\n",
    "        elif normalizer == 'gaussian':\n",
    "            return (group_importance - group_importance.mean()) / (group_importance.std()+1e-8)\n",
    "        elif normalizer.startswith('sentinel'): # normalize the score with the k-th smallest element. e.g. sentinel_0.5 means median normalization\n",
    "            sentinel = float(normalizer.split('_')[1]) * len(group_importance)\n",
    "            sentinel = torch.argsort(group_importance, dim=0, descending=False)[int(sentinel)]\n",
    "            return group_importance / (group_importance[sentinel]+1e-8)\n",
    "        elif normalizer=='lamp':\n",
    "            return self._lamp(group_importance)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def _reduce(self, group_imp: typing.List[torch.Tensor], group_idxs: typing.List[typing.List[int]]):\n",
    "        if len(group_imp) == 0: return group_imp\n",
    "        if self.group_reduction == 'prod':\n",
    "            reduced_imp = torch.ones_like(group_imp[0])\n",
    "        elif self.group_reduction == 'max':\n",
    "            reduced_imp = torch.ones_like(group_imp[0]) * -99999\n",
    "        else:\n",
    "            reduced_imp = torch.zeros_like(group_imp[0])\n",
    "\n",
    "        for i, (imp, root_idxs) in enumerate(zip(group_imp, group_idxs)):\n",
    "            imp = imp.to(reduced_imp.device)\n",
    "            if self.group_reduction == \"sum\" or self.group_reduction == \"mean\":\n",
    "                reduced_imp.scatter_add_(0, torch.tensor(root_idxs, device=imp.device), imp) # accumulated importance\n",
    "            elif self.group_reduction == \"max\": # keep the max importance\n",
    "                selected_imp = torch.index_select(reduced_imp, 0, torch.tensor(root_idxs, device=imp.device))\n",
    "                selected_imp = torch.maximum(input=selected_imp, other=imp)\n",
    "                reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), selected_imp)\n",
    "            elif self.group_reduction == \"prod\": # product of importance\n",
    "                selected_imp = torch.index_select(reduced_imp, 0, torch.tensor(root_idxs, device=imp.device))\n",
    "                torch.mul(selected_imp, imp, out=selected_imp)\n",
    "                reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), selected_imp)\n",
    "            elif self.group_reduction == 'first':\n",
    "                if i == 0:\n",
    "                    reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "            elif self.group_reduction == 'gate':\n",
    "                if i == len(group_imp)-1:\n",
    "                    reduced_imp.scatter_(0, torch.tensor(root_idxs, device=imp.device), imp)\n",
    "            elif self.group_reduction is None:\n",
    "                reduced_imp = torch.stack(group_imp, dim=0) # no reduction\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        \n",
    "        if self.group_reduction == \"mean\":\n",
    "            reduced_imp /= len(group_imp)\n",
    "        return reduced_imp\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, group: Group):\n",
    "        group_imp = []\n",
    "        group_idxs = []\n",
    "        # Iterate over all groups and estimate group importance\n",
    "        for i, (dep, idxs) in enumerate(group):\n",
    "            layer = dep.layer\n",
    "            prune_fn = dep.pruning_fn\n",
    "            root_idxs = group[i].root_idxs\n",
    "            if not isinstance(layer, tuple(self.target_types)):\n",
    "                continue\n",
    "            ####################\n",
    "            # Conv/Linear Output\n",
    "            ####################\n",
    "            if prune_fn in [\n",
    "                function.prune_conv_out_channels,\n",
    "                function.prune_linear_out_channels,\n",
    "            ]:\n",
    "                if hasattr(layer, \"transposed\") and layer.transposed:\n",
    "                    w = layer.weight.data.transpose(1, 0)[idxs].flatten(1)\n",
    "                else:\n",
    "                    w = layer.weight.data[idxs].flatten(1)\n",
    "                #local_imp = w.abs().pow(self.p).sum(1)\n",
    "                local_imp = w.abs().pow(self.p).mean(1)\n",
    "                group_imp.append(local_imp)\n",
    "                group_idxs.append(root_idxs)\n",
    "\n",
    "                if self.bias and layer.bias is not None:\n",
    "                    local_imp = layer.bias.data[idxs].abs().pow(self.p)\n",
    "                    group_imp.append(local_imp)\n",
    "                    group_idxs.append(root_idxs)\n",
    "\n",
    "            ####################\n",
    "            # Conv/Linear Input\n",
    "            ####################\n",
    "            elif prune_fn in [\n",
    "                function.prune_conv_in_channels,\n",
    "                function.prune_linear_in_channels,\n",
    "            ]:\n",
    "                if hasattr(layer, \"transposed\") and layer.transposed:\n",
    "                    w = (layer.weight.data).flatten(1)\n",
    "                else:\n",
    "                    w = (layer.weight.data).transpose(0, 1).flatten(1)\n",
    "                #local_imp = w.abs().pow(self.p).sum(1)\n",
    "                local_imp = w.abs().pow(self.p).mean(1)\n",
    "\n",
    "                # repeat importance for group convolutions\n",
    "                if prune_fn == function.prune_conv_in_channels and layer.groups != layer.in_channels and layer.groups != 1:\n",
    "                    local_imp = local_imp.repeat(layer.groups)\n",
    "                \n",
    "                local_imp = local_imp[idxs]\n",
    "                group_imp.append(local_imp)\n",
    "                group_idxs.append(root_idxs)\n",
    "\n",
    "            ####################\n",
    "            # BatchNorm\n",
    "            ####################\n",
    "            elif prune_fn == function.prune_batchnorm_out_channels:\n",
    "                # regularize BN\n",
    "                if layer.affine:\n",
    "                    w = layer.weight.data[idxs]\n",
    "                    local_imp = w.abs().pow(self.p)\n",
    "                    group_imp.append(local_imp)\n",
    "                    group_idxs.append(root_idxs)\n",
    "\n",
    "                    if self.bias and layer.bias is not None:\n",
    "                        local_imp = layer.bias.data[idxs].abs().pow(self.p)\n",
    "                        group_imp.append(local_imp)\n",
    "                        group_idxs.append(root_idxs)\n",
    "            ####################\n",
    "            # LayerNorm\n",
    "            ####################\n",
    "            elif prune_fn == function.prune_layernorm_out_channels:\n",
    "\n",
    "                if layer.elementwise_affine:\n",
    "                    w = layer.weight.data[idxs]\n",
    "                    local_imp = w.abs().pow(self.p)\n",
    "                    group_imp.append(local_imp)\n",
    "                    group_idxs.append(root_idxs)\n",
    "\n",
    "                    if self.bias and layer.bias is not None:\n",
    "                        local_imp = layer.bias.data[idxs].abs().pow(self.p)\n",
    "                        group_imp.append(local_imp)\n",
    "                        group_idxs.append(root_idxs)\n",
    "\n",
    "        if len(group_imp) == 0: # skip groups without parameterized layers\n",
    "            return None\n",
    "\n",
    "        group_imp = self._reduce(group_imp, group_idxs)\n",
    "        group_imp = self._normalize(group_imp, self.normalizer)\n",
    "        return group_imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a36b8-a2a2-4767-8757-690eae72b8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
