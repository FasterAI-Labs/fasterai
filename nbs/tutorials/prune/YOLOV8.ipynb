{
 "cells": [
  {
   "cell_type": "raw",
   "id": "10c41965-a076-4a77-a864-5230d7b79d70",
   "metadata": {},
   "source": [
    "---\n",
    "description: YOLOV8\n",
    "output-file: tutorial.YOLOV8.html\n",
    "title: YOLOV8\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4991349-58bc-46bb-9322-793e9d3d927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO, __version__\n",
    "from ultralytics.nn.modules import Detect, C2f, Conv, Bottleneck\n",
    "from ultralytics.nn.tasks import attempt_load_one_weight\n",
    "from ultralytics.yolo.engine.model import TASK_MAP\n",
    "from ultralytics.yolo.engine.trainer import BaseTrainer\n",
    "from ultralytics.yolo.utils import yaml_load, LOGGER, RANK, DEFAULT_CFG_DICT, DEFAULT_CFG_KEYS\n",
    "from ultralytics.yolo.utils.checks import check_yaml\n",
    "from ultralytics.yolo.utils.torch_utils import initialize_weights, de_parallel\n",
    "\n",
    "import torch_pruning as tp\n",
    "from fasterai.prune.all import *\n",
    "from fastai.vision.all import *\n",
    "from fastcore.basics import store_attr, listify, true\n",
    "from torch_pruning.pruner import function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627fea81-6877-43a7-a383-e96a566f6364",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb742075-3158-48ba-836a-8bfe51388b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "def infer_shortcut(bottleneck):\n",
    "    c1 = bottleneck.cv1.conv.in_channels\n",
    "    c2 = bottleneck.cv2.conv.out_channels\n",
    "    return c1 == c2 and hasattr(bottleneck, 'add') and bottleneck.add\n",
    "\n",
    "\n",
    "class C2f_v2(nn.Module):\n",
    "    # CSP Bottleneck with 2 convolutions\n",
    "    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n",
    "        super().__init__()\n",
    "        self.c = int(c2 * e)  # hidden channels\n",
    "        self.cv0 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv1 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)\n",
    "        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # y = list(self.cv1(x).chunk(2, 1))\n",
    "        y = [self.cv0(x), self.cv1(x)]\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        return self.cv2(torch.cat(y, 1))\n",
    "\n",
    "\n",
    "def transfer_weights(c2f, c2f_v2):\n",
    "    c2f_v2.cv2 = c2f.cv2\n",
    "    c2f_v2.m = c2f.m\n",
    "\n",
    "    state_dict = c2f.state_dict()\n",
    "    state_dict_v2 = c2f_v2.state_dict()\n",
    "\n",
    "    # Transfer cv1 weights from C2f to cv0 and cv1 in C2f_v2\n",
    "    old_weight = state_dict['cv1.conv.weight']\n",
    "    half_channels = old_weight.shape[0] // 2\n",
    "    state_dict_v2['cv0.conv.weight'] = old_weight[:half_channels]\n",
    "    state_dict_v2['cv1.conv.weight'] = old_weight[half_channels:]\n",
    "\n",
    "    # Transfer cv1 batchnorm weights and buffers from C2f to cv0 and cv1 in C2f_v2\n",
    "    for bn_key in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "        old_bn = state_dict[f'cv1.bn.{bn_key}']\n",
    "        state_dict_v2[f'cv0.bn.{bn_key}'] = old_bn[:half_channels]\n",
    "        state_dict_v2[f'cv1.bn.{bn_key}'] = old_bn[half_channels:]\n",
    "\n",
    "    # Transfer remaining weights and buffers\n",
    "    for key in state_dict:\n",
    "        if not key.startswith('cv1.'):\n",
    "            state_dict_v2[key] = state_dict[key]\n",
    "\n",
    "    # Transfer all non-method attributes\n",
    "    for attr_name in dir(c2f):\n",
    "        attr_value = getattr(c2f, attr_name)\n",
    "        if not callable(attr_value) and '_' not in attr_name:\n",
    "            setattr(c2f_v2, attr_name, attr_value)\n",
    "\n",
    "    c2f_v2.load_state_dict(state_dict_v2)\n",
    "\n",
    "\n",
    "def replace_c2f_with_c2f_v2(module):\n",
    "    for name, child_module in module.named_children():\n",
    "        if isinstance(child_module, C2f):\n",
    "            # Replace C2f with C2f_v2 while preserving its parameters\n",
    "            shortcut = infer_shortcut(child_module.m[0])\n",
    "            c2f_v2 = C2f_v2(child_module.cv1.conv.in_channels, child_module.cv2.conv.out_channels,\n",
    "                            n=len(child_module.m), shortcut=shortcut,\n",
    "                            g=child_module.m[0].cv2.conv.groups,\n",
    "                            e=child_module.c / child_module.cv2.conv.out_channels)\n",
    "            transfer_weights(child_module, c2f_v2)\n",
    "            setattr(module, name, c2f_v2)\n",
    "        else:\n",
    "            replace_c2f_with_c2f_v2(child_module)\n",
    "\n",
    "\n",
    "def save_model_v2(self: BaseTrainer):\n",
    "    \"\"\"\n",
    "    Disabled half precision saving. originated from ultralytics/yolo/engine/trainer.py\n",
    "    \"\"\"\n",
    "    ckpt = {\n",
    "        'epoch': self.epoch,\n",
    "        'best_fitness': self.best_fitness,\n",
    "        'model': deepcopy(de_parallel(self.model)),\n",
    "        'ema': deepcopy(self.ema.ema),\n",
    "        'updates': self.ema.updates,\n",
    "        'optimizer': self.optimizer.state_dict(),\n",
    "        'train_args': vars(self.args),  # save as dict\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'version': __version__}\n",
    "\n",
    "    # Save last, best and delete\n",
    "    torch.save(ckpt, self.last)\n",
    "    if self.best_fitness == self.fitness:\n",
    "        torch.save(ckpt, self.best)\n",
    "    if (self.epoch > 0) and (self.save_period > 0) and (self.epoch % self.save_period == 0):\n",
    "        torch.save(ckpt, self.wdir / f'epoch{self.epoch}.pt')\n",
    "    del ckpt\n",
    "\n",
    "def final_eval_v2(self: BaseTrainer):\n",
    "    \"\"\"\n",
    "    originated from ultralytics/yolo/engine/trainer.py\n",
    "    \"\"\"\n",
    "    for f in self.last, self.best:\n",
    "        if f.exists():\n",
    "            strip_optimizer_v2(f)  # strip optimizers\n",
    "            if f is self.best:\n",
    "                LOGGER.info(f'\\nValidating {f}...')\n",
    "                self.metrics = self.validator(model=f)\n",
    "                self.metrics.pop('fitness', None)\n",
    "                self.run_callbacks('on_fit_epoch_end')\n",
    "\n",
    "def strip_optimizer_v2(f: Union[str, Path] = 'best.pt', s: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Disabled half precision saving. originated from ultralytics/yolo/utils/torch_utils.py\n",
    "    \"\"\"\n",
    "    x = torch.load(f, map_location=torch.device('cpu'))\n",
    "    args = {**DEFAULT_CFG_DICT, **x['train_args']}  # combine model args with default args, preferring model args\n",
    "    if x.get('ema'):\n",
    "        x['model'] = x['ema']  # replace model with ema\n",
    "    for k in 'optimizer', 'ema', 'updates':  # keys\n",
    "        x[k] = None\n",
    "    for p in x['model'].parameters():\n",
    "        p.requires_grad = False\n",
    "    x['train_args'] = {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  # strip non-default keys\n",
    "    # x['model'].args = x['train_args']\n",
    "    torch.save(x, s or f)\n",
    "    mb = os.path.getsize(s or f) / 1E6  # filesize\n",
    "    LOGGER.info(f\"Optimizer stripped from {f},{f' saved as {s},' if s else ''} {mb:.1f}MB\")\n",
    "\n",
    "\n",
    "def train_v2(self: YOLO, pruning=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Disabled loading new model when pruning flag is set. originated from ultralytics/yolo/engine/model.py\n",
    "    \"\"\"\n",
    "\n",
    "    self._check_is_pytorch_model()\n",
    "    if self.session:  # Ultralytics HUB session\n",
    "        if any(kwargs):\n",
    "            LOGGER.warning('WARNING âš ï¸ using HUB training arguments, ignoring local training arguments.')\n",
    "        kwargs = self.session.train_args\n",
    "    overrides = self.overrides.copy()\n",
    "    overrides.update(kwargs)\n",
    "    if kwargs.get('cfg'):\n",
    "        LOGGER.info(f\"cfg file passed. Overriding default params with {kwargs['cfg']}.\")\n",
    "        overrides = yaml_load(check_yaml(kwargs['cfg']))\n",
    "    overrides['mode'] = 'train'\n",
    "    if not overrides.get('data'):\n",
    "        raise AttributeError(\"Dataset required but missing, i.e. pass 'data=coco128.yaml'\")\n",
    "    if overrides.get('resume'):\n",
    "        overrides['resume'] = self.ckpt_path\n",
    "\n",
    "    self.task = overrides.get('task') or self.task\n",
    "    self.trainer = TASK_MAP[self.task][1](overrides=overrides, _callbacks=self.callbacks)\n",
    "\n",
    "    if not pruning:\n",
    "        if not overrides.get('resume'):  # manually set model only if not resuming\n",
    "            self.trainer.model = self.trainer.get_model(weights=self.model if self.ckpt else None, cfg=self.model.yaml)\n",
    "            self.model = self.trainer.model\n",
    "\n",
    "    else:\n",
    "        # pruning mode\n",
    "        self.trainer.pruning = True\n",
    "        self.trainer.model = self.model\n",
    "\n",
    "        # replace some functions to disable half precision saving\n",
    "        self.trainer.save_model = save_model_v2.__get__(self.trainer)\n",
    "        self.trainer.final_eval = final_eval_v2.__get__(self.trainer)\n",
    "\n",
    "    self.trainer.hub_session = self.session  # attach optional HUB session\n",
    "    self.trainer.train()\n",
    "    # Update model and cfg after training\n",
    "    if RANK in (-1, 0):\n",
    "        self.model, _ = attempt_load_one_weight(str(self.trainer.best))\n",
    "        self.overrides = self.model.args\n",
    "        self.metrics = getattr(self.trainer.validator, 'metrics', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03d638-01ae-4d35-88c1-6215e5211cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "def prune(args):\n",
    "    # load trained yolov8 model\n",
    "    model = YOLO(args.model)\n",
    "    model.__setattr__(\"train_v2\", train_v2.__get__(model))\n",
    "    pruning_cfg = yaml_load(check_yaml(args.cfg))\n",
    "    batch_size = pruning_cfg['batch']\n",
    "    \n",
    "    pruning_cfg['data'] = \"coco128.yaml\"\n",
    "    pruning_cfg['epochs'] = 10\n",
    "    pruning_cfg['verbose'] = False\n",
    "    \n",
    "    model.model.train()\n",
    "    replace_c2f_with_c2f_v2(model.model)\n",
    "    initialize_weights(model.model)\n",
    "    \n",
    "    validation_model = deepcopy(model)\n",
    "    metric = validation_model.val(**pruning_cfg)\n",
    "    init_map = metric.box.map\n",
    "    example_inputs = torch.randn(1, 3, pruning_cfg[\"imgsz\"], pruning_cfg[\"imgsz\"]).to(model.device)\n",
    "    \n",
    "    base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs)\n",
    "    print(f\"Before Pruning: MACs={base_macs / 1e9: .5f} G, #Params={base_nparams / 1e6: .5f} M, mAP={init_map: .5f}\")\n",
    "    \n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    model.train_v2(pruning=True, **pruning_cfg)\n",
    "\n",
    "    pruning_cfg['epochs'] = 10\n",
    "    \n",
    "    macs_list, nparams_list, map_list, pruned_map_list = [], [], [], []\n",
    "    base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs)\n",
    "    \n",
    "    pruning_cfg['name'] = f\"baseline_val\"\n",
    "    pruning_cfg['batch'] = 1\n",
    "    \n",
    "    \n",
    "    validation_model.model.model = deepcopy(model.model.model)\n",
    "    metric = validation_model.val(**pruning_cfg)\n",
    "    init_map = metric.box.map\n",
    "    macs_list.append(base_macs)\n",
    "    nparams_list.append(100)\n",
    "    map_list.append(init_map)\n",
    "    pruned_map_list.append(init_map)\n",
    "    print(f\"Before Pruning: MACs={base_macs / 1e9: .5f} G, #Params={base_nparams / 1e6: .5f} M, mAP={init_map: .5f}\")\n",
    "    \n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "        ignored_layers = []\n",
    "        unwrapped_parameters = []\n",
    "        for m in model.model.modules():\n",
    "            if isinstance(m, (Detect,)):\n",
    "                ignored_layers.append(m)\n",
    "    \n",
    "    \n",
    "    print(model.model.model[0].conv)\n",
    "    pruner = Pruner(model.model, args.target_prune_rate, 'local', large_final, ignored_layers=ignored_layers, iterative_steps=args.iterative_steps, schedule=args.sched._scheduler)\n",
    "\n",
    "    for i in range(args.iterative_steps):\n",
    "\n",
    "        pruning_ratio = args.sched(args.target_prune_rate, i/args.iterative_steps)\n",
    "\n",
    "        \n",
    "\n",
    "        pruner.prune_model()\n",
    "        print(pruning_ratio[0])\n",
    "\n",
    "        print('After Pruning')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "\n",
    "        pruning_cfg['name'] = f\"step_{i}_pre_val\"\n",
    "        pruning_cfg['batch'] = 1\n",
    "        validation_model.model.model = deepcopy(pruner.model.model)\n",
    "        metric = validation_model.val(**pruning_cfg)\n",
    "        pruned_map = metric.box.map\n",
    "        pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(pruner.model.to(default_device()), example_inputs.to(default_device()))\n",
    "        \n",
    "        print('After post-pruning Validation')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "        \n",
    "        \n",
    "        current_speed_up = float(macs_list[0]) / pruned_macs\n",
    "        print(f\"After pruning iter {i + 1}: MACs={pruned_macs / 1e9} G, #Params={pruned_nparams / 1e6} M, \"\n",
    "              f\"mAP={pruned_map}, speed up={current_speed_up}\")\n",
    "\n",
    "        \n",
    "        # fine-tuning\n",
    "        for name, param in model.model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "        pruning_cfg['name'] = f\"step_{i}_finetune\"\n",
    "        pruning_cfg['batch'] = batch_size  # restore batch size\n",
    "        model.model = pruner.model\n",
    "        model.train_v2(pruning=True, **pruning_cfg)\n",
    "\n",
    "        print('After fine-tuning')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "        \n",
    "        \n",
    "        # post fine-tuning validation\n",
    "        pruning_cfg['name'] = f\"step_{i}_post_val\"\n",
    "        pruning_cfg['batch'] = 1\n",
    "        validation_model = YOLO(model.trainer.best)\n",
    "        validation_model.model = deepcopy(model.model)\n",
    "        metric = validation_model.val( **pruning_cfg)\n",
    "        current_map = metric.box.map\n",
    "        print(f\"After fine tuning mAP={current_map}\")\n",
    "\n",
    "        print('After post fine-tuning validation')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "    \n",
    "\n",
    "        macs_list.append(pruned_macs)\n",
    "        nparams_list.append(pruned_nparams / base_nparams * 100)\n",
    "        pruned_map_list.append(pruned_map)\n",
    "        map_list.append(current_map)\n",
    "\n",
    "        if init_map - current_map > args.max_map_drop:\n",
    "            print(\"Pruning early stop\")\n",
    "            break\n",
    "\n",
    "\n",
    "    model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098fc1b4-57d5-4a31-a557-920688c094a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b08319-6d07-4e42-9528-3e09a0558e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.731      0.768      0.828      0.658\n",
      "Speed: 0.1ms preprocess, 7.5ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/val39\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning: MACs= 82.72641 G, #Params= 43.69152 M, mAP= 0.65799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/train33\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/train33/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/train33\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10        12G     0.9535     0.9388      1.178    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.824      0.712      0.832      0.665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.2G     0.9172     0.8093      1.161    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.836      0.755      0.842      0.682\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.6G     0.9013     0.7191      1.099    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.874      0.756      0.852      0.691\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      12.1G     0.9249     0.7495      1.118    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.858      0.793      0.863      0.699\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.8G     0.8319     0.6796      1.082    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.859       0.81      0.882      0.717\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.9G     0.8412     0.6843      1.096    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.848      0.828      0.892      0.729\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      12.1G      0.814     0.6248      1.067    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.88      0.825      0.898      0.737\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.9G     0.8093      0.615      1.067    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.905      0.819      0.897      0.748\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.8G     0.7573     0.5698      1.036    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.905       0.83      0.901      0.755\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      12.1G     0.7934     0.6052      1.075    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.894      0.835        0.9      0.758\n",
      "\n",
      "10 epochs completed in 0.029 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/train33/weights/last.pt, 175.3MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/train33/weights/best.pt, 175.3MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/train33/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.894      0.835        0.9      0.758\n",
      "Speed: 0.1ms preprocess, 4.2ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/train33\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.892      0.826      0.901      0.751\n",
      "Speed: 0.2ms preprocess, 10.8ms inference, 0.0ms loss, 0.5ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/baseline_val28\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning: MACs= 82.72641 G, #Params= 43.69152 M, mAP= 0.75140\n",
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.0027046189978777607\n",
      "After Pruning\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 43081939 parameters, 74176 gradients, 162.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929        0.9      0.825      0.906      0.734\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_0_pre_val17\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_0_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_0_finetune16\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 1: MACs=81.5020432 G, #Params=43.105009 M, mAP=0.7335178809742455, speed up=1.0150224847369225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_0_finetune16/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_0_finetune16\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      12.7G     0.7839       0.65      1.053    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.886      0.849      0.906      0.752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.7G     0.7319      0.499      1.036    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.901      0.856      0.914      0.756\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      12.5G     0.7449     0.4985      1.014    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.896      0.864      0.915       0.76\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      12.6G     0.7679     0.5147      1.027    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.896      0.864      0.912      0.758\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      12.7G     0.6996     0.4846      1.015    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.909      0.863      0.915      0.761\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      12.8G     0.7258      0.516      1.026    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.908      0.869      0.916      0.766\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      12.8G     0.7541     0.5142      1.024    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.919      0.863      0.915      0.771\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      12.8G     0.7233     0.5094      1.014    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.912      0.868      0.917      0.776\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      12.8G       0.69     0.4918     0.9917    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.909      0.869      0.919      0.778\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      12.8G     0.7366     0.5463      1.035    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.919      0.865      0.918      0.779\n",
      "\n",
      "10 epochs completed in 0.029 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_0_finetune16/weights/last.pt, 173.0MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_0_finetune16/weights/best.pt, 173.0MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_0_finetune16/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 43081939 parameters, 0 gradients, 162.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.919      0.865      0.918      0.778\n",
      "Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_0_finetune16\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 43081939 parameters, 0 gradients, 162.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.909      0.865      0.915      0.776\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_0_post_val12\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.775721307939776\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.005179586515491673\n",
      "After Pruning\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 42712366 parameters, 74176 gradients, 161.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.923      0.859      0.916      0.767\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_1_pre_val9\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_1_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_1_finetune9\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 2: MACs=80.7933916 G, #Params=42.735334 M, mAP=0.7671079746246661, speed up=1.0239254072854147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_1_finetune9/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_1_finetune9\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      13.6G     0.6788     0.5264     0.9988    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.91      0.873      0.918      0.777\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.7G     0.6175     0.4036     0.9705    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.93      0.863       0.92      0.783\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      12.6G      0.646     0.4189     0.9632    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.918      0.863      0.922      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      12.7G     0.6623     0.4434     0.9798    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.925       0.86      0.923      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      12.8G     0.6136     0.4164     0.9643    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.861      0.926      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      12.8G     0.6421     0.4466     0.9727    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.928      0.862      0.928      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      12.8G     0.6767      0.457     0.9847    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.934      0.865      0.931      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      12.9G     0.6599     0.4573     0.9827    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.877      0.934      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      12.8G     0.6616     0.4547     0.9732    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.928      0.872      0.935      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      12.7G     0.6991     0.5169      1.008    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.934      0.869      0.936      0.803\n",
      "\n",
      "10 epochs completed in 0.039 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_1_finetune9/weights/last.pt, 171.5MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_1_finetune9/weights/best.pt, 171.5MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_1_finetune9/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 42712366 parameters, 0 gradients, 161.3 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.933      0.871      0.935      0.803\n",
      "Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_1_finetune9\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 42712366 parameters, 0 gradients, 161.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.91      0.872       0.93      0.792\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_1_post_val9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.7924603103645905\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.009769531739708686\n",
      "After Pruning\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 42094706 parameters, 74176 gradients, 158.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.908      0.868      0.924      0.779\n",
      "Speed: 0.1ms preprocess, 13.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_2_pre_val9\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_2_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_2_finetune9\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 3: MACs=79.5541908 G, #Params=42.117503 M, mAP=0.7792330059497833, speed up=1.0398749024796818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_2_finetune9/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_2_finetune9\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10        13G     0.6418     0.5222     0.9767    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.914      0.885      0.929      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.6G     0.5453      0.368     0.9336    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.92      0.884      0.938      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      12.5G     0.5814     0.3836     0.9312    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.925      0.884      0.937      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      12.6G     0.6058     0.3976     0.9452    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.949       0.87      0.937      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      12.6G     0.5516     0.3755     0.9373    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.948      0.867      0.939       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      12.7G     0.5859     0.4033     0.9496    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.929      0.887      0.942      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      12.6G      0.635     0.4225     0.9698    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.942      0.883      0.941      0.809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      12.7G     0.6191     0.4212     0.9639    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.937      0.888      0.941      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      12.7G      0.631     0.4236     0.9608    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.936      0.889      0.942       0.82\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      12.6G     0.6808     0.5085      1.003    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.935      0.889      0.942      0.821\n",
      "\n",
      "10 epochs completed in 0.040 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_2_finetune9/weights/last.pt, 169.0MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_2_finetune9/weights/best.pt, 169.0MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_2_finetune9/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 42094706 parameters, 0 gradients, 158.8 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.935       0.89      0.942      0.821\n",
      "Speed: 0.1ms preprocess, 4.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_2_finetune9\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 42094706 parameters, 0 gradients, 158.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.883      0.942      0.811\n",
      "Speed: 0.2ms preprocess, 13.5ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_2_post_val9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8108994344622686\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.017924759478681728\n",
      "After Pruning\n",
      "Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 40919781 parameters, 74176 gradients, 154.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.911      0.866      0.928      0.771\n",
      "Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_3_pre_val8\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_3_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_3_finetune8\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 4: MACs=77.3600192 G, #Params=40.942254 M, mAP=0.7714194636333309, speed up=1.0693690003634333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_3_finetune8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_3_finetune8\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      12.6G     0.6354     0.4858     0.9676    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.931       0.87      0.936      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.6G     0.5377     0.3467     0.9207    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.933      0.878      0.939      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      12.5G      0.588     0.3751     0.9277    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.939      0.875      0.939      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      12.6G     0.5795     0.3872     0.9303    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.944       0.87      0.937      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      12.6G     0.5511     0.3675     0.9235    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.943      0.872      0.937      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      12.7G     0.5638     0.3974     0.9317    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.925      0.879      0.939      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      12.6G     0.6183     0.4048     0.9559    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.915      0.885      0.939      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      12.7G     0.6064     0.4156     0.9551    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.888       0.94       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      12.7G     0.6126     0.4111     0.9473    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.928      0.898      0.943      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      12.6G     0.6751     0.4922      1.001    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.898      0.942       0.82\n",
      "\n",
      "10 epochs completed in 0.027 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_3_finetune8/weights/last.pt, 164.3MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_3_finetune8/weights/best.pt, 164.3MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_3_finetune8/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 40919781 parameters, 0 gradients, 154.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.898      0.942       0.82\n",
      "Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_3_finetune8\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 40919781 parameters, 0 gradients, 154.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.919      0.891      0.941      0.813\n",
      "Speed: 0.1ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_3_post_val7\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.813335254805048\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03136884242508382\n",
      "After Pruning\n",
      "Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 39455305 parameters, 74176 gradients, 149.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.853       0.93      0.771\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_4_pre_val7\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_4_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_4_finetune7\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 5: MACs=74.8418608 G, #Params=39.477376 M, mAP=0.7709511018059185, speed up=1.1053494062777232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_4_finetune7/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_4_finetune7\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      12.8G     0.6393     0.4996     0.9632    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.91      0.879      0.934      0.787\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.7G     0.5385     0.3464     0.9142    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.915      0.879      0.936      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      12.5G     0.5725     0.3758     0.9139    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.916      0.899      0.943      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      12.6G     0.5814     0.3863     0.9212    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.923        0.9      0.948      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      12.7G     0.5392     0.3637     0.9171    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.901      0.948      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      12.9G     0.5582     0.4023     0.9233    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.93      0.898       0.95      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      12.8G     0.6234     0.4091     0.9585    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.905      0.951      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      12.8G     0.6062     0.4115     0.9444    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.908      0.953      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      12.7G     0.6105     0.4111     0.9411    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.906      0.949      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      12.6G     0.6834      0.498      1.001    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.926      0.906       0.95      0.819\n",
      "\n",
      "10 epochs completed in 0.027 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_4_finetune7/weights/last.pt, 158.5MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_4_finetune7/weights/best.pt, 158.5MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_4_finetune7/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 39455305 parameters, 0 gradients, 149.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.905       0.95      0.819\n",
      "Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_4_finetune7\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 39455305 parameters, 0 gradients, 149.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.921      0.909      0.951      0.816\n",
      "Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_4_post_val6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8155992309783842\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.051012679818528694\n",
      "After Pruning\n",
      "Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 37708749 parameters, 74176 gradients, 143.2 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.902      0.862      0.927      0.764\n",
      "Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_5_pre_val6\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_5_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_5_finetune6\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 6: MACs=71.732976 G, #Params=37.730325 M, mAP=0.7640629035267851, speed up=1.1532549046898597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_5_finetune6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_5_finetune6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      13.1G     0.6622     0.5187     0.9815    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.911      0.878      0.936      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.7G     0.5412     0.3602       0.91    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.908      0.899       0.94      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      12.6G     0.5946     0.3883     0.9197    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.918      0.893      0.941      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      12.7G     0.5856      0.396     0.9263    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.937       0.88      0.942      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      12.7G     0.5495     0.3637     0.9176    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.93      0.873      0.944      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      12.8G     0.5562      0.396     0.9231    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.938      0.872      0.945      0.805\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      12.7G     0.6301     0.4115     0.9537    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.883      0.942      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      12.8G     0.6138     0.4093      0.944    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.919      0.894      0.946       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      12.8G     0.6297     0.4207     0.9478    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.926      0.898      0.949      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      12.7G      0.703     0.5027      1.009    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.898       0.95      0.814\n",
      "\n",
      "10 epochs completed in 0.037 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_5_finetune6/weights/last.pt, 151.5MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_5_finetune6/weights/best.pt, 151.5MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_5_finetune6/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 37708749 parameters, 0 gradients, 143.2 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.898       0.95      0.814\n",
      "Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_5_finetune6\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 37708749 parameters, 0 gradients, 143.2 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.888      0.946       0.81\n",
      "Speed: 0.1ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_5_post_val6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8104708131787314\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.07518590641324997\n",
      "After Pruning\n",
      "Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 35995675 parameters, 74176 gradients, 136.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.878      0.799      0.907       0.74\n",
      "Speed: 0.2ms preprocess, 12.7ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_6_pre_val6\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_6_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_6_finetune6\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 7: MACs=68.4860368 G, #Params=36.016747 M, mAP=0.7398590274182758, speed up=1.207930992438447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_6_finetune6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_6_finetune6\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      11.7G     0.6993     0.5584     0.9858    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.902      0.841      0.921      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.8G     0.5531     0.3752     0.9125    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.91      0.849      0.927      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.7G     0.6039     0.4089     0.9216    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.926       0.86       0.93      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.5G     0.6132      0.414     0.9289    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.906      0.882      0.933      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.5G     0.5718      0.383     0.9257    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.909      0.879      0.938      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.9G     0.5734     0.4089     0.9254    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.928      0.877      0.942      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.5G     0.6396     0.4206     0.9589    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.929      0.883      0.945        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.6G     0.6347     0.4307     0.9533    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.932      0.879      0.946      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.6G     0.6589     0.4376     0.9609    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.931      0.885      0.947      0.808\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.8G     0.7121     0.5232      1.016    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.93      0.886      0.945       0.81\n",
      "\n",
      "10 epochs completed in 0.025 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_6_finetune6/weights/last.pt, 144.6MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_6_finetune6/weights/best.pt, 144.6MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_6_finetune6/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 35995675 parameters, 0 gradients, 136.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.929      0.887      0.945      0.808\n",
      "Speed: 0.1ms preprocess, 4.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_6_finetune6\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 35995675 parameters, 0 gradients, 136.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.887      0.943      0.804\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_6_post_val5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8040926175515907\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.09935913300797124\n",
      "After Pruning\n",
      "Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 34583399 parameters, 74176 gradients, 131.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.915      0.829      0.917      0.733\n",
      "Speed: 0.1ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_7_pre_val5\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_7_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_7_finetune5\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 8: MACs=65.8289424 G, #Params=34.604045 M, mAP=0.7333194226117398, speed up=1.2566874597092115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_7_finetune5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_7_finetune5\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      11.2G     0.6839     0.5488     0.9811    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.931      0.847      0.932      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.5G     0.5602     0.3693     0.9134    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.92      0.869      0.936      0.781\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.4G     0.5984     0.3895     0.9188    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.905      0.879      0.936      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.6G     0.6034      0.418     0.9248    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.899      0.886      0.936      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.4G     0.5658     0.3782      0.928    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.925      0.872      0.938      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.7G     0.5917     0.4156     0.9288    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.92      0.882      0.939      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.4G     0.6339     0.4252     0.9516    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.933      0.876      0.944      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.4G     0.6471     0.4304     0.9604    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.933      0.878      0.945        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.4G      0.668     0.4424      0.959    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.884      0.944      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.6G     0.7304     0.5445      1.031    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.919      0.887      0.943      0.802\n",
      "\n",
      "10 epochs completed in 0.024 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_7_finetune5/weights/last.pt, 139.0MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_7_finetune5/weights/best.pt, 139.0MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_7_finetune5/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 34583399 parameters, 0 gradients, 131.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.884      0.944      0.802\n",
      "Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_7_finetune5\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 34583399 parameters, 0 gradients, 131.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.915       0.88       0.94      0.793\n",
      "Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_7_post_val5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.7931599917268005\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.11900297040141611\n",
      "After Pruning\n",
      "Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 33747610 parameters, 74176 gradients, 128.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.919      0.861       0.93      0.769\n",
      "Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_8_pre_val5\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_8_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_8_finetune5\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 9: MACs=64.3900056 G, #Params=33.768007 M, mAP=0.7690853683854553, speed up=1.2847709148203583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_8_finetune5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_8_finetune5\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10        12G     0.6504     0.5212     0.9696    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.934       0.87      0.935      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.6G     0.5047     0.3425     0.8995    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.908      0.889      0.936      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.5G     0.5622     0.3725     0.9046    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.913      0.892      0.938      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.7G     0.5558     0.3856     0.9139    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.925      0.894      0.941      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.7G     0.5481     0.3728       0.92    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.92      0.886      0.939       0.79\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.2G     0.5576     0.4045     0.9157    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.928      0.888      0.943      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.1G      0.635      0.429     0.9474    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.935      0.891      0.947      0.794\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.2G     0.6145     0.4019     0.9449    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.939      0.887      0.949        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.2G     0.6569     0.4243     0.9517    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.945      0.881      0.949      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.6G     0.7253     0.5226      1.024    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.945      0.883      0.948      0.802\n",
      "\n",
      "10 epochs completed in 0.034 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_8_finetune5/weights/last.pt, 135.6MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_8_finetune5/weights/best.pt, 135.6MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_8_finetune5/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 33747610 parameters, 0 gradients, 128.5 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.946      0.881      0.949      0.803\n",
      "Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_8_finetune5\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 33747610 parameters, 0 gradients, 128.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.937      0.875      0.942      0.796\n",
      "Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_8_post_val5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.7963247276929302\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.1324470533478182\n",
      "After Pruning\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 33209910 parameters, 74176 gradients, 126.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.935      0.847      0.931      0.768\n",
      "Speed: 0.2ms preprocess, 11.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_9_pre_val3\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_9_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_9_finetune3\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 10: MACs=63.4942128 G, #Params=33.230145 M, mAP=0.7676251325156896, speed up=1.302896795658832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_9_finetune3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_9_finetune3\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      12.2G      0.627     0.5006     0.9614    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.92      0.879       0.94      0.792\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      12.4G     0.4757     0.3198     0.8867    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.935      0.878      0.944      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.7G     0.5402     0.3563     0.8958    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.931      0.877      0.941      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.8G     0.5459     0.3752     0.9083    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.934      0.882      0.945      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.8G     0.5164     0.3487     0.9079    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.923      0.893      0.943      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.9G     0.5421      0.385     0.9102    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.918      0.896      0.942      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.8G     0.6251     0.4038     0.9468    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.926       0.89      0.945      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.9G     0.5953     0.3998      0.934    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.918      0.905      0.946      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.9G     0.6388     0.4184     0.9476    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.92      0.898      0.947      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.7G     0.7187     0.5164      1.018    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.93      0.895      0.947      0.806\n",
      "\n",
      "10 epochs completed in 0.031 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_9_finetune3/weights/last.pt, 133.4MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_9_finetune3/weights/best.pt, 133.4MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_9_finetune3/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 33209910 parameters, 0 gradients, 126.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.932      0.893      0.947      0.805\n",
      "Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_9_finetune3\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 33209910 parameters, 0 gradients, 126.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.936      0.889      0.945      0.801\n",
      "Speed: 0.2ms preprocess, 11.3ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_9_post_val3\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8009899904343383\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.14060228108679124\n",
      "After Pruning\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32703049 parameters, 74176 gradients, 124.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.847      0.937      0.771\n",
      "Speed: 0.1ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_10_pre_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_10_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_10_finetune2\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 11: MACs=62.4345712 G, #Params=32.723122 M, mAP=0.7711514639154989, speed up=1.3250096030130178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_10_finetune2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_10_finetune2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10        12G     0.6334     0.5193     0.9605    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.931      0.852       0.94      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.5G      0.466     0.3067     0.8851    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.942      0.847      0.937      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.4G     0.5156      0.342     0.8852    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.946      0.868      0.938      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.5G     0.5392     0.3641     0.9066    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.934      0.884      0.937      0.791\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.5G     0.5117     0.3557     0.9081    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.909      0.894      0.941      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.6G      0.515      0.373     0.9027    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.911      0.889      0.939      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.5G     0.6053     0.4073     0.9379    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.905      0.884      0.939      0.797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.6G     0.5829       0.39     0.9326    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.881      0.944      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.5G     0.6332     0.4096      0.942    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.929      0.886      0.945      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.5G     0.7178     0.5183      1.015    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.941      0.877      0.945      0.808\n",
      "\n",
      "10 epochs completed in 0.033 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_10_finetune2/weights/last.pt, 131.4MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_10_finetune2/weights/best.pt, 131.4MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_10_finetune2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 32703049 parameters, 0 gradients, 124.6 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.941      0.876      0.945      0.809\n",
      "Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_10_finetune2\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32703049 parameters, 0 gradients, 124.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.92      0.896       0.95      0.808\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_10_post_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8081809745840371\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.14519222631100823\n",
      "After Pruning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32669140 parameters, 74176 gradients, 124.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.917      0.899       0.95       0.81\n",
      "Speed: 0.2ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_11_pre_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_11_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_11_finetune2\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 12: MACs=62.4070664 G, #Params=32.689204 M, mAP=0.8098376035512942, speed up=1.325593577332454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_11_finetune2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_11_finetune2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      11.5G     0.5624     0.4578     0.9404    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.905      0.907      0.946      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.6G      0.399     0.2726      0.865    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.931      0.879      0.941      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.4G     0.4809     0.3212      0.879    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.929      0.892      0.941      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.5G     0.4806      0.334     0.8879    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.945      0.881       0.94      0.804\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.6G     0.4862     0.3288     0.8994    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.938      0.883      0.942      0.806\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.6G     0.4887     0.3584      0.893    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.929       0.89      0.943       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.6G     0.5702     0.3791     0.9254    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.937      0.888      0.943      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.6G     0.5531     0.3689     0.9184    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.933      0.896      0.946      0.812\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.6G      0.588     0.3884      0.923    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.926        0.9       0.95      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.5G     0.7003     0.4962      1.007    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.899      0.949      0.814\n",
      "\n",
      "10 epochs completed in 0.019 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_11_finetune2/weights/last.pt, 131.3MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_11_finetune2/weights/best.pt, 131.3MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_11_finetune2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 32669140 parameters, 0 gradients, 124.6 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.925        0.9       0.95      0.815\n",
      "Speed: 0.1ms preprocess, 4.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_11_finetune2\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32669140 parameters, 0 gradients, 124.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.932      0.884      0.943      0.809\n",
      "Speed: 0.2ms preprocess, 12.5ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_11_post_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.80867019892426\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.14766719382862217\n",
      "After Pruning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 74176 gradients, 123.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.884      0.943      0.793\n",
      "Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_12_pre_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_12_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_12_finetune2\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 13: MACs=61.8488912 G, #Params=32.436843 M, mAP=0.7929855954557918, speed up=1.3375568226839933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_12_finetune2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_12_finetune2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      11.7G     0.5728     0.4693     0.9395    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.935      0.885      0.944      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.6G      0.403      0.267     0.8612    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.934      0.876      0.946      0.813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.4G     0.4806     0.3161     0.8771    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.885      0.945      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.5G     0.4954     0.3358     0.8895    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.923      0.898      0.946       0.81\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.5G     0.4868     0.3256     0.8983    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.927      0.889      0.945      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.5G     0.5005     0.3485      0.893    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.923      0.901      0.946      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.5G     0.5637     0.3694     0.9171    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.923      0.898      0.946      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.6G     0.5525      0.361     0.9134    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.94      0.892      0.945      0.809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.6G     0.5873     0.3731      0.923    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.94      0.897      0.945      0.815\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.5G     0.7004     0.4849      1.012    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.94      0.898      0.946      0.813\n",
      "\n",
      "10 epochs completed in 0.030 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_12_finetune2/weights/last.pt, 130.3MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_12_finetune2/weights/best.pt, 130.3MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_12_finetune2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.921      0.886      0.945      0.814\n",
      "Speed: 0.1ms preprocess, 4.0ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_12_finetune2\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.931      0.889      0.946       0.81\n",
      "Speed: 0.2ms preprocess, 12.1ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_12_post_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.81035824268819\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.14897095513156428\n",
      "After Pruning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 74176 gradients, 123.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.921      0.899      0.946      0.809\n",
      "Speed: 0.1ms preprocess, 12.1ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_13_pre_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_13_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_13_finetune2\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 14: MACs=61.8488912 G, #Params=32.436843 M, mAP=0.8094708031863412, speed up=1.3375568226839933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_13_finetune2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_13_finetune2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      11.2G     0.5243     0.4358     0.9284    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.922      0.904      0.948      0.817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.3G     0.3797     0.2496     0.8509    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.926      0.903      0.949      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.2G     0.4293     0.2921     0.8642    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.939       0.89      0.948      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.2G     0.4573     0.3141     0.8773    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.936      0.899      0.949      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.3G     0.4667     0.3122     0.8898    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.929      0.897      0.947      0.811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.4G     0.4877     0.3356     0.8894    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.932      0.889      0.945      0.802\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.3G     0.5567     0.3642     0.9154    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.937      0.882      0.947      0.807\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.4G      0.522     0.3407     0.9033    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.945      0.885      0.947      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.3G       0.59     0.3656     0.9174    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.946      0.884      0.947      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.3G     0.7007      0.488      1.009    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.941      0.887      0.949      0.824\n",
      "\n",
      "10 epochs completed in 0.020 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_13_finetune2/weights/last.pt, 130.3MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_13_finetune2/weights/best.pt, 130.3MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_13_finetune2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.941      0.887      0.949      0.823\n",
      "Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_13_finetune2\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.923      0.902      0.949      0.818\n",
      "Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_13_post_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8178296276387611\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "0.14964931342467439\n",
      "After Pruning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 74176 gradients, 123.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.926      0.897      0.949      0.817\n",
      "Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_14_pre_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_14_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_14_finetune2\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After post-pruning Validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "After pruning iter 15: MACs=61.8488912 G, #Params=32.436843 M, mAP=0.8171226992562459, speed up=1.3375568226839933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "Plotting labels to /home/HubensN/ultralytics/runs/detect/step_14_finetune2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_14_finetune2\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self.amp):\n",
      "       1/10      11.3G     0.5084     0.4275     0.9241    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.943      0.886      0.945      0.824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/10      11.3G     0.3449     0.2386     0.8452    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.939      0.889      0.948      0.826\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/10      11.2G     0.4181     0.2863     0.8581    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.945       0.89      0.948      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/10      11.5G     0.4197     0.3033     0.8692    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.954      0.903      0.952       0.82\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/10      11.3G     0.4552     0.3053     0.8846    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.949      0.905       0.95      0.819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/10      11.4G     0.4572     0.3242      0.878    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.941      0.904      0.955      0.816\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/10      11.3G     0.5533     0.3546     0.9156    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.928      0.905      0.948      0.818\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/10      11.7G     0.5238     0.3388     0.9018    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.934      0.909      0.949       0.82\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/10      11.6G     0.5513     0.3486     0.9081    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.943      0.912      0.952      0.821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/10      11.3G     0.6869      0.468     0.9985    \n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.944      0.913      0.952       0.82\n",
      "\n",
      "10 epochs completed in 0.018 hours.\n",
      "/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  x = torch.load(f, map_location=torch.device('cpu'))\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/last.pt, 130.3MB\n",
      "Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt, 130.3MB\n",
      "\n",
      "Validating /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt...\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929       0.94      0.889      0.948      0.826\n",
      "Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_14_finetune2\u001b[0m\n",
      "/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine-tuning\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.924      0.896      0.945       0.82\n",
      "Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_14_post_val2\u001b[0m\n",
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fine tuning mAP=0.8199030883902761\n",
      "After post fine-tuning validation\n",
      "Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (124.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.2s, saved as /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.onnx (123.9 MB)\n",
      "\n",
      "Export complete (2.9s)\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.onnx imgsz=640 \n",
      "Validate:        yolo val task=detect model=/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.onnx imgsz=640 data=/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/datasets/coco128.yaml \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  model = 'yolov8l.pt'\n",
    "  cfg = 'default.yaml'\n",
    "  iterative_steps = 15\n",
    "  target_prune_rate = 0.15\n",
    "  max_map_drop = 0.2\n",
    "  sched = Schedule(partial(sched_onecycle,  Î±=10, Î²=4))\n",
    "\n",
    "args=Args()\n",
    "prune(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8afe98d-f6c4-4451-a838-991bb5993134",
   "metadata": {},
   "source": [
    "## Post-Training Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4390e-038c-42a5-a80a-872e35bf1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c68d4-e374-4a2d-b1cd-80374a804725",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = torch.randn(1, 3, 640, 640).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3527bf-bdca-40f0-93d3-42af28b01b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61848891200.0, 32436843)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs); base_macs, base_nparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39190b40-3d3b-4844-9da7-c41e9b9aa6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/HubensN/datasets/coco128/labels/train20\u001b[0m\n",
      "                 Class     Images  Instances      Box(P    \n",
      "                   all        128        929      0.941      0.891      0.948      0.828\n",
      "Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1m/home/HubensN/ultralytics/runs/detect/val41\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.val(\n",
    "                data='coco128.yaml',\n",
    "                batch=1,\n",
    "                imgsz=640,\n",
    "                verbose=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb54734-cf16-4051-ae58-1e0b03435c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.yolo.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79])\n",
       "box: ultralytics.yolo.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.yolo.utils.metrics.ConfusionMatrix object>\n",
       "fitness: 0.8398465728578197\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.80663,     0.56166,     0.46391,     0.97747,     0.97261,     0.92577,      0.9079,     0.78266,     0.69041,     0.39913,      0.8278,      0.8955,      0.8278,     0.86033,     0.85892,       0.995,       0.962,     0.92662,      0.8278,      0.8278,     0.93661,       0.995,     0.96237,     0.85834,\n",
       "           0.78541,     0.86574,     0.69715,     0.81464,     0.94304,      0.7515,      0.8955,     0.81395,     0.34834,     0.52181,     0.74658,     0.37593,     0.74195,      0.8278,     0.64171,     0.66705,     0.73098,     0.83937,      0.7376,     0.65567,     0.71183,     0.84817,       0.995,      0.8278,\n",
       "             0.995,      0.8408,     0.68827,      0.8293,     0.92344,      0.9785,       0.995,     0.92662,      0.8607,     0.91091,     0.86934,       0.995,     0.91683,      0.8603,      0.9501,     0.95359,     0.80117,     0.84734,      0.8278,     0.69016,     0.95773,     0.96025,      0.8278,     0.83127,\n",
       "             0.977,     0.58867,     0.88629,       0.995,       0.995,     0.93602,      0.8278,      0.9465])\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9410256301337474, 'metrics/recall(B)': 0.8911335314866058, 'metrics/mAP50(B)': 0.9482558527722713, 'metrics/mAP50-95(B)': 0.8278010973117694, 'fitness': 0.8398465728578197}\n",
       "save_dir: Path('/home/HubensN/ultralytics/runs/detect/val41')\n",
       "speed: {'preprocess': 0.14928914606571198, 'inference': 9.854648262262344, 'loss': 0.004881992936134338, 'postprocess': 0.43218769133090973}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36d64b-13ff-4480-ae1b-7d302a7857e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.124 ðŸš€ Python-3.10.15 torch-2.5.1+cu124 CPU\n",
      "WARNING âš ï¸ half=True only compatible with GPU export, i.e. use device=0\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.export(format = 'onnx', half = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
