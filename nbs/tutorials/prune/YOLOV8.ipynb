{
 "cells": [
  {
   "cell_type": "raw",
   "id": "10c41965-a076-4a77-a864-5230d7b79d70",
   "metadata": {},
   "source": [
    "---\n",
    "description: YOLOV8\n",
    "output-file: tutorial.YOLOV8.html\n",
    "title: YOLOV8\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4991349-58bc-46bb-9322-793e9d3d927e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO, __version__\n",
    "from ultralytics.nn.modules import Detect, C2f, Conv, Bottleneck\n",
    "from ultralytics.nn.tasks import attempt_load_one_weight\n",
    "from ultralytics.yolo.engine.model import TASK_MAP\n",
    "from ultralytics.yolo.engine.trainer import BaseTrainer\n",
    "from ultralytics.yolo.utils import yaml_load, LOGGER, RANK, DEFAULT_CFG_DICT, DEFAULT_CFG_KEYS\n",
    "from ultralytics.yolo.utils.checks import check_yaml\n",
    "from ultralytics.yolo.utils.torch_utils import initialize_weights, de_parallel\n",
    "\n",
    "import torch_pruning as tp\n",
    "from fasterai.prune.all import *\n",
    "from fastai.vision.all import *\n",
    "from fastcore.basics import store_attr, listify, true\n",
    "from torch_pruning.pruner import function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627fea81-6877-43a7-a383-e96a566f6364",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb742075-3158-48ba-836a-8bfe51388b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "def infer_shortcut(bottleneck):\n",
    "    c1 = bottleneck.cv1.conv.in_channels\n",
    "    c2 = bottleneck.cv2.conv.out_channels\n",
    "    return c1 == c2 and hasattr(bottleneck, 'add') and bottleneck.add\n",
    "\n",
    "\n",
    "class C2f_v2(nn.Module):\n",
    "    # CSP Bottleneck with 2 convolutions\n",
    "    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion\n",
    "        super().__init__()\n",
    "        self.c = int(c2 * e)  # hidden channels\n",
    "        self.cv0 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv1 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)\n",
    "        self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # y = list(self.cv1(x).chunk(2, 1))\n",
    "        y = [self.cv0(x), self.cv1(x)]\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        return self.cv2(torch.cat(y, 1))\n",
    "\n",
    "\n",
    "def transfer_weights(c2f, c2f_v2):\n",
    "    c2f_v2.cv2 = c2f.cv2\n",
    "    c2f_v2.m = c2f.m\n",
    "\n",
    "    state_dict = c2f.state_dict()\n",
    "    state_dict_v2 = c2f_v2.state_dict()\n",
    "\n",
    "    # Transfer cv1 weights from C2f to cv0 and cv1 in C2f_v2\n",
    "    old_weight = state_dict['cv1.conv.weight']\n",
    "    half_channels = old_weight.shape[0] // 2\n",
    "    state_dict_v2['cv0.conv.weight'] = old_weight[:half_channels]\n",
    "    state_dict_v2['cv1.conv.weight'] = old_weight[half_channels:]\n",
    "\n",
    "    # Transfer cv1 batchnorm weights and buffers from C2f to cv0 and cv1 in C2f_v2\n",
    "    for bn_key in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "        old_bn = state_dict[f'cv1.bn.{bn_key}']\n",
    "        state_dict_v2[f'cv0.bn.{bn_key}'] = old_bn[:half_channels]\n",
    "        state_dict_v2[f'cv1.bn.{bn_key}'] = old_bn[half_channels:]\n",
    "\n",
    "    # Transfer remaining weights and buffers\n",
    "    for key in state_dict:\n",
    "        if not key.startswith('cv1.'):\n",
    "            state_dict_v2[key] = state_dict[key]\n",
    "\n",
    "    # Transfer all non-method attributes\n",
    "    for attr_name in dir(c2f):\n",
    "        attr_value = getattr(c2f, attr_name)\n",
    "        if not callable(attr_value) and '_' not in attr_name:\n",
    "            setattr(c2f_v2, attr_name, attr_value)\n",
    "\n",
    "    c2f_v2.load_state_dict(state_dict_v2)\n",
    "\n",
    "\n",
    "def replace_c2f_with_c2f_v2(module):\n",
    "    for name, child_module in module.named_children():\n",
    "        if isinstance(child_module, C2f):\n",
    "            # Replace C2f with C2f_v2 while preserving its parameters\n",
    "            shortcut = infer_shortcut(child_module.m[0])\n",
    "            c2f_v2 = C2f_v2(child_module.cv1.conv.in_channels, child_module.cv2.conv.out_channels,\n",
    "                            n=len(child_module.m), shortcut=shortcut,\n",
    "                            g=child_module.m[0].cv2.conv.groups,\n",
    "                            e=child_module.c / child_module.cv2.conv.out_channels)\n",
    "            transfer_weights(child_module, c2f_v2)\n",
    "            setattr(module, name, c2f_v2)\n",
    "        else:\n",
    "            replace_c2f_with_c2f_v2(child_module)\n",
    "\n",
    "\n",
    "def save_model_v2(self: BaseTrainer):\n",
    "    \"\"\"\n",
    "    Disabled half precision saving. originated from ultralytics/yolo/engine/trainer.py\n",
    "    \"\"\"\n",
    "    ckpt = {\n",
    "        'epoch': self.epoch,\n",
    "        'best_fitness': self.best_fitness,\n",
    "        'model': deepcopy(de_parallel(self.model)),\n",
    "        'ema': deepcopy(self.ema.ema),\n",
    "        'updates': self.ema.updates,\n",
    "        'optimizer': self.optimizer.state_dict(),\n",
    "        'train_args': vars(self.args),  # save as dict\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'version': __version__}\n",
    "\n",
    "    # Save last, best and delete\n",
    "    torch.save(ckpt, self.last)\n",
    "    if self.best_fitness == self.fitness:\n",
    "        torch.save(ckpt, self.best)\n",
    "    if (self.epoch > 0) and (self.save_period > 0) and (self.epoch % self.save_period == 0):\n",
    "        torch.save(ckpt, self.wdir / f'epoch{self.epoch}.pt')\n",
    "    del ckpt\n",
    "\n",
    "def final_eval_v2(self: BaseTrainer):\n",
    "    \"\"\"\n",
    "    originated from ultralytics/yolo/engine/trainer.py\n",
    "    \"\"\"\n",
    "    for f in self.last, self.best:\n",
    "        if f.exists():\n",
    "            strip_optimizer_v2(f)  # strip optimizers\n",
    "            if f is self.best:\n",
    "                LOGGER.info(f'\\nValidating {f}...')\n",
    "                self.metrics = self.validator(model=f)\n",
    "                self.metrics.pop('fitness', None)\n",
    "                self.run_callbacks('on_fit_epoch_end')\n",
    "\n",
    "def strip_optimizer_v2(f: Union[str, Path] = 'best.pt', s: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Disabled half precision saving. originated from ultralytics/yolo/utils/torch_utils.py\n",
    "    \"\"\"\n",
    "    x = torch.load(f, map_location=torch.device('cpu'))\n",
    "    args = {**DEFAULT_CFG_DICT, **x['train_args']}  # combine model args with default args, preferring model args\n",
    "    if x.get('ema'):\n",
    "        x['model'] = x['ema']  # replace model with ema\n",
    "    for k in 'optimizer', 'ema', 'updates':  # keys\n",
    "        x[k] = None\n",
    "    for p in x['model'].parameters():\n",
    "        p.requires_grad = False\n",
    "    x['train_args'] = {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  # strip non-default keys\n",
    "    # x['model'].args = x['train_args']\n",
    "    torch.save(x, s or f)\n",
    "    mb = os.path.getsize(s or f) / 1E6  # filesize\n",
    "    LOGGER.info(f\"Optimizer stripped from {f},{f' saved as {s},' if s else ''} {mb:.1f}MB\")\n",
    "\n",
    "\n",
    "def train_v2(self: YOLO, pruning=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Disabled loading new model when pruning flag is set. originated from ultralytics/yolo/engine/model.py\n",
    "    \"\"\"\n",
    "\n",
    "    self._check_is_pytorch_model()\n",
    "    if self.session:  # Ultralytics HUB session\n",
    "        if any(kwargs):\n",
    "            LOGGER.warning('WARNING ⚠️ using HUB training arguments, ignoring local training arguments.')\n",
    "        kwargs = self.session.train_args\n",
    "    overrides = self.overrides.copy()\n",
    "    overrides.update(kwargs)\n",
    "    if kwargs.get('cfg'):\n",
    "        LOGGER.info(f\"cfg file passed. Overriding default params with {kwargs['cfg']}.\")\n",
    "        overrides = yaml_load(check_yaml(kwargs['cfg']))\n",
    "    overrides['mode'] = 'train'\n",
    "    if not overrides.get('data'):\n",
    "        raise AttributeError(\"Dataset required but missing, i.e. pass 'data=coco128.yaml'\")\n",
    "    if overrides.get('resume'):\n",
    "        overrides['resume'] = self.ckpt_path\n",
    "\n",
    "    self.task = overrides.get('task') or self.task\n",
    "    self.trainer = TASK_MAP[self.task][1](overrides=overrides, _callbacks=self.callbacks)\n",
    "\n",
    "    if not pruning:\n",
    "        if not overrides.get('resume'):  # manually set model only if not resuming\n",
    "            self.trainer.model = self.trainer.get_model(weights=self.model if self.ckpt else None, cfg=self.model.yaml)\n",
    "            self.model = self.trainer.model\n",
    "\n",
    "    else:\n",
    "        # pruning mode\n",
    "        self.trainer.pruning = True\n",
    "        self.trainer.model = self.model\n",
    "\n",
    "        # replace some functions to disable half precision saving\n",
    "        self.trainer.save_model = save_model_v2.__get__(self.trainer)\n",
    "        self.trainer.final_eval = final_eval_v2.__get__(self.trainer)\n",
    "\n",
    "    self.trainer.hub_session = self.session  # attach optional HUB session\n",
    "    self.trainer.train()\n",
    "    # Update model and cfg after training\n",
    "    if RANK in (-1, 0):\n",
    "        self.model, _ = attempt_load_one_weight(str(self.trainer.best))\n",
    "        self.overrides = self.model.args\n",
    "        self.metrics = getattr(self.trainer.validator, 'metrics', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03d638-01ae-4d35-88c1-6215e5211cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "\n",
    "def prune(args):\n",
    "    # load trained yolov8 model\n",
    "    model = YOLO(args.model)\n",
    "    model.__setattr__(\"train_v2\", train_v2.__get__(model))\n",
    "    pruning_cfg = yaml_load(check_yaml(args.cfg))\n",
    "    batch_size = pruning_cfg['batch']\n",
    "    \n",
    "    pruning_cfg['data'] = \"coco128.yaml\"\n",
    "    pruning_cfg['epochs'] = 10\n",
    "    pruning_cfg['verbose'] = False\n",
    "    \n",
    "    model.model.train()\n",
    "    replace_c2f_with_c2f_v2(model.model)\n",
    "    initialize_weights(model.model)\n",
    "    \n",
    "    validation_model = deepcopy(model)\n",
    "    metric = validation_model.val(**pruning_cfg)\n",
    "    init_map = metric.box.map\n",
    "    example_inputs = torch.randn(1, 3, pruning_cfg[\"imgsz\"], pruning_cfg[\"imgsz\"]).to(model.device)\n",
    "    \n",
    "    base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs)\n",
    "    print(f\"Before Pruning: MACs={base_macs / 1e9: .5f} G, #Params={base_nparams / 1e6: .5f} M, mAP={init_map: .5f}\")\n",
    "    \n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    model.train_v2(pruning=True, **pruning_cfg)\n",
    "\n",
    "    pruning_cfg['epochs'] = 10\n",
    "    \n",
    "    macs_list, nparams_list, map_list, pruned_map_list = [], [], [], []\n",
    "    base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs)\n",
    "    \n",
    "    pruning_cfg['name'] = f\"baseline_val\"\n",
    "    pruning_cfg['batch'] = 1\n",
    "    \n",
    "    \n",
    "    validation_model.model.model = deepcopy(model.model.model)\n",
    "    metric = validation_model.val(**pruning_cfg)\n",
    "    init_map = metric.box.map\n",
    "    macs_list.append(base_macs)\n",
    "    nparams_list.append(100)\n",
    "    map_list.append(init_map)\n",
    "    pruned_map_list.append(init_map)\n",
    "    print(f\"Before Pruning: MACs={base_macs / 1e9: .5f} G, #Params={base_nparams / 1e6: .5f} M, mAP={init_map: .5f}\")\n",
    "    \n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "        ignored_layers = []\n",
    "        unwrapped_parameters = []\n",
    "        for m in model.model.modules():\n",
    "            if isinstance(m, (Detect,)):\n",
    "                ignored_layers.append(m)\n",
    "    \n",
    "    \n",
    "    print(model.model.model[0].conv)\n",
    "    pruner = Pruner(model.model, args.target_prune_rate, 'local', large_final, ignored_layers=ignored_layers, iterative_steps=args.iterative_steps, schedule=args.sched._scheduler)\n",
    "\n",
    "    for i in range(args.iterative_steps):\n",
    "\n",
    "        pruning_ratio = args.sched(args.target_prune_rate, i/args.iterative_steps)\n",
    "\n",
    "        \n",
    "\n",
    "        pruner.prune_model()\n",
    "        print(pruning_ratio[0])\n",
    "\n",
    "        print('After Pruning')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "\n",
    "        pruning_cfg['name'] = f\"step_{i}_pre_val\"\n",
    "        pruning_cfg['batch'] = 1\n",
    "        validation_model.model.model = deepcopy(pruner.model.model)\n",
    "        metric = validation_model.val(**pruning_cfg)\n",
    "        pruned_map = metric.box.map\n",
    "        pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(pruner.model.to(default_device()), example_inputs.to(default_device()))\n",
    "        \n",
    "        print('After post-pruning Validation')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "        \n",
    "        \n",
    "        current_speed_up = float(macs_list[0]) / pruned_macs\n",
    "        print(f\"After pruning iter {i + 1}: MACs={pruned_macs / 1e9} G, #Params={pruned_nparams / 1e6} M, \"\n",
    "              f\"mAP={pruned_map}, speed up={current_speed_up}\")\n",
    "\n",
    "        \n",
    "        # fine-tuning\n",
    "        for name, param in model.model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "        pruning_cfg['name'] = f\"step_{i}_finetune\"\n",
    "        pruning_cfg['batch'] = batch_size  # restore batch size\n",
    "        model.model = pruner.model\n",
    "        model.train_v2(pruning=True, **pruning_cfg)\n",
    "\n",
    "        print('After fine-tuning')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "        \n",
    "        \n",
    "        # post fine-tuning validation\n",
    "        pruning_cfg['name'] = f\"step_{i}_post_val\"\n",
    "        pruning_cfg['batch'] = 1\n",
    "        validation_model = YOLO(model.trainer.best)\n",
    "        validation_model.model = deepcopy(model.model)\n",
    "        metric = validation_model.val( **pruning_cfg)\n",
    "        current_map = metric.box.map\n",
    "        print(f\"After fine tuning mAP={current_map}\")\n",
    "\n",
    "        print('After post fine-tuning validation')\n",
    "        print('Model', model.model.model[0].conv)\n",
    "        print('Pruner', pruner.model.model[0].conv)\n",
    "    \n",
    "\n",
    "        macs_list.append(pruned_macs)\n",
    "        nparams_list.append(pruned_nparams / base_nparams * 100)\n",
    "        pruned_map_list.append(pruned_map)\n",
    "        map_list.append(current_map)\n",
    "\n",
    "        if init_map - current_map > args.max_map_drop:\n",
    "            print(\"Pruning early stop\")\n",
    "            break\n",
    "\n",
    "\n",
    "    model.export(format='onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098fc1b4-57d5-4a31-a557-920688c094a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b08319-6d07-4e42-9528-3e09a0558e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args(argparse.Namespace):\n",
    "  model = 'yolov8l.pt'\n",
    "  cfg = 'default.yaml'\n",
    "  iterative_steps = 15\n",
    "  target_prune_rate = 0.15\n",
    "  max_map_drop = 0.2\n",
    "  sched = Schedule(partial(sched_onecycle,  α=10, β=4))\n",
    "\n",
    "args=Args()\n",
    "prune(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8afe98d-f6c4-4451-a838-991bb5993134",
   "metadata": {},
   "source": [
    "## Post-Training Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4390e-038c-42a5-a80a-872e35bf1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c68d4-e374-4a2d-b1cd-80374a804725",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = torch.randn(1, 3, 640, 640).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3527bf-bdca-40f0-93d3-42af28b01b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs); base_macs, base_nparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39190b40-3d3b-4844-9da7-c41e9b9aa6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.val(\n",
    "                data='coco128.yaml',\n",
    "                batch=1,\n",
    "                imgsz=640,\n",
    "                verbose=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb54734-cf16-4051-ae58-1e0b03435c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef36d64b-13ff-4480-ae1b-7d302a7857e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export(format = 'onnx', half = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
