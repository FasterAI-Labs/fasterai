{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08159415",
   "metadata": {},
   "source": [
    "---\n",
    "description: Use the pruner in fastai Callback system\n",
    "output-file: tutorial.pruner_callback.html\n",
    "title: Prune Callback\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fasterai.prune.all import *\n",
    "from fasterai.core.criteria import *\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "import torch_pruning as tp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c7e4d",
   "metadata": {},
   "source": [
    "Let's try our `PruneCallback` on the `Pets` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bb548",
   "metadata": {},
   "source": [
    "We'll train a vanilla ResNet18 for 5 epochs to have an idea of the expected performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90051f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_macs, base_params = tp.utils.count_ops_and_params(learn.model, torch.randn(1,3,224,224).to(default_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4aa2b",
   "metadata": {},
   "source": [
    "Let's now try adding to remove some filters in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09415b3b",
   "metadata": {},
   "source": [
    "We'll set the `sparsity` to 50 (i.e. remove 50% of filters), the `context` to global (i.e. we remove filters from anywhere in the network), the `criteria` to large_final (i.e. keep the highest value filters and the `schedule` to one_cycle (i.e. follow the One-Cycle schedule to remove filters along training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff12b7-53dd-4703-a501-919cb4f59d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = Pruner(\n",
    "learn.model,\n",
    "criteria=large_final,\n",
    "pruning_ratio=40, \n",
    "context='global',\n",
    "iterative_steps=, \n",
    "schedule=one_cycle._scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e736a-8d49-4f57-85dd-69707ae8b16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_cb = PruneCallback(pruning_ratio=40, context='global', criteria=large_final, schedule=one_cycle)\n",
    "learn.fit_one_cycle(10, cbs=pr_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(learn.model, torch.randn(1,3,224,224).to(default_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008be12",
   "metadata": {},
   "source": [
    "We observe that our network has lost less than 1% of accuracy. But how much parameters have we removed and how much compute does that save ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391c584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The pruned model has {pruned_macs/base_macs:.2f} the compute of original model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1db56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The pruned model has {pruned_params/base_params:.2f} the parameters of original model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335aaa57",
   "metadata": {},
   "source": [
    "So at the price of a slight decrease in accuracy, we now have a model that is 5x smaller and requires 1.5x fewer compute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
