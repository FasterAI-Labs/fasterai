{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08159415",
   "metadata": {},
   "source": [
    "---\n",
    "description: Use the pruner in fastai Callback system\n",
    "output-file: tutorial.pruner_callback.html\n",
    "title: Prune Callback\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fasterai.prune.all import *\n",
    "from fasterai.core.criteria import *\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "import torch_pruning as tp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c7e4d",
   "metadata": {},
   "source": [
    "Let's try our `PruneCallback` on the `Pets` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bb548",
   "metadata": {},
   "source": [
    "We'll train a vanilla ResNet18 for 5 epochs to have an idea of the expected performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90051f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.612992</td>\n",
       "      <td>0.329872</td>\n",
       "      <td>0.860622</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_macs, base_params = tp.utils.count_ops_and_params(learn.model, torch.randn(1,3,224,224).to(default_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4aa2b",
   "metadata": {},
   "source": [
    "Let's now try adding to remove some filters in our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09415b3b",
   "metadata": {},
   "source": [
    "We'll set the `sparsity` to 50 (i.e. remove 50% of filters), the `context` to global (i.e. we remove filters from anywhere in the network), the `criteria` to large_final (i.e. keep the highest value filters and the `schedule` to one_cycle (i.e. follow the One-Cycle schedule to remove filters along training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff12b7-53dd-4703-a501-919cb4f59d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = Pruner(\n",
    "learn.model,\n",
    "criteria=large_final,\n",
    "pruning_ratio=40, \n",
    "context='global',\n",
    "iterative_steps=, \n",
    "schedule=one_cycle._scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e736a-8d49-4f57-85dd-69707ae8b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920\n",
      "Ignoring output layer: Linear(in_features=512, out_features=2, bias=False)\n",
      "Total ignored layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/24 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pr_cb = PruneCallback(pruning_ratio=40, context='global', criteria=large_final, schedule=one_cycle)\n",
    "learn.fit_one_cycle(10, cbs=pr_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(learn.model, torch.randn(1,3,224,224).to(default_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008be12",
   "metadata": {},
   "source": [
    "We observe that our network has lost less than 1% of accuracy. But how much parameters have we removed and how much compute does that save ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model has 0.63 the compute of original model\n"
     ]
    }
   ],
   "source": [
    "print(f'The pruned model has {pruned_macs/base_macs:.2f} the compute of original model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1db56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model has 0.18 the parameters of original model\n"
     ]
    }
   ],
   "source": [
    "print(f'The pruned model has {pruned_params/base_params:.2f} the parameters of original model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335aaa57",
   "metadata": {},
   "source": [
    "So at the price of a slight decrease in accuracy, we now have a model that is 5x smaller and requires 1.5x fewer compute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
