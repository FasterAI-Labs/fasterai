{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08159415",
   "metadata": {},
   "source": [
    "---\n",
    "description: Use the pruner in fastai Callback system\n",
    "output-file: tutorial.pruner_callback.html\n",
    "title: Prune Callback\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fasterai.prune.all import *\n",
    "from fasterai.core.criteria import *\n",
    "import torch_pruning as tp\n",
    "from torch_pruning.pruner import function\n",
    "import torch_pruning as tp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7c7e4d",
   "metadata": {},
   "source": "## Overview\n\n**Structured Pruning** removes entire filters, channels, or layers from neural networks, resulting in genuinely smaller and faster models. Unlike sparsification (which zeros individual weights), pruning physically removes parameters.\n\n### Why Use Structured Pruning?\n\n| Approach | What's Removed | Model Size | Speed Benefit | Hardware |\n|----------|----------------|------------|---------------|----------|\n| Sparsification | Individual weights | Same | Requires sparse support | Specialized |\n| **Structured Pruning** | Entire filters | **Smaller** | **Immediate** | Standard |\n\n### Key Benefits\n\n- **Real speedup** - Fewer parameters = faster inference on any hardware\n- **Smaller models** - Reduced memory footprint for deployment\n- **Gradual pruning** - Remove filters progressively during training\n- **Flexible targeting** - Global or local pruning strategies\n\n## 1. Setup and Baseline"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bb548",
   "metadata": {},
   "source": "First, train a baseline ResNet-18 to establish expected performance:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90051f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.654544</td>\n",
       "      <td>0.395677</td>\n",
       "      <td>0.853857</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12fc922",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_macs, base_params = tp.utils.count_ops_and_params(learn.model, torch.randn(1,3,224,224).to(default_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4aa2b",
   "metadata": {},
   "source": "## 2. Training with PruneCallback\n\nNow let's train with gradual filter pruning. We'll remove 40% of filters using a one-cycle schedule:"
  },
  {
   "cell_type": "markdown",
   "id": "09415b3b",
   "metadata": {},
   "source": "Configuration:\n- **`pruning_ratio=40`** - Remove 40% of filters\n- **`context='global'`** - Remove least important filters from anywhere in the network\n- **`criteria=large_final`** - Keep filters with largest final weights\n- **`schedule=one_cycle`** - Gradually increase pruning following one-cycle pattern"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ff12b7-53dd-4703-a501-919cb4f59d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring output layer: Linear(in_features=512, out_features=2, bias=False)\n",
      "Total ignored layers: 1\n"
     ]
    }
   ],
   "source": [
    "pruner = Pruner(\n",
    "learn.model,\n",
    "criteria=large_final,\n",
    "pruning_ratio=40, \n",
    "context='global',\n",
    "iterative_steps=3, \n",
    "schedule=one_cycle._scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445e736a-8d49-4f57-85dd-69707ae8b16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring output layer: Linear(in_features=512, out_features=2, bias=False)\n",
      "Total ignored layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.354357</td>\n",
       "      <td>0.313860</td>\n",
       "      <td>0.882950</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.289704</td>\n",
       "      <td>0.273885</td>\n",
       "      <td>0.891746</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.242167</td>\n",
       "      <td>0.244028</td>\n",
       "      <td>0.901218</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219180</td>\n",
       "      <td>0.425877</td>\n",
       "      <td>0.770636</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.153443</td>\n",
       "      <td>0.236760</td>\n",
       "      <td>0.903248</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.175014</td>\n",
       "      <td>0.257431</td>\n",
       "      <td>0.900541</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169409</td>\n",
       "      <td>0.232646</td>\n",
       "      <td>0.912720</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.147067</td>\n",
       "      <td>0.240273</td>\n",
       "      <td>0.910014</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.136972</td>\n",
       "      <td>0.226695</td>\n",
       "      <td>0.916779</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.125311</td>\n",
       "      <td>0.222924</td>\n",
       "      <td>0.916779</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.39%\n",
      "Sparsity at the end of epoch 1: 1.54%\n",
      "Sparsity at the end of epoch 2: 5.60%\n",
      "Sparsity at the end of epoch 3: 15.91%\n",
      "Sparsity at the end of epoch 4: 29.13%\n",
      "Sparsity at the end of epoch 5: 36.64%\n",
      "Sparsity at the end of epoch 6: 39.12%\n",
      "Sparsity at the end of epoch 7: 39.79%\n",
      "Sparsity at the end of epoch 8: 39.96%\n",
      "Sparsity at the end of epoch 9: 40.00%\n"
     ]
    }
   ],
   "source": [
    "pr_cb = PruneCallback(pruning_ratio=40, context='global', criteria=large_final, schedule=one_cycle)\n",
    "learn.fit_one_cycle(10, cbs=pr_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_macs, pruned_params = tp.utils.count_ops_and_params(learn.model, torch.randn(1,3,224,224).to(default_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9008be12",
   "metadata": {},
   "source": "## 3. Measuring Compression\n\nThe pruned model has fewer parameters and requires less compute:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391c584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model has 0.63 the compute of original model\n"
     ]
    }
   ],
   "source": [
    "print(f'The pruned model has {pruned_macs/base_macs:.2f} the compute of original model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1db56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pruned model has 0.18 the parameters of original model\n"
     ]
    }
   ],
   "source": [
    "print(f'The pruned model has {pruned_params/base_params:.2f} the parameters of original model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335aaa57",
   "metadata": {},
   "source": "## Summary\n\n| Metric | Original | Pruned (40%) | Improvement |\n|--------|----------|--------------|-------------|\n| Parameters | 100% | ~18% | **5.5x smaller** |\n| Compute (MACs) | 100% | ~63% | **1.6x fewer ops** |\n| Accuracy | Baseline | ~1% drop | Minimal impact |\n\n### Parameter Reference\n\n| Parameter | Description | Example |\n|-----------|-------------|---------|\n| `pruning_ratio` | Percentage of filters to remove | `40` |\n| `context` | Pruning scope | `'global'` (whole model) or `'local'` (per-layer) |\n| `criteria` | Importance measure | `large_final`, `magnitude`, `taylor` |\n| `schedule` | How pruning increases over training | `one_cycle`, `cos`, `linear` |\n\n---\n\n## See Also\n\n- [Pruner](../../prune/pruner.html) - Lower-level API for one-shot pruning\n- [Sparsifier](../../sparse/sparsifier.html) - For unstructured sparsification\n- [Schedules](../../core/schedules.html) - Available pruning schedules\n- [Criteria](../../core/criteria.html) - Filter importance measures\n- [YOLO Pruning Tutorial](YOLOV8.html) - Pruning detection models"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
