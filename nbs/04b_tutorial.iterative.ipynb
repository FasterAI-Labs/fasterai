{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-floating",
   "metadata": {},
   "source": [
    "# Iterative Pruning\n",
    "\n",
    "> Make your neural network sparse with fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-elder",
   "metadata": {},
   "source": [
    "Researchers have come up with a better way to do pruning than pruning all the weigths in once (as in One-Shot Pruning). The idea is to perform several iterations of pruning and fine-tuning and is thus called Iterative Pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-booth",
   "metadata": {},
   "source": [
    "![alt text](imgs/iterative.pdf \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-browse",
   "metadata": {},
   "source": [
    "1. You first need to train a network\n",
    "2. You then need to remove a part of the weights weights (depending on your criteria, needs,...)\n",
    "3. You fine-tune the remaining weights to recover from the loss of parameters.\n",
    "4. Back to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-circular",
   "metadata": {},
   "source": [
    "With fasterai, this is really easy to do. Let's illustrate it by an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "from fasterai.sparsifier import *\n",
    "from fasterai.criteria import *\n",
    "from fasterai.sparsify_callback import *\n",
    "from fasterai.schedule import iterative\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_image_files(path/\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(f): return f[0].isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-measurement",
   "metadata": {},
   "source": [
    "We will first train a network without any pruning, which will serve as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-camcorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.661170</td>\n",
       "      <td>0.411315</td>\n",
       "      <td>0.862652</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.344798</td>\n",
       "      <td>0.235212</td>\n",
       "      <td>0.901218</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.184619</td>\n",
       "      <td>0.195194</td>\n",
       "      <td>0.923545</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-consideration",
   "metadata": {},
   "source": [
    "## Iterative Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-chemical",
   "metadata": {},
   "source": [
    "There are two main ways that you can perform Iterative Pruning with fasterai. \n",
    "\n",
    "1. You already possess a trained network and want to prune it\n",
    "2. You don't possess such a network and have to train it from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-remove",
   "metadata": {},
   "source": [
    "In this case, your network needs to be trained before pruning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-depression",
   "metadata": {},
   "source": [
    "You only need to create the Callback with the `iterative` schedule and set the `start_epoch` argument, i.e. how many epochs you want to train your network before pruning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative(start, end, pos, n_steps=3):\n",
    "    \"Perform iterative pruning, and pruning in `n_steps` steps\"\n",
    "    return start + ((end-start)/n_steps)*(np.ceil((pos)*n_steps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-witness",
   "metadata": {},
   "source": [
    "The `iterative` schedules has a `n_steps`parameter, i.e. how many iterations of pruning/fine-tuning you want to perform. To modify its value, we can use the `partial` function like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-speed",
   "metadata": {},
   "source": [
    "```\n",
    "iterative = partial(iterative, n_steps=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(sparsity=80, granularity='weight', method='global', criteria=l1_norm, sched_func=iterative, start_epoch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-factor",
   "metadata": {},
   "source": [
    "Let's start pruningn after 3 epochs and train our model for 6 epochs to have the same total amount of training as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 80%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.705333</td>\n",
       "      <td>0.590168</td>\n",
       "      <td>0.826793</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.376754</td>\n",
       "      <td>0.285279</td>\n",
       "      <td>0.892422</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.238135</td>\n",
       "      <td>0.217662</td>\n",
       "      <td>0.916779</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.191392</td>\n",
       "      <td>0.926928</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088618</td>\n",
       "      <td>0.181956</td>\n",
       "      <td>0.936401</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.072037</td>\n",
       "      <td>0.189369</td>\n",
       "      <td>0.935047</td>\n",
       "      <td>01:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 0.00%\n",
      "Sparsity at the end of epoch 1: 0.00%\n",
      "Sparsity at the end of epoch 2: 0.00%\n",
      "Sparsity at the end of epoch 3: 26.67%\n",
      "Sparsity at the end of epoch 4: 53.33%\n",
      "Sparsity at the end of epoch 5: 80.00%\n",
      "Final Sparsity: 80.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(6, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-extent",
   "metadata": {},
   "source": [
    "As you can see, the network sparsity changes over the training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
