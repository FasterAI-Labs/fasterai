{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sparse.criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-process",
   "metadata": {},
   "source": [
    "# Criteria\n",
    "\n",
    ">  Which parameter is important in a neural network ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def l1_norm(m, granularity):\n",
    "\n",
    "    if granularity == 'weight':\n",
    "        w = m.weight.abs()\n",
    "\n",
    "    elif granularity == 'vector':\n",
    "        dim = 3 # dim=1 -> channel vector, dim=2 -> column vector, dim=3 -> row vector\n",
    "        w = (torch.norm(m.weight, p=1, dim=dim)/(m.weight.shape[3])).unsqueeze(dim) # Normalize the norm to be consistent for different dimensions\n",
    "\n",
    "    elif granularity == 'kernel':\n",
    "        w = (torch.norm(m.weight, p=1, dim=(2,3))/(m.weight.shape[2:].numel()))[:,:, None, None]\n",
    "\n",
    "    elif granularity == 'filter':       \n",
    "        w = (torch.norm(m.weight, p=1, dim=(1,2,3))/(m.weight.shape[1:].numel()))[:, None, None, None]\n",
    "\n",
    "    else: raise NameError('Invalid Granularity')\n",
    "\n",
    "    return w\n",
    "\n",
    "def grad_crit(m, granularity):\n",
    "    if m.weight.grad is not None:\n",
    "        if granularity == 'weight':\n",
    "            w = (m.weight*m.weight.grad).data.pow(2)\n",
    "\n",
    "        elif granularity == 'vector':\n",
    "            w = ((m.weight*m.weight.grad).data.pow(2).sum(dim=dim)/(m.weight.shape[3])).unsqueeze(dim)\n",
    "\n",
    "        elif granularity == 'kernel':\n",
    "            w = ((m.weight*m.weight.grad).data.pow(2).sum(dim=(2,3))/(m.weight.shape[2:].numel()))[:,:, None, None]\n",
    "\n",
    "        elif granularity == 'filter':       \n",
    "            w = ((m.weight*m.weight.grad).data.pow(2).sum(dim=(1,2,3))/(m.weight.shape[1:].numel()))[:, None, None, None]\n",
    "\n",
    "        else: raise NameError('Invalid Granularity') \n",
    "\n",
    "        return w\n",
    "\n",
    "def movement(m):\n",
    "    if hasattr(m, '_old_weights') == False:\n",
    "        m.register_buffer(\"_old_weights\", m._init_weights.clone()) # If the previous value of weights is not known, take the initial value\n",
    "\n",
    "    old_weights = getattr(m, \"_init_weights\")\n",
    "\n",
    "    if granularity == 'weight': \n",
    "        w = torch.abs((m.weight.view(-1)).clone()) - torch.abs(old_weights.view(-1).clone())\n",
    "\n",
    "    elif granularity == 'vector': \n",
    "        w = torch.abs(m.weight.sum(dim=(3)).clone()) - torch.abs(old_weights.sum(dim=(3).clone()))\n",
    "\n",
    "    elif granularity == 'kernel': \n",
    "        w = torch.abs(m.weight.sum(dim=(2,3)).clone()) - torch.abs(old_weights.sum(dim=(2,3).clone()))           \n",
    "\n",
    "    elif granularity == 'filter': \n",
    "        w = torch.abs(module.weight.sum(dim=(1,2,3)).clone()) - torch.abs(old_weights.sum(dim=(1,2,3).clone()))\n",
    "\n",
    "    else: raise NameError('Invalid Granularity')\n",
    "\n",
    "    m._old_weights = m.weight.clone() # The current value becomes the old one for the next iteration\n",
    "\n",
    "    return w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
