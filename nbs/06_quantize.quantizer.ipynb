{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5a33dc9c",
   "metadata": {},
   "source": [
    "---\n",
    "description: Quantize your network \n",
    "output-file: quantizer.html\n",
    "title: Quantizer\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1856ae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp quantize.quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.ao.quantization import get_default_qconfig_mapping\n",
    "import torch.ao.quantization.quantize_fx as quantize_fx\n",
    "from torch.ao.quantization.quantize_fx import convert_fx, prepare_fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "from fastai.vision.all import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1cacc1-3f19-40d7-bf98-87277872c711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mprepare_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mqconfig_mapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQConfigMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexample_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprepare_custom_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrepareCustomConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_equalization_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQConfigMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbackend_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mao\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBackendConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mprepare_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mqconfig_mapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQConfigMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mexample_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprepare_custom_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPrepareCustomConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0m_equalization_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mQConfigMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbackend_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBackendConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGraphModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\" Prepare a model for post training quantization\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m      * `model` (torch.nn.Module): torch.nn.Module model\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m      * `qconfig_mapping` (QConfigMapping): QConfigMapping object to configure how a model is\u001b[0m\n",
       "\u001b[0;34m         quantized, see :class:`~torch.ao.quantization.qconfig_mapping.QConfigMapping`\u001b[0m\n",
       "\u001b[0;34m         for more details\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m      * `example_inputs` (Tuple[Any, ...]): Example inputs for forward function of the model,\u001b[0m\n",
       "\u001b[0;34m         Tuple of positional args (keyword args can be passed as positional args as well)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m      * `prepare_custom_config` (PrepareCustomConfig): customization configuration for quantization tool.\u001b[0m\n",
       "\u001b[0;34m          See :class:`~torch.ao.quantization.fx.custom_config.PrepareCustomConfig` for more details\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m      * `_equalization_config`: config for specifying how to perform equalization on the model\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m      * `backend_config` (BackendConfig): config that specifies how operators are quantized\u001b[0m\n",
       "\u001b[0;34m         in a backend, this includes how the operators are observed,\u001b[0m\n",
       "\u001b[0;34m         supported fusion patterns, how quantize/dequantize ops are\u001b[0m\n",
       "\u001b[0;34m         inserted, supported dtypes etc. See :class:`~torch.ao.quantization.backend_config.BackendConfig` for more details\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Return:\u001b[0m\n",
       "\u001b[0;34m      A GraphModule with observer (configured by qconfig_mapping), ready for calibration\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Example::\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        import torch\u001b[0m\n",
       "\u001b[0;34m        from torch.ao.quantization import get_default_qconfig_mapping\u001b[0m\n",
       "\u001b[0;34m        from torch.ao.quantization.quantize_fx import prepare_fx\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        class Submodule(torch.nn.Module):\u001b[0m\n",
       "\u001b[0;34m            def __init__(self):\u001b[0m\n",
       "\u001b[0;34m                super().__init__()\u001b[0m\n",
       "\u001b[0;34m                self.linear = torch.nn.Linear(5, 5)\u001b[0m\n",
       "\u001b[0;34m            def forward(self, x):\u001b[0m\n",
       "\u001b[0;34m                x = self.linear(x)\u001b[0m\n",
       "\u001b[0;34m                return x\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        class M(torch.nn.Module):\u001b[0m\n",
       "\u001b[0;34m            def __init__(self):\u001b[0m\n",
       "\u001b[0;34m                super().__init__()\u001b[0m\n",
       "\u001b[0;34m                self.linear = torch.nn.Linear(5, 5)\u001b[0m\n",
       "\u001b[0;34m                self.sub = Submodule()\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m            def forward(self, x):\u001b[0m\n",
       "\u001b[0;34m                x = self.linear(x)\u001b[0m\n",
       "\u001b[0;34m                x = self.sub(x) + x\u001b[0m\n",
       "\u001b[0;34m                return x\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # initialize a floating point model\u001b[0m\n",
       "\u001b[0;34m        float_model = M().eval()\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # define calibration function\u001b[0m\n",
       "\u001b[0;34m        def calibrate(model, data_loader):\u001b[0m\n",
       "\u001b[0;34m            model.eval()\u001b[0m\n",
       "\u001b[0;34m            with torch.no_grad():\u001b[0m\n",
       "\u001b[0;34m                for image, target in data_loader:\u001b[0m\n",
       "\u001b[0;34m                    model(image)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # qconfig is the configuration for how we insert observers for a particular\u001b[0m\n",
       "\u001b[0;34m        # operator\u001b[0m\n",
       "\u001b[0;34m        # qconfig = get_default_qconfig(\"fbgemm\")\u001b[0m\n",
       "\u001b[0;34m        # Example of customizing qconfig:\u001b[0m\n",
       "\u001b[0;34m        # qconfig = torch.ao.quantization.QConfig(\u001b[0m\n",
       "\u001b[0;34m        #    activation=MinMaxObserver.with_args(dtype=torch.qint8),\u001b[0m\n",
       "\u001b[0;34m        #    weight=MinMaxObserver.with_args(dtype=torch.qint8))\u001b[0m\n",
       "\u001b[0;34m        # `activation` and `weight` are constructors of observer module\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # qconfig_mapping is a collection of quantization configurations, user can\u001b[0m\n",
       "\u001b[0;34m        # set the qconfig for each operator (torch op calls, functional calls, module calls)\u001b[0m\n",
       "\u001b[0;34m        # in the model through qconfig_mapping\u001b[0m\n",
       "\u001b[0;34m        # the following call will get the qconfig_mapping that works best for models\u001b[0m\n",
       "\u001b[0;34m        # that target \"fbgemm\" backend\u001b[0m\n",
       "\u001b[0;34m        qconfig_mapping = get_default_qconfig_mapping(\"fbgemm\")\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # We can customize qconfig_mapping in different ways.\u001b[0m\n",
       "\u001b[0;34m        # e.g. set the global qconfig, which means we will use the same qconfig for\u001b[0m\n",
       "\u001b[0;34m        # all operators in the model, this can be overwritten by other settings\u001b[0m\n",
       "\u001b[0;34m        # qconfig_mapping = QConfigMapping().set_global(qconfig)\u001b[0m\n",
       "\u001b[0;34m        # e.g. quantize the linear submodule with a specific qconfig\u001b[0m\n",
       "\u001b[0;34m        # qconfig_mapping = QConfigMapping().set_module_name(\"linear\", qconfig)\u001b[0m\n",
       "\u001b[0;34m        # e.g. quantize all nn.Linear modules with a specific qconfig\u001b[0m\n",
       "\u001b[0;34m        # qconfig_mapping = QConfigMapping().set_object_type(torch.nn.Linear, qconfig)\u001b[0m\n",
       "\u001b[0;34m        # for a more complete list, please see the docstring for :class:`torch.ao.quantization.QConfigMapping`\u001b[0m\n",
       "\u001b[0;34m        # argument\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # example_inputs is a tuple of inputs, that is used to infer the type of the\u001b[0m\n",
       "\u001b[0;34m        # outputs in the model\u001b[0m\n",
       "\u001b[0;34m        # currently it's not used, but please make sure model(*example_inputs) runs\u001b[0m\n",
       "\u001b[0;34m        example_inputs = (torch.randn(1, 3, 224, 224),)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # TODO: add backend_config after we split the backend_config for fbgemm and qnnpack\u001b[0m\n",
       "\u001b[0;34m        # e.g. backend_config = get_default_backend_config(\"fbgemm\")\u001b[0m\n",
       "\u001b[0;34m        # `prepare_fx` inserts observers in the model based on qconfig_mapping and\u001b[0m\n",
       "\u001b[0;34m        # backend_config. If the configuration for an operator in qconfig_mapping\u001b[0m\n",
       "\u001b[0;34m        # is supported in the backend_config (meaning it's supported by the target\u001b[0m\n",
       "\u001b[0;34m        # hardware), we'll insert observer modules according to the qconfig_mapping\u001b[0m\n",
       "\u001b[0;34m        # otherwise the configuration in qconfig_mapping will be ignored\u001b[0m\n",
       "\u001b[0;34m        #\u001b[0m\n",
       "\u001b[0;34m        # Example:\u001b[0m\n",
       "\u001b[0;34m        # in qconfig_mapping, user sets linear module to be quantized with quint8 for\u001b[0m\n",
       "\u001b[0;34m        # activation and qint8 for weight:\u001b[0m\n",
       "\u001b[0;34m        # qconfig = torch.ao.quantization.QConfig(\u001b[0m\n",
       "\u001b[0;34m        #     observer=MinMaxObserver.with_args(dtype=torch.quint8),\u001b[0m\n",
       "\u001b[0;34m        #     weight=MinMaxObserver.with-args(dtype=torch.qint8))\u001b[0m\n",
       "\u001b[0;34m        # Note: current qconfig api does not support setting output observer, but\u001b[0m\n",
       "\u001b[0;34m        # we may extend this to support these more fine grained control in the\u001b[0m\n",
       "\u001b[0;34m        # future\u001b[0m\n",
       "\u001b[0;34m        #\u001b[0m\n",
       "\u001b[0;34m        # qconfig_mapping = QConfigMapping().set_object_type(torch.nn.Linear, qconfig)\u001b[0m\n",
       "\u001b[0;34m        # in backend config, linear module also supports in this configuration:\u001b[0m\n",
       "\u001b[0;34m        # weighted_int8_dtype_config = DTypeConfig(\u001b[0m\n",
       "\u001b[0;34m        #   input_dtype=torch.quint8,\u001b[0m\n",
       "\u001b[0;34m        #   output_dtype=torch.quint8,\u001b[0m\n",
       "\u001b[0;34m        #   weight_dtype=torch.qint8,\u001b[0m\n",
       "\u001b[0;34m        #   bias_type=torch.float)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # linear_pattern_config = BackendPatternConfig(torch.nn.Linear) \\\u001b[0m\n",
       "\u001b[0;34m        #    .set_observation_type(ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT) \\\u001b[0m\n",
       "\u001b[0;34m        #    .add_dtype_config(weighted_int8_dtype_config) \\\u001b[0m\n",
       "\u001b[0;34m        #    ...\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        # backend_config = BackendConfig().set_backend_pattern_config(linear_pattern_config)\u001b[0m\n",
       "\u001b[0;34m        # `prepare_fx` will check that the setting requested by suer in qconfig_mapping\u001b[0m\n",
       "\u001b[0;34m        # is supported by the backend_config and insert observers and fake quant modules\u001b[0m\n",
       "\u001b[0;34m        # in the model\u001b[0m\n",
       "\u001b[0;34m        prepared_model = prepare_fx(float_model, qconfig_mapping, example_inputs)\u001b[0m\n",
       "\u001b[0;34m        # Run calibration\u001b[0m\n",
       "\u001b[0;34m        calibrate(prepared_model, sample_inference_data)\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"quantization_api.quantize_fx.prepare_fx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m_prepare_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mqconfig_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# is_qat\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprepare_custom_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0m_equalization_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbackend_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/ao/quantization/quantize_fx.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepare_fx??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88ee70-e77b-41bb-9754-d0379122bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_default_qconfig_mapping(\"x86\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b711b44-9112-48cb-a671-92ded90bd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.observer import *\n",
    "from torch.ao.quantization.qconfig_mapping import *\n",
    "from torch.ao.quantization.qconfig import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b3667-7e12-4976-82d0-cbdb81c690c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconfig = torch.ao.quantization.QConfig(\n",
    "            activation=MinMaxObserver.with_args(dtype=torch.qint8),\n",
    "            weight=MinMaxObserver.with_args(dtype=torch.qint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f6ffc-3347-471f-b890-ec466e5add0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8){})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e9f0a-2b7e-4266-81be-51eeb71b413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconfig_mapping = get_default_qconfig_mapping(\"x86\")\n",
    "\n",
    "qconfig = torch.ao.quantization.QConfig(\n",
    "            activation=MinMaxObserver.with_args(dtype=torch.qint8),\n",
    "            weight=MinMaxObserver.with_args(dtype=torch.quint8))\n",
    "\n",
    "qconfig_mapping.set_global(qconfig)\n",
    "\n",
    "x, _ = dls.valid.one_batch()\n",
    "model_prepared = prepare_fx(model.eval(), qconfig_mapping, x\n",
    "\n",
    "convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60181084-0e7c-4ec1-af27-17e591e8345f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f51780-1699-48a7-9cca-0913681de77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02a6a2-5f3b-43c4-b2f4-9f88eaf47b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.ao.quantization import get_default_qconfig_mapping\n",
    "import torch.ao.quantization.quantize_fx as quantize_fx\n",
    "from torch.ao.quantization.quantize_fx import convert_fx, prepare_fx\n",
    "\n",
    "# %% ../../nbs/06_quantize.quantizer.ipynb 4\n",
    "class Quantizer():\n",
    "    def __init__(self, backend=\"x86\"):\n",
    "        self.qconfig = get_default_qconfig_mapping(backend)\n",
    "    \n",
    "    def quantize(self, model, calibration_dl):\n",
    "        x, _ = calibration_dl.valid.one_batch()\n",
    "        model_prepared = prepare_fx(model.eval(), self.qconfig, x)\n",
    "        _ = [model_prepared(xb.to('cpu')) for xb, _ in calibration_dl.valid]\n",
    "            \n",
    "        return convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50facf59-92b3-49b8-81dd-e91df23f48b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c9798-7334-4cda-8f41-03195f90f6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.03916042298078537, zero_point=0, padding=(3, 3))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.034414783120155334, zero_point=135, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10346762835979462, zero_point=99, padding=(1, 1))\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07803963869810104, zero_point=150, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1477663815021515, zero_point=154, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0938093438744545, zero_point=145, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2231246680021286, zero_point=153, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.08568578958511353, zero_point=143, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.13219939172267914, zero_point=130, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.12116639316082001, zero_point=132)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10290561616420746, zero_point=163, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1333627998828888, zero_point=152, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.11892875283956528, zero_point=138, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.17234939336776733, zero_point=143, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.15155480802059174, zero_point=160, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.26260507106781006, zero_point=130, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.23813869059085846, zero_point=137, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.254102498292923, zero_point=109, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.16449806094169617, zero_point=131)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.255676805973053, zero_point=106, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2000371366739273, zero_point=151, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1978582888841629, zero_point=145, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.31975799798965454, zero_point=160, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.15835610032081604, zero_point=147, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.32871541380882263, zero_point=148, padding=(1, 1))\n",
       "    )\n",
       "    (4): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1602625995874405, zero_point=146, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.4190238118171692, zero_point=135, padding=(1, 1))\n",
       "    )\n",
       "    (5): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.15976759791374207, zero_point=153, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.6285133957862854, zero_point=168, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.17346984148025513, zero_point=145, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.15855780243873596, zero_point=167, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.19657236337661743, zero_point=118)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.12368176132440567, zero_point=157, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1558169573545456, zero_point=164, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.14525258541107178, zero_point=171, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.27562740445137024, zero_point=161, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (global_pool): Module(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.6697565913200378, zero_point=104, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "pretrained_resnet_34 = timm.create_model('resnet34', pretrained=True)\n",
    "qt = Quantizer(granularity='tensor')\n",
    "\n",
    "q_model = qt.quantize(pretrained_resnet_34, dls); q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461c402-4a60-4b55-9dd7-297f340cd690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.03916042298078537, zero_point=0, padding=(3, 3))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.034414783120155334, zero_point=135, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10346762835979462, zero_point=99, padding=(1, 1))\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07803963869810104, zero_point=150, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1477663815021515, zero_point=154, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0938093438744545, zero_point=145, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2231246680021286, zero_point=153, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.08568578958511353, zero_point=143, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.13219939172267914, zero_point=130, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.12116639316082001, zero_point=132)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10290561616420746, zero_point=163, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1333627998828888, zero_point=152, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.11892875283956528, zero_point=138, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.17234939336776733, zero_point=143, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.15155480802059174, zero_point=160, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.26260507106781006, zero_point=130, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.23813869059085846, zero_point=137, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.254102498292923, zero_point=109, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.16449806094169617, zero_point=131)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.255676805973053, zero_point=106, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2000371366739273, zero_point=151, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1978582888841629, zero_point=145, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.31975799798965454, zero_point=160, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.15835610032081604, zero_point=147, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.32871541380882263, zero_point=148, padding=(1, 1))\n",
       "    )\n",
       "    (4): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.1602625995874405, zero_point=146, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.4190238118171692, zero_point=135, padding=(1, 1))\n",
       "    )\n",
       "    (5): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.15976759791374207, zero_point=153, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.6285133957862854, zero_point=168, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.17346984148025513, zero_point=145, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.15855780243873596, zero_point=167, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.19657236337661743, zero_point=118)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.12368176132440567, zero_point=157, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1558169573545456, zero_point=164, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.14525258541107178, zero_point=171, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.27562740445137024, zero_point=161, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (global_pool): Module(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.6697565913200378, zero_point=104, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a785165d-98e7-4419-b69c-5d5fa96ce5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a962a5-6ab5-4fa4-9291-3a5d145a9182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd0754-2109-48f8-a76b-cb5f6a7638c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9022cd-9d38-48d7-9ec3-bf7eb5524afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1bc-4e90-4945-8815-398ea783f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = dls.valid.one_batch()\n",
    "model_prepared = prepare_fx(model.eval(), qconfig_mapping, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d5dc6-aba4-4ccd-bb22-2a14b23ba364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): ConvReLU2d(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Module(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Module(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "      )\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (global_pool): Module(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6257d5-4e4c-440f-83c2-dfffc5341a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization as quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5c239-edc0-4220-8ff1-8925a96755cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quantizer:\n",
    "    def __init__(self, activation_observer=MinMaxObserver, \n",
    "                 weight_observer=PerChannelMinMaxObserver,\n",
    "                 activation_qtype=torch.quint8, weight_qtype=torch.qint8,\n",
    "                 granularity='channel'):\n",
    "        self.activation_observer = activation_observer\n",
    "        self.weight_observer = weight_observer\n",
    "        self.activation_qtype = activation_qtype\n",
    "        self.weight_qtype = weight_qtype\n",
    "        self.granularity = granularity\n",
    "\n",
    "    def prepare_qconfig(self):\n",
    "        if self.granularity == 'tensor':\n",
    "            qconfig = quant.QConfig(\n",
    "                activation=self.activation_observer.with_args(dtype=self.activation_qtype),\n",
    "                weight=self.weight_observer.with_args(dtype=self.weight_qtype)\n",
    "            )\n",
    "        elif self.granularity == 'channel':\n",
    "            qconfig = quant.QConfig(\n",
    "                activation=self.activation_observer.with_args(dtype=self.activation_qtype),\n",
    "                weight=self.weight_observer.with_args(dtype=self.weight_qtype, qscheme=torch.per_channel_symmetric)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Granularity must be 'tensor' or 'channel'\")\n",
    "        return qconfig\n",
    "\n",
    "    def quantize(self, model, calibration_dl):\n",
    "        qconfig = self.prepare_qconfig()\n",
    "        #qconfig_mapping = get_default_qconfig_mapping(\"x86\")\n",
    "        qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "        #qconfig_mapping = qconfig_mapping.set_global(qconfig)\n",
    "\n",
    "        \n",
    "        #qconfig = get_default_qconfig(\"x86\")\n",
    "        #qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "\n",
    "        \n",
    "        #print(qconfig_mapping)\n",
    "        \n",
    "        x, _ = calibration_dl.valid.one_batch()\n",
    "\n",
    "        model_prepared = quantize_fx.prepare_fx(model.eval(), qconfig_mapping, x)\n",
    "        \n",
    "        _ = [model_prepared(xb.to('cpu')) for xb, _ in calibration_dl.valid]\n",
    "\n",
    "        model_quantized = quantize_fx.convert_fx(model_prepared)\n",
    "        return model_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a0126-f28f-4536-bae8-211f763b5ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_qconfig():\n",
    "        qconfig = quant.QConfig(\n",
    "                activation=HistogramObserver.with_args(reduce_range=True, dtype=torch.quint8),\n",
    "                weight=PerChannelMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_channel_symmetric)\n",
    "            )\n",
    "        return qconfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a34c11-e3e4-4937-83f8-55360ee1b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71238e-af40-4076-b425-9ba62c83e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfigMapping (\n",
      " global_qconfig\n",
      "  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True, dtype=torch.quint8){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      " object_type_qconfigs\n",
      "  OrderedDict()\n",
      " module_name_regex_qconfigs\n",
      "  OrderedDict()\n",
      " module_name_qconfigs\n",
      "  OrderedDict()\n",
      " module_name_object_type_order_qconfigs\n",
      "  OrderedDict()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.0586698092520237, zero_point=0, padding=(3, 3))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05712748318910599, zero_point=73, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.18472586572170258, zero_point=40, padding=(1, 1))\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1304682344198227, zero_point=70, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.22737379372119904, zero_point=86, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.13824054598808289, zero_point=76, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2884523868560791, zero_point=78, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.12035684287548065, zero_point=71, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.18092282116413116, zero_point=69, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.1676047295331955, zero_point=65)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.15122142434120178, zero_point=83, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1486966460943222, zero_point=79, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.192796990275383, zero_point=77, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.2337365448474884, zero_point=84, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1911012828350067, zero_point=90, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.31719857454299927, zero_point=65, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.3262193500995636, zero_point=75, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.3559166193008423, zero_point=58, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.2244267761707306, zero_point=65)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.3229292631149292, zero_point=70, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2822004556655884, zero_point=77, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.23272879421710968, zero_point=89, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.37436699867248535, zero_point=73, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.24542182683944702, zero_point=76, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.4782363772392273, zero_point=79, padding=(1, 1))\n",
       "    )\n",
       "    (4): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.22176529467105865, zero_point=79, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.5768976807594299, zero_point=78, padding=(1, 1))\n",
       "    )\n",
       "    (5): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2168983519077301, zero_point=82, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.8886998891830444, zero_point=90, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.23399946093559265, zero_point=75, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.23325596749782562, zero_point=85, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.34827449917793274, zero_point=59)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.20107585191726685, zero_point=86, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.20108701288700104, zero_point=79, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.2110409289598465, zero_point=89, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.32835322618484497, zero_point=78, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (global_pool): Module(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=1.1136842966079712, zero_point=57, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qconfig = prepare_qconfig()\n",
    "qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "print(qconfig_mapping)\n",
    "\n",
    "model = timm.create_model('resnet34', pretrained=True)\n",
    "x, _ = dls.valid.one_batch()\n",
    "model_prepared = quantize_fx.prepare_fx(model.eval(), qconfig_mapping, x)\n",
    "_ = [model_prepared(xb.to('cpu')) for xb, _ in dls.valid]\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared); model_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfbc329-5b14-4840-942a-b45ce25cd7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b6c74-2bb1-4301-8d3f-eecb44ef0312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dccc605-0b3f-4744-a6f4-19ccbdf26a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QConfigMapping (\n",
      " global_qconfig\n",
      "  QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.HistogramObserver'>, reduce_range=True){}, weight=functools.partial(<class 'torch.ao.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric){})\n",
      " object_type_qconfigs\n",
      "  OrderedDict()\n",
      " module_name_regex_qconfigs\n",
      "  OrderedDict()\n",
      " module_name_qconfigs\n",
      "  OrderedDict()\n",
      " module_name_object_type_order_qconfigs\n",
      "  OrderedDict()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.0586698092520237, zero_point=0, padding=(3, 3))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.05712748318910599, zero_point=73, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.18472586572170258, zero_point=40, padding=(1, 1))\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.1304682344198227, zero_point=70, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.22737379372119904, zero_point=86, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.13824054598808289, zero_point=76, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.2884523868560791, zero_point=78, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.12035684287548065, zero_point=71, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.18092282116413116, zero_point=69, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.1676047295331955, zero_point=65)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.15122142434120178, zero_point=83, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1486966460943222, zero_point=79, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.192796990275383, zero_point=77, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.2337365448474884, zero_point=84, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1911012828350067, zero_point=90, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.31719857454299927, zero_point=65, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.3262193500995636, zero_point=75, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.3559166193008423, zero_point=58, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.2244267761707306, zero_point=65)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.3229292631149292, zero_point=70, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2822004556655884, zero_point=77, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.23272879421710968, zero_point=89, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.37436699867248535, zero_point=73, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.24542182683944702, zero_point=76, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.4782363772392273, zero_point=79, padding=(1, 1))\n",
       "    )\n",
       "    (4): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.22176529467105865, zero_point=79, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.5768976807594299, zero_point=78, padding=(1, 1))\n",
       "    )\n",
       "    (5): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2168983519077301, zero_point=82, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.8886998891830444, zero_point=90, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.23399946093559265, zero_point=75, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.23325596749782562, zero_point=85, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.34827449917793274, zero_point=59)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.20107585191726685, zero_point=86, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.20108701288700104, zero_point=79, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.2110409289598465, zero_point=89, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.32835322618484497, zero_point=78, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (global_pool): Module(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=1.1136842966079712, zero_point=57, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qconfig = prepare_qconfig()\n",
    "#qconfig_mapping = get_default_qconfig_mapping(\"x86\")\n",
    "qconfig = get_default_qconfig(\"x86\")\n",
    "qconfig_mapping = QConfigMapping().set_global(qconfig)\n",
    "#qconfig_mapping = qconfig_mapping.set_global(qconfig); \n",
    "print(qconfig_mapping)\n",
    "\n",
    "model = timm.create_model('resnet34', pretrained=True)\n",
    "x, _ = dls.valid.one_batch()\n",
    "model_prepared = quantize_fx.prepare_fx(model.eval(), qconfig_mapping, x)\n",
    "_ = [model_prepared(xb.to('cpu')) for xb, _ in dls.valid]\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared); model_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4930fa2-55d3-4c92-80db-910b14f414ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quantized(x.to('cpu')).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6765956f-e7f9-4c5d-84b8-23f278fe4fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe661a8-7e76-4dba-a9ae-f918ac4d6420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321367f7-4a56-4497-841f-75e8cd649662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ef0db-9218-468b-a48a-0f6a9c1a121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class Quantizer():\n",
    "    def __init__(self, backend=\"x86\"):\n",
    "        self.qconfig_mapping = get_default_qconfig_mapping(backend)\n",
    "        self.qconfig = torch.ao.quantization.QConfig(\n",
    "            activation=MinMaxObserver.with_args(dtype=torch.qint8),\n",
    "            weight=MinMaxObserver.with_args(dtype=torch.qint8))\n",
    "        self.qconfig_mapping = self.qconfig_mapping.set_global(self.qconfig)\n",
    "    \n",
    "    def quantize(self, model, calibration_dl):\n",
    "        x, _ = calibration_dl.valid.one_batch()\n",
    "        model_prepared = prepare_fx(model.eval(), self.qconfig_mapping, x)\n",
    "        _ = [model_prepared(xb.to('cpu')) for xb, _ in calibration_dl.valid]\n",
    "            \n",
    "        return convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7ed85-e565-4ede-af67-4277d9d6df3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/nathanhubens/fasterai/tree/master/blob/master/fasterai/quantize/quantizer.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Quantizer\n",
       "\n",
       ">      Quantizer (activation_observer=<class\n",
       ">                 'torch.ao.quantization.observer.MinMaxObserver'>,\n",
       ">                 weight_observer=<class\n",
       ">                 'torch.ao.quantization.observer.MinMaxObserver'>,\n",
       ">                 activation_qtype=torch.qint8, weight_qtype=torch.quint8,\n",
       ">                 granularity='tensor')\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/nathanhubens/fasterai/tree/master/blob/master/fasterai/quantize/quantizer.py#L16){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Quantizer\n",
       "\n",
       ">      Quantizer (activation_observer=<class\n",
       ">                 'torch.ao.quantization.observer.MinMaxObserver'>,\n",
       ">                 weight_observer=<class\n",
       ">                 'torch.ao.quantization.observer.MinMaxObserver'>,\n",
       ">                 activation_qtype=torch.qint8, weight_qtype=torch.quint8,\n",
       ">                 granularity='tensor')\n",
       "\n",
       "Initialize self.  See help(type(self)) for accurate signature."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17555b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()\n",
    "\n",
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109868d-b9d7-40b7-8fe2-1672f55a7a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.03994439169764519, zero_point=0, padding=(3, 3))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.0350755974650383, zero_point=129, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.10775818675756454, zero_point=105, padding=(1, 1))\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.07896550744771957, zero_point=148, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.15020190179347992, zero_point=155, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.09426897019147873, zero_point=146, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.20375744998455048, zero_point=156, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer2): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.08102598786354065, zero_point=135, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.14021606743335724, zero_point=125, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.11898498237133026, zero_point=123)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10020500421524048, zero_point=168, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.10859350860118866, zero_point=165, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.13375234603881836, zero_point=126, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.1900726854801178, zero_point=139, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.16172252595424652, zero_point=165, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.2634170353412628, zero_point=130, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer3): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.2651125490665436, zero_point=136, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2561491131782532, zero_point=101, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.22120125591754913, zero_point=103)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.280063658952713, zero_point=100, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.2203514575958252, zero_point=147, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.18013906478881836, zero_point=156, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.284829705953598, zero_point=154, padding=(1, 1))\n",
       "    )\n",
       "    (3): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.16133826971054077, zero_point=134, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.34921708703041077, zero_point=149, padding=(1, 1))\n",
       "    )\n",
       "    (4): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.14920611679553986, zero_point=149, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.4331035614013672, zero_point=138, padding=(1, 1))\n",
       "    )\n",
       "    (5): Module(\n",
       "      (conv1): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.14942212402820587, zero_point=149, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.5795217752456665, zero_point=178, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (layer4): Module(\n",
       "    (0): Module(\n",
       "      (conv1): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.16258913278579712, zero_point=144, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1643662452697754, zero_point=165, padding=(1, 1))\n",
       "      (downsample): Module(\n",
       "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.19744457304477692, zero_point=105)\n",
       "      )\n",
       "    )\n",
       "    (1): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1236722469329834, zero_point=159, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.15787488222122192, zero_point=147, padding=(1, 1))\n",
       "    )\n",
       "    (2): Module(\n",
       "      (conv1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.14230094850063324, zero_point=174, padding=(1, 1))\n",
       "      (drop_block): Identity()\n",
       "      (act1): ReLU(inplace=True)\n",
       "      (aa): Identity()\n",
       "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.291374146938324, zero_point=175, padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (global_pool): Module(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.631743311882019, zero_point=106, qscheme=torch.per_channel_affine)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "pretrained_resnet_34 = timm.create_model('resnet34', pretrained=True)\n",
    "qt = Quantizer(granularity='tensor')\n",
    "\n",
    "q_model = qt.quantize(pretrained_resnet_34, dls); q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde7873c-25be-4159-b867-2910bb4a1e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.3 ms ± 2.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "q_model(x.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdf35f-1734-40ec-9e1d-d5614e22f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_resnet_34 = timm.create_model('resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d29af-fb90-427c-810a-fb1d88cb313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 ms ± 70.1 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pretrained_resnet_34(x.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184c93c-4aba-41d0-a3fa-16ca98a29538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389838df-36c8-4d74-8ee1-d8136b7fdd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.qint8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.conv1.weight().dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92897f27-f920-4a10-ac52-23581d331b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49fe5e8-ceea-40f3-95cc-f8cb133e64c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ec4eef-9baa-4cf0-9801-87f8d43b5d87",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConvReLU2d' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mq_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConvReLU2d' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "q_model.conv1.weight()[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70457121",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model = resnet18()\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model.fc = nn.Linear(512, 2)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m qt \u001b[38;5;241m=\u001b[39m Quantizer()\n\u001b[0;32m----> 6\u001b[0m q_model \u001b[38;5;241m=\u001b[39m \u001b[43mqt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdls\u001b[49m\u001b[43m)\u001b[49m; q_model\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36mQuantizer.quantize\u001b[0;34m(self, model, calibration_dl)\u001b[0m\n\u001b[1;32m      7\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m calibration_dl\u001b[38;5;241m.\u001b[39mvalid\u001b[38;5;241m.\u001b[39mone_batch()\n\u001b[1;32m      8\u001b[0m model_prepared \u001b[38;5;241m=\u001b[39m prepare_fx(model\u001b[38;5;241m.\u001b[39meval(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqconfig, x)\n\u001b[0;32m----> 9\u001b[0m _ \u001b[38;5;241m=\u001b[39m [model_prepared(xb\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m xb, _ \u001b[38;5;129;01min\u001b[39;00m calibration_dl\u001b[38;5;241m.\u001b[39mvalid]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convert_fx(model_prepared)\n",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m calibration_dl\u001b[38;5;241m.\u001b[39mvalid\u001b[38;5;241m.\u001b[39mone_batch()\n\u001b[1;32m      8\u001b[0m model_prepared \u001b[38;5;241m=\u001b[39m prepare_fx(model\u001b[38;5;241m.\u001b[39meval(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqconfig, x)\n\u001b[0;32m----> 9\u001b[0m _ \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel_prepared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m xb, _ \u001b[38;5;129;01min\u001b[39;00m calibration_dl\u001b[38;5;241m.\u001b[39mvalid]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convert_fx(model_prepared)\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/fx/graph_module.py:738\u001b[0m, in \u001b[0;36mGraphModule.recompile.<locals>.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 738\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/fx/graph_module.py:304\u001b[0m, in \u001b[0;36m_WrappedCall.__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_call(obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m e\u001b[38;5;241m.\u001b[39m__traceback__\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m<eval_with_key>.8:21\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m layer1_1_conv2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconv2(activation_post_process_6);  activation_post_process_6 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m activation_post_process_7 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_post_process_7(layer1_1_conv2);  layer1_1_conv2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m add_1 \u001b[38;5;241m=\u001b[39m \u001b[43mactivation_post_process_7\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mactivation_post_process_5\u001b[49m;  activation_post_process_7 \u001b[38;5;241m=\u001b[39m activation_post_process_5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m layer1_1_relu_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrelu(add_1);  add_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     23\u001b[0m activation_post_process_8 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_post_process_8(layer1_1_relu_1);  layer1_1_relu_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/fastai/torch_core.py:382\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 382\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mifnone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fasterai/lib/python3.9/site-packages/torch/_tensor.py:1418\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1418\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1420\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#model = resnet18()\n",
    "#model.fc = nn.Linear(512, 2)\n",
    "\n",
    "qt = Quantizer()\n",
    "\n",
    "q_model = qt.quantize(model, dls); q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1da9963-82d9-4b5a-8bfe-0c39624fb475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
