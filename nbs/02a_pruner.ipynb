{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b72694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sparse.pruner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3d7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "from fasterai.sparse.all import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f0c21",
   "metadata": {},
   "source": [
    "> Important: The Pruner method currently works on fully-feedforward ConvNets, e.g. VGG16. Support for residual connections, e.g. ResNets is under development."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b31e6",
   "metadata": {},
   "source": [
    "When our network has filters containing zero values, there is an additional step that we may take. Indeed, those zero-filters can be **physically** removed from our network, allowing us to get a new, dense, architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e314e62",
   "metadata": {},
   "source": [
    "This can be done by reexpressing each layer, reducing the number of filter, to match the number of non-zero filters. However, when we remove a filter in a layer, this means that there will be a missing activation map, which should be used by all the filters in the next layer. So, not only should we physically remove the filter, but also its corresponding kernel in each of the filters in the next layer (see Fig. below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8d044",
   "metadata": {},
   "source": [
    "![alt text](imgs/pruning_filters.pdf \"Pruning Filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb7d131",
   "metadata": {},
   "source": [
    "Let's illustrate this with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-constraint",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976388b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a8b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pruner():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def filters_to_keep(self, layer, nxt_layer):\n",
    "        \n",
    "        ixs = self._get_nz_ixs(layer)\n",
    "    \n",
    "        filters_keep = layer.weight.index_select(0, ixs[0]).data # keep only the non_zero filters\n",
    "        biases_keep = layer.bias.index_select(0, ixs[0]).data\n",
    "        \n",
    "        nxt_filters_keep = nxt_layer.weight.index_select(1, ixs[0]).data if nxt_layer is not None else None\n",
    "            \n",
    "        return filters_keep, biases_keep, nxt_filters_keep\n",
    "    \n",
    "    def prune_conv(self, layer, nxt_layer):\n",
    "        assert layer.__class__.__name__ == 'Conv2d'\n",
    "    \n",
    "        new_weights, new_biases, new_next_weights = self.filters_to_keep(layer, nxt_layer)\n",
    "    \n",
    "        layer.out_channels = new_weights.shape[0]\n",
    "        layer.in_channels = new_weights.shape[1]\n",
    "    \n",
    "        layer.weight = nn.Parameter(new_weights)\n",
    "        layer.bias = nn.Parameter(new_biases)\n",
    "\n",
    "        if new_next_weights is not None:\n",
    "            new_next_in_channels = new_next_weights.shape[1]\n",
    "            nxt_layer.weight = nn.Parameter(new_next_weights)\n",
    "            nxt_layer.in_channels = new_next_in_channels\n",
    "    \n",
    "        return layer, nxt_layer\n",
    "    \n",
    "    def prune_bn(self, layer, prev_conv):\n",
    "        \n",
    "        ixs = self._get_nz_ixs(prev_conv)\n",
    "        \n",
    "        weights_keep = layer.weight.data.index_select(0, ixs[0]).data\n",
    "    \n",
    "        layer.num_features = weights_keep.shape[0]\n",
    "        layer.weight = nn.Parameter(weights_keep)\n",
    "        layer.bias = nn.Parameter(layer.bias.data.index_select(0, ixs[0]).data)\n",
    "        layer.running_mean = layer.running_mean.data.index_select(0, ixs[0]).data\n",
    "        layer.running_var = layer.running_var.data.index_select(0, ixs[0]).data\n",
    "        \n",
    "        return layer\n",
    "\n",
    "    def delete_fc_weights(self, layer, last_conv, pool_shape):\n",
    "        \n",
    "        ixs = self._get_nz_ixs(last_conv)\n",
    "        \n",
    "        new_ixs = torch.cat([torch.arange(i*pool_shape**2,((i+1)*pool_shape**2)) for i in ixs[0]]) if pool_shape else ixs[0]\n",
    "        new_ixs = torch.LongTensor(new_ixs).cuda()\n",
    "\n",
    "        weights_keep = layer.weight.data.index_select(1, new_ixs).data\n",
    "        \n",
    "        layer.in_features = weights_keep.shape[1]\n",
    "        layer.weight = nn.Parameter(weights_keep)\n",
    "    \n",
    "        return layer\n",
    "    \n",
    "    def _get_nz_ixs(self, layer):\n",
    "        filters = layer.weight\n",
    "        nz_filters = filters.data.sum(dim=(1,2,3)) # Flatten the filters to compare them\n",
    "        ixs = torch.nonzero(nz_filters).T\n",
    "        return ixs.cuda()\n",
    "    \n",
    "    def _find_next_conv(self, model, conv_ix):\n",
    "        for k,m in enumerate(model.modules()):\n",
    "            if k > conv_ix and isinstance(m, nn.Conv2d):\n",
    "                next_conv_ix = k\n",
    "                break\n",
    "            else:\n",
    "                next_conv_ix = None\n",
    "        return next_conv_ix\n",
    "    \n",
    "    def _find_previous_conv(self, model, layer_ix):\n",
    "        for k,m in reversed(list(enumerate(model.modules()))):\n",
    "            if k < layer_ix and isinstance(m, nn.Conv2d):\n",
    "                prev_conv_ix = k\n",
    "                break\n",
    "            else:\n",
    "                prev_conv_ix = None\n",
    "        return prev_conv_ix    \n",
    "    \n",
    "    def _get_last_conv_ix(self, model):\n",
    "        for k,m in enumerate(list(model.modules())):\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                last_conv_ix = k\n",
    "        return last_conv_ix\n",
    "    \n",
    "    def _get_first_fc_ix(self, model):\n",
    "        for k,m in enumerate(list(model.modules())):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                first_fc_ix = k\n",
    "                break       \n",
    "        return first_fc_ix\n",
    "    \n",
    "    def _find_pool_shape(self, model):\n",
    "        for k,m in enumerate(model.modules()):\n",
    "            if isinstance(m, nn.AdaptiveAvgPool2d):\n",
    "                output_shape = m.output_size\n",
    "                break\n",
    "            else: output_shape=None\n",
    "        return output_shape    \n",
    "    \n",
    "    def prune_model(self, model):\n",
    "        pruned_model = copy.deepcopy(model)\n",
    "        \n",
    "        layer_names = list(dict(pruned_model.named_modules()).keys())\n",
    "        layers = dict(pruned_model.named_modules())\n",
    "        old_layers = dict(model.named_modules())\n",
    "        \n",
    "        last_conv_ix = self._get_last_conv_ix(pruned_model)\n",
    "        first_fc_ix = self._get_first_fc_ix(pruned_model)\n",
    "        \n",
    "        for k,m in enumerate(list(pruned_model.modules())):\n",
    "            \n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                next_conv_ix = self._find_next_conv(model, k)\n",
    "                if next_conv_ix is not None: # The conv layer is not the last one\n",
    "                    new_m, new_next_m = self.prune_conv(m, layers[layer_names[next_conv_ix]]) # Prune the current conv layer\n",
    "                else:\n",
    "                    new_m, _ = self.prune_conv(m, None) # Prune the current conv layer without changing the next one\n",
    "                    \n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                new_m = self.prune_bn(m, old_layers[layer_names[self._find_previous_conv(model, k)]])             \n",
    "                    \n",
    "            if isinstance(m, nn.Linear) and k==first_fc_ix:\n",
    "                pool_shape = self._find_pool_shape(model)\n",
    "                new_m = self.delete_fc_weights(m, old_layers[layer_names[last_conv_ix]], pool_shape[0])\n",
    "\n",
    "        return pruned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, vgg16_bn(num_classes=2), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14878a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134277186"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50855518",
   "metadata": {},
   "source": [
    "Our initial model, a VGG16, possess more than 134 million parameters. Let's see what happens when we make it sparse, on a filter level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(end_sparsity=50, granularity='filter', method='local', criteria=large_final, sched_func=sched_onecycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004fbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of filter until a sparsity of 50%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.630026</td>\n",
       "      <td>0.764953</td>\n",
       "      <td>0.685386</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.609164</td>\n",
       "      <td>0.562719</td>\n",
       "      <td>0.719892</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.541365</td>\n",
       "      <td>0.497277</td>\n",
       "      <td>0.746279</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Weights at epoch 0\n",
      "Sparsity at the end of epoch 0: 10.43%\n",
      "Sparsity at the end of epoch 1: 48.29%\n",
      "Sparsity at the end of epoch 2: 50.00%\n",
      "Final Sparsity: 50.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 1e-3, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5584e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134277186"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d79e3",
   "metadata": {},
   "source": [
    "The total amount of parameters hasn't changed! This is because we only replaced the values by zeroes, leading to a sparse model, but they are still there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f9ebf",
   "metadata": {},
   "source": [
    "The `Pruner` will take care of removing those useless filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f08805",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = Pruner()\n",
    "pruned_model = pruner.prune_model(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efbcd78",
   "metadata": {},
   "source": [
    "Done! Let's see if the performance is still the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4cf9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_learn = Learner(dls, pruned_model.cuda(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb74090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.4975821375846863,0.7435724139213562]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f93e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71858210"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(pruned_learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7fd1a",
   "metadata": {},
   "source": [
    "Now we have 71 million of parameters, approximately 50% of the initial parameters as we asked!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
