{
 "cells": [
  {
   "cell_type": "raw",
   "id": "08159415",
   "metadata": {},
   "source": [
    "---\n",
    "description: Use the sparsifier in fastai Callback system\n",
    "output-file: tutorial.sparsify_callback.html\n",
    "title: Sparsify Callback\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1749ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "from fasterai.sparse.all import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73f2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6944fb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c13f6",
   "metadata": {},
   "source": [
    "The most important part of our `Callback` happens in `before_batch`. There, we first compute the sparsity of our network according to our schedule and then we remove the parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7750dd9c-2e32-4610-9305-e7c07d2c4bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bce769fabbb54b29ad1a6ae456b9ecbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/87.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import timm\n",
    "pretrained_resnet_34 = timm.create_model('resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7040df1-588f-42cf-be98-e19d7c4b3f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of filter until a sparsity of [50]%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.434834</td>\n",
       "      <td>0.498019</td>\n",
       "      <td>0.758457</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.409158</td>\n",
       "      <td>0.432628</td>\n",
       "      <td>0.809202</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.338707</td>\n",
       "      <td>0.371978</td>\n",
       "      <td>0.832206</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.274749</td>\n",
       "      <td>0.368416</td>\n",
       "      <td>0.854533</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.237638</td>\n",
       "      <td>0.373818</td>\n",
       "      <td>0.849797</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: [1.96]%\n",
      "Sparsity at the end of epoch 1: [20.07]%\n",
      "Sparsity at the end of epoch 2: [45.86]%\n",
      "Sparsity at the end of epoch 3: [49.74]%\n",
      "Sparsity at the end of epoch 4: [50.0]%\n",
      "Final Sparsity: [50.0]%\n",
      "Sparsity in Conv2d 1: 50.00%\n",
      "Sparsity in Conv2d 7: 53.12%\n",
      "Sparsity in Conv2d 12: 50.47%\n",
      "Sparsity in Conv2d 16: 50.00%\n",
      "Sparsity in Conv2d 21: 50.53%\n",
      "Sparsity in Conv2d 25: 50.00%\n",
      "Sparsity in Conv2d 30: 50.41%\n",
      "Sparsity in Conv2d 35: 50.00%\n",
      "Sparsity in Conv2d 40: 50.24%\n",
      "Sparsity in Conv2d 44: 50.00%\n",
      "Sparsity in Conv2d 47: 50.00%\n",
      "Sparsity in Conv2d 52: 50.24%\n",
      "Sparsity in Conv2d 56: 50.00%\n",
      "Sparsity in Conv2d 61: 50.38%\n",
      "Sparsity in Conv2d 65: 50.00%\n",
      "Sparsity in Conv2d 70: 50.11%\n",
      "Sparsity in Conv2d 75: 50.00%\n",
      "Sparsity in Conv2d 80: 50.12%\n",
      "Sparsity in Conv2d 84: 50.00%\n",
      "Sparsity in Conv2d 87: 50.00%\n",
      "Sparsity in Conv2d 92: 50.09%\n",
      "Sparsity in Conv2d 96: 50.00%\n",
      "Sparsity in Conv2d 101: 50.10%\n",
      "Sparsity in Conv2d 105: 50.00%\n",
      "Sparsity in Conv2d 110: 50.03%\n",
      "Sparsity in Conv2d 114: 50.00%\n",
      "Sparsity in Conv2d 119: 50.11%\n",
      "Sparsity in Conv2d 123: 50.00%\n",
      "Sparsity in Conv2d 128: 50.12%\n",
      "Sparsity in Conv2d 133: 50.00%\n",
      "Sparsity in Conv2d 138: 50.08%\n",
      "Sparsity in Conv2d 142: 50.00%\n",
      "Sparsity in Conv2d 145: 50.01%\n",
      "Sparsity in Conv2d 150: 50.14%\n",
      "Sparsity in Conv2d 154: 50.00%\n",
      "Sparsity in Conv2d 159: 50.28%\n"
     ]
    }
   ],
   "source": [
    "learn = Learner(dls, pretrained_resnet_34, metrics=accuracy)\n",
    "learn.fc = nn.Linear(512, 2)\n",
    "sp_cb = SparsifyCallback(sparsity=50, granularity='filter', context='global', criteria=large_final, schedule=one_cycle)\n",
    "learn.fit_one_cycle(5, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ce1d4-4a86-4106-9843-ceac897bd25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00, -0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          ...,\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
       "           -0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00,  0.0000e+00],\n",
       "          ...,\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00]],\n",
       "\n",
       "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          ...,\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00],\n",
       "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
       "           -0.0000e+00, -0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-7.4296e-03, -7.5463e-03, -8.3205e-03,  ..., -7.1928e-02,\n",
       "            1.5917e-01,  1.2489e-01],\n",
       "          [ 1.0137e-01, -5.4320e-03, -7.5936e-03,  ..., -4.2560e-01,\n",
       "           -1.0976e-02,  1.9817e-01],\n",
       "          [ 1.2293e-01,  2.8018e-01,  3.2716e-01,  ..., -6.7938e-01,\n",
       "           -4.9350e-01, -1.6077e-02],\n",
       "          ...,\n",
       "          [-1.8629e-01, -1.9095e-01, -2.0495e-02,  ...,  5.9457e-01,\n",
       "           -1.7923e-02, -2.3116e-01],\n",
       "          [-1.1156e-01, -2.5112e-01, -3.7146e-01,  ...,  3.9388e-01,\n",
       "            2.8940e-01, -1.7420e-02],\n",
       "          [-9.4251e-03, -1.6436e-02, -3.3763e-01,  ..., -1.1631e-02,\n",
       "            1.7691e-01,  1.0555e-01]],\n",
       "\n",
       "         [[-8.8509e-03, -6.3883e-03, -5.0388e-03,  ...,  4.3923e-03,\n",
       "            1.0098e-01,  6.4890e-03],\n",
       "          [-7.3702e-03, -2.3618e-03, -2.8961e-03,  ..., -2.6874e-01,\n",
       "           -2.7887e-03,  1.6050e-01],\n",
       "          [-5.0071e-03,  1.6799e-01,  2.7184e-01,  ..., -5.8726e-01,\n",
       "           -3.1158e-01, -6.8676e-03],\n",
       "          ...,\n",
       "          [-1.5120e-01, -2.3115e-01, -1.0500e-01,  ...,  4.9077e-01,\n",
       "           -8.2684e-03, -1.3619e-01],\n",
       "          [-7.1860e-03, -1.8193e-01, -3.3559e-01,  ...,  2.7722e-01,\n",
       "            1.6240e-01, -9.3599e-03],\n",
       "          [-2.4150e-03, -7.1116e-03, -1.8751e-01,  ..., -1.6245e-04,\n",
       "            1.1394e-01, -8.0694e-03]],\n",
       "\n",
       "         [[-3.9283e-03, -3.3088e-03, -3.5065e-03,  ...,  3.9558e-03,\n",
       "            1.9028e-03,  3.6099e-03],\n",
       "          [-1.2535e-03,  1.3431e-03, -7.3769e-04,  ..., -2.8860e-03,\n",
       "           -3.9271e-03, -4.3433e-03],\n",
       "          [ 1.9957e-03,  6.6360e-03,  2.0233e-03,  ..., -1.9471e-01,\n",
       "           -7.5721e-03, -8.9046e-03],\n",
       "          ...,\n",
       "          [-4.8502e-03, -9.2381e-02, -7.7613e-02,  ...,  1.2395e-01,\n",
       "           -1.0181e-02, -9.2624e-03],\n",
       "          [ 1.8123e-03, -3.5798e-03, -1.1415e-01,  ..., -5.0590e-03,\n",
       "           -8.1797e-03, -9.5528e-03],\n",
       "          [ 5.2121e-03, -2.0169e-04,  1.2455e-03,  ...,  1.7431e-03,\n",
       "           -4.9568e-03, -8.3131e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 7.8349e-03,  1.3473e-02,  8.7682e-02,  ...,  1.4227e-01,\n",
       "            1.4403e-02,  1.1514e-02],\n",
       "          [ 5.7151e-03,  1.5254e-01, -1.6662e-01,  ..., -1.9651e-01,\n",
       "            9.3270e-03,  9.1108e-03],\n",
       "          [ 8.3750e-02, -6.4736e-02, -7.7611e-02,  ...,  1.6225e-01,\n",
       "           -2.5000e-01,  2.0282e-01],\n",
       "          ...,\n",
       "          [-9.0023e-02,  1.0453e-01, -1.6298e-01,  ..., -1.1992e-01,\n",
       "            3.8632e-03, -1.2307e-01],\n",
       "          [ 1.1366e-02,  1.7510e-01, -2.6541e-01,  ...,  5.9963e-03,\n",
       "           -2.4098e-01,  2.6635e-01],\n",
       "          [ 9.7180e-03,  1.6214e-01, -2.6019e-01,  ..., -1.3749e-01,\n",
       "           -6.4509e-02, -1.0232e-03]],\n",
       "\n",
       "         [[ 1.8908e-02,  2.6516e-02, -8.7681e-02,  ...,  2.7610e-02,\n",
       "            2.3307e-02,  1.2432e-01],\n",
       "          [ 1.5978e-02,  1.7737e-02,  2.3648e-02,  ...,  2.1288e-02,\n",
       "            1.9111e-02, -1.5350e-01],\n",
       "          [ 1.8378e-02, -8.8506e-02,  3.1728e-01,  ..., -2.9368e-01,\n",
       "            5.7689e-01, -1.4814e-01],\n",
       "          ...,\n",
       "          [-7.0136e-02,  2.9066e-02, -6.5593e-02,  ...,  3.0752e-03,\n",
       "           -3.0135e-01,  1.3104e-01],\n",
       "          [ 1.6101e-02,  2.9628e-01, -1.2312e-01,  ...,  1.9397e-01,\n",
       "            2.5778e-01,  5.0888e-03],\n",
       "          [ 1.4030e-02, -2.0212e-01,  3.2355e-01,  ...,  7.0312e-03,\n",
       "            8.5274e-03, -1.1626e-01]],\n",
       "\n",
       "         [[ 1.8303e-02,  2.4612e-02,  2.9882e-02,  ..., -9.8176e-02,\n",
       "            2.3368e-02,  1.9999e-02],\n",
       "          [ 1.5427e-02,  1.6103e-02,  1.4962e-01,  ...,  2.1504e-01,\n",
       "            1.8854e-02,  1.6187e-01],\n",
       "          [-5.3391e-02,  1.4294e-01, -2.2367e-01,  ...,  1.3511e-02,\n",
       "           -1.8316e-01, -8.3739e-02],\n",
       "          ...,\n",
       "          [ 2.1427e-01, -1.5982e-01,  1.8060e-01,  ..., -9.3084e-02,\n",
       "            4.8867e-01, -1.2281e-01],\n",
       "          [ 9.6726e-03, -3.7949e-01,  3.9740e-01,  ..., -1.5790e-01,\n",
       "           -1.5290e-01, -1.8989e-01],\n",
       "          [ 7.3821e-03,  7.1633e-03,  2.5753e-03,  ..., -3.3214e-03,\n",
       "            1.5466e-01, -6.4393e-03]]],\n",
       "\n",
       "\n",
       "        [[[ 1.4643e-01,  5.8291e-03, -9.3539e-02,  ..., -1.0934e-01,\n",
       "           -6.7021e-02,  1.4150e-02],\n",
       "          [-1.4916e-01, -3.0628e-01, -3.8497e-01,  ..., -3.3362e-01,\n",
       "           -2.2944e-01, -1.6075e-01],\n",
       "          [-1.6706e-01, -2.8656e-01, -3.0256e-01,  ..., -2.0954e-01,\n",
       "           -1.3465e-01,  9.8437e-03],\n",
       "          ...,\n",
       "          [ 5.5858e-03,  6.4734e-03,  1.8051e-01,  ...,  3.8381e-01,\n",
       "            3.5352e-01,  2.8040e-01],\n",
       "          [ 8.6895e-03,  1.1563e-01,  2.1870e-01,  ...,  3.3523e-01,\n",
       "            2.3642e-01,  1.5989e-01],\n",
       "          [ 9.8079e-02,  1.6960e-01,  2.1411e-01,  ...,  1.8952e-01,\n",
       "            6.1990e-03,  1.1999e-02]],\n",
       "\n",
       "         [[ 1.7169e-01,  3.0308e-03, -1.3982e-01,  ..., -1.6779e-01,\n",
       "           -1.0978e-01,  7.9350e-03],\n",
       "          [-1.9304e-01, -4.0593e-01, -5.3100e-01,  ..., -4.6119e-01,\n",
       "           -3.2400e-01, -2.0214e-01],\n",
       "          [-2.8363e-01, -4.3816e-01, -4.9162e-01,  ..., -3.1524e-01,\n",
       "           -2.1846e-01, -8.9559e-02],\n",
       "          ...,\n",
       "          [ 4.0925e-03,  2.3280e-03,  2.0114e-01,  ...,  4.4946e-01,\n",
       "            4.0134e-01,  3.4598e-01],\n",
       "          [ 1.1379e-01,  1.8643e-01,  3.1593e-01,  ...,  4.7618e-01,\n",
       "            3.8119e-01,  3.1284e-01],\n",
       "          [ 1.8202e-01,  2.5852e-01,  3.0201e-01,  ...,  3.2789e-01,\n",
       "            1.8261e-01,  1.0490e-01]],\n",
       "\n",
       "         [[ 1.4723e-01, -1.3924e-02, -1.1114e-02,  ..., -3.3590e-03,\n",
       "           -3.8765e-03, -9.1093e-04],\n",
       "          [-1.7495e-02, -1.6472e-01, -2.6806e-01,  ..., -2.4088e-01,\n",
       "           -1.9225e-01, -1.3964e-01],\n",
       "          [-1.1816e-01, -2.2255e-01, -2.8439e-01,  ..., -1.7405e-01,\n",
       "           -1.1457e-01, -9.2854e-03],\n",
       "          ...,\n",
       "          [-1.5639e-02, -1.7753e-02, -2.0895e-02,  ...,  2.2529e-01,\n",
       "            1.7778e-01,  1.4106e-01],\n",
       "          [-1.3705e-02, -1.7075e-02,  9.4111e-02,  ...,  2.2573e-01,\n",
       "            1.6869e-01,  1.2757e-01],\n",
       "          [ 1.0739e-01,  1.3187e-01,  1.1567e-01,  ...,  1.6808e-01,\n",
       "            1.1086e-01,  8.2069e-02]]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model.conv1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90051f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.711885</td>\n",
       "      <td>1.064277</td>\n",
       "      <td>0.843708</td>\n",
       "      <td>00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.409735</td>\n",
       "      <td>0.217008</td>\n",
       "      <td>0.913396</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.265280</td>\n",
       "      <td>0.284833</td>\n",
       "      <td>0.898512</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144334</td>\n",
       "      <td>0.158726</td>\n",
       "      <td>0.936401</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082726</td>\n",
       "      <td>0.153889</td>\n",
       "      <td>0.939784</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4aa2b",
   "metadata": {},
   "source": [
    "Let's now try adding some sparsity in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1821ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f373da5",
   "metadata": {},
   "source": [
    "The `SparsifyCallback` requires a new argument compared to the `Sparsifier`. Indeed, we need to know the pruning schedule that we should follow during training in order to prune the parameters accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d931837",
   "metadata": {},
   "source": [
    "You can use any scheduling function already [available](https://docs.fast.ai/callback.schedule.html#Annealing) in fastai or come up with your own ! For more information about the pruning schedules, take a look at the [Schedules section](https://nathanhubens.github.io/fasterai/schedules.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f7c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb = SparsifyCallback(sparsity=50, granularity='weight', context='local', criteria=large_final, schedule=one_cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3044be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of [50]%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.711270</td>\n",
       "      <td>0.742762</td>\n",
       "      <td>0.775372</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.383374</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.864005</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.219235</td>\n",
       "      <td>0.217708</td>\n",
       "      <td>0.905954</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121921</td>\n",
       "      <td>0.213659</td>\n",
       "      <td>0.933018</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.067208</td>\n",
       "      <td>0.200506</td>\n",
       "      <td>0.930988</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: [1.96]%\n",
      "Sparsity at the end of epoch 1: [20.07]%\n",
      "Sparsity at the end of epoch 2: [45.86]%\n",
      "Sparsity at the end of epoch 3: [49.74]%\n",
      "Sparsity at the end of epoch 4: [50.0]%\n",
      "Final Sparsity: [50.0]%\n",
      "Sparsity in Conv2d 2: 50.00%\n",
      "Sparsity in Conv2d 8: 50.00%\n",
      "Sparsity in Conv2d 11: 50.00%\n",
      "Sparsity in Conv2d 14: 50.00%\n",
      "Sparsity in Conv2d 17: 50.00%\n",
      "Sparsity in Conv2d 21: 50.00%\n",
      "Sparsity in Conv2d 24: 50.00%\n",
      "Sparsity in Conv2d 27: 50.00%\n",
      "Sparsity in Conv2d 30: 50.00%\n",
      "Sparsity in Conv2d 33: 50.00%\n",
      "Sparsity in Conv2d 37: 50.00%\n",
      "Sparsity in Conv2d 40: 50.00%\n",
      "Sparsity in Conv2d 43: 50.00%\n",
      "Sparsity in Conv2d 46: 50.00%\n",
      "Sparsity in Conv2d 49: 50.00%\n",
      "Sparsity in Conv2d 53: 50.00%\n",
      "Sparsity in Conv2d 56: 50.00%\n",
      "Sparsity in Conv2d 59: 50.00%\n",
      "Sparsity in Conv2d 62: 50.00%\n",
      "Sparsity in Conv2d 65: 50.00%\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e0077b",
   "metadata": {},
   "source": [
    "Surprisingly, our network that is composed of $50 \\%$ of zeroes performs reasonnably well when compared to our plain and dense network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb827347",
   "metadata": {},
   "source": [
    "The `SparsifyCallback` also accepts a list of sparsities, corresponding to each layer of `layer_type` to be pruned. Below, we show how to prune only the intermediate layers of ResNet-18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7801b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsities = [0, 0, 0, 0, 0, 0, 50, 50, 50, 50, 50, 50, 50, 50, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_cb = SparsifyCallback(sparsity=sparsities, granularity='weight', context='local', criteria=large_final, schedule=cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9693eaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of [0, 0, 0, 0, 0, 0, 50, 50, 50, 50, 50, 50, 50, 50, 0, 0, 0, 0, 0, 0]%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.731650</td>\n",
       "      <td>0.570400</td>\n",
       "      <td>0.811908</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396108</td>\n",
       "      <td>0.262083</td>\n",
       "      <td>0.895805</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250992</td>\n",
       "      <td>0.210679</td>\n",
       "      <td>0.909337</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132799</td>\n",
       "      <td>0.192091</td>\n",
       "      <td>0.925575</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.079732</td>\n",
       "      <td>0.159255</td>\n",
       "      <td>0.938430</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.77, 4.77, 4.77, 4.77, 4.77, 4.77, 4.77, 4.77, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]%\n",
      "Sparsity at the end of epoch 1: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.27, 17.27, 17.27, 17.27, 17.27, 17.27, 17.27, 17.27, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]%\n",
      "Sparsity at the end of epoch 2: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 32.73, 32.73, 32.73, 32.73, 32.73, 32.73, 32.73, 32.73, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]%\n",
      "Sparsity at the end of epoch 3: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 45.23, 45.23, 45.23, 45.23, 45.23, 45.23, 45.23, 45.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]%\n",
      "Sparsity at the end of epoch 4: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]%\n",
      "Final Sparsity: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]%\n",
      "Sparsity in Conv2d 2: 0.00%\n",
      "Sparsity in Conv2d 8: 0.00%\n",
      "Sparsity in Conv2d 11: 0.00%\n",
      "Sparsity in Conv2d 14: 0.00%\n",
      "Sparsity in Conv2d 17: 0.00%\n",
      "Sparsity in Conv2d 21: 0.00%\n",
      "Sparsity in Conv2d 24: 50.00%\n",
      "Sparsity in Conv2d 27: 50.00%\n",
      "Sparsity in Conv2d 30: 50.00%\n",
      "Sparsity in Conv2d 33: 50.00%\n",
      "Sparsity in Conv2d 37: 50.00%\n",
      "Sparsity in Conv2d 40: 50.00%\n",
      "Sparsity in Conv2d 43: 50.00%\n",
      "Sparsity in Conv2d 46: 50.00%\n",
      "Sparsity in Conv2d 49: 0.00%\n",
      "Sparsity in Conv2d 53: 0.00%\n",
      "Sparsity in Conv2d 56: 0.00%\n",
      "Sparsity in Conv2d 59: 0.00%\n",
      "Sparsity in Conv2d 62: 0.00%\n",
      "Sparsity in Conv2d 65: 0.00%\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46323843",
   "metadata": {},
   "source": [
    "On top of that, the `SparsifyCallback`can also take many optionnal arguments: \n",
    "\n",
    "- `lth`: whether training using the Lottery Ticket Hypothesis, i.e. reset the weights to their original value at each pruning step (more information in the Lottery Ticket Hypothesis section)\n",
    "- `rewind_epoch`: the epoch used as a reference for the Lottery Ticket Hypothesis with Rewinding (default to 0)\n",
    "- `reset_end`: whether you want to reset the weights to their original values after training (pruning masks are still applied)\n",
    "- `save_tickets`: whether to save intermediate winning tickets.\n",
    "- `model`: pass a model or a part of the model if you don't want to apply pruning on the whole model trained.\n",
    "- `round_to`: if specified, the weights will be pruned to the closest multiple value of `round_to`.\n",
    "- `layer_type`: specify the type of layer that you want to apply pruning to (default to nn.Conv2d)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39090448",
   "metadata": {},
   "source": [
    "For example, we correctly pruned the convolution layers of our model, but we could imagine pruning the Linear Layers of even only the BatchNorm ones !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
