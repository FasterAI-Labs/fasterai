{
 "cells": [
  {
   "cell_type": "raw",
   "id": "98b78fa6",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: overview.html\n",
    "title: Overview\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2e983",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "![](https://capsule-render.vercel.app/api?type=waving&color=008080&height=300&section=header&text=fasterai%20&fontSize=90&animation=fadeIn&fontAlignY=38&desc=A%20Library%20to%20make%20smaller%20and%20faster%20neural%20networks&descAlignY=51&descAlign=62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab51ae",
   "metadata": {},
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "    <a href=\"https://pypi.org/project/fasterai/\"><img src=\"https://img.shields.io/pypi/v/fasterai?color=00a89e\"></a>\n",
    "    <a href=\"https://www.apache.org/licenses/LICENSE-2.0\"><img src=\"https://img.shields.io/github/license/nathanhubens/fasterai?color=00a89e\"></a>\n",
    "    <a href=\"https://pypi.org/project/fasterai/\"><img src=\"https://img.shields.io/badge/DOI-10.5281%2Fzenodo.6469868-y?color=00a89e\"></a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3adcb00",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <a href=\"#methods\">Methods</a> •\n",
    "  <a href=\"#features\">Features</a> •\n",
    "  <a href=\"#installation\">Installation</a> •\n",
    "  <a href=\"#tutorials\">Tutorials</a> •\n",
    "  <a href=\"#citing\">Citing</a> •\n",
    "  <a href=\"#license\">License</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c69e26",
   "metadata": {},
   "source": [
    "`fasterai` is a library created to make neural network **smaller** and **faster**. It essentially relies on common compression techniques for networks such as pruning, knowledge distillation, Lottery Ticket Hypothesis, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145cf969",
   "metadata": {},
   "source": "The core feature of `fasterai` is its Sparsifying capabilities, constructed around 4 main modules: **granularity**, **context**, **criteria**, **schedule**. Each of these modules is highly customizable, allowing you to change them according to your needs or even to come up with your own!"
  },
  {
   "cell_type": "markdown",
   "id": "ea4741cc",
   "metadata": {},
   "source": [
    "## Project Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80e3c1",
   "metadata": {},
   "source": [
    "Visit [Read The Docs Project Page](https://nathanhubens.github.io/fasterai/) or read following README to know more about using `fasterai`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4890a5c",
   "metadata": {},
   "source": "---"
  },
  {
   "cell_type": "markdown",
   "id": "6654d1bb",
   "metadata": {},
   "source": [
    "##  Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f6ffff",
   "metadata": {},
   "source": [
    "### 1. Sparsifying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3753d21",
   "metadata": {},
   "source": [
    "![](imgs/sparsification.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26a7c69",
   "metadata": {},
   "source": [
    "Make your model sparse according to a: <br>\n",
    "- <b>Sparsity: </b> the percentage of weights that will be replaced by 0 <br>\n",
    "- <b>Granularity: </b> the granularity at which you operate the pruning (removing weights, vectors, kernels, filters) <br>\n",
    "- <b>Context: </b> prune either each layer independantly (local pruning) or the whole model (global pruning) <br>\n",
    "- <b>Criteria: </b> the criteria used to select the weights to remove (magnitude, movement, ...) <br>\n",
    "- <b>Schedule: </b> which schedule you want to use for pruning (one shot, iterative, gradual, ...) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c918aa1",
   "metadata": {},
   "source": [
    "This can be achieved by using the `SparsifyCallback(sparsity, granularity, context, criteria, schedule)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54709b41",
   "metadata": {},
   "source": [
    "### 2. Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54d80b",
   "metadata": {},
   "source": [
    "![](imgs/pruning_readme.png \"Pruning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7c8f8",
   "metadata": {},
   "source": [
    "Once your model has useless nodes due to zero-weights, they can be removed to not be a part of the network anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017559c4",
   "metadata": {},
   "source": [
    "This can be achieved by using the `PruneCallback(sparsity, context, criteria, schedule)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c21ee8",
   "metadata": {},
   "source": [
    "### 3. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8851fa",
   "metadata": {},
   "source": [
    "![](imgs/regularization.png \"Regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835c369",
   "metadata": {},
   "source": [
    "Instead of explicitely make your network sparse, let it train towards sparse connections by pushing the weights to be as small as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e27e0f8",
   "metadata": {},
   "source": [
    "Regularization can be applied to groups of weights, following the same granularities as for sparsifying, i.e.:\n",
    "- <b>Granularity: </b> the granularity at which you operate the regularization (weights, vectors, kernels, filters, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d87749",
   "metadata": {},
   "source": [
    "This can be achieved by using the `RegularizationCallback(granularity)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3823924e",
   "metadata": {},
   "source": [
    "### 4. Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef28540",
   "metadata": {},
   "source": [
    "![alt text](imgs/distillation.png \"Distillation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e05d172",
   "metadata": {},
   "source": [
    "Distill the knowledge acquired by a big model into a smaller one, by using the `KnowledgeDistillation` callback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899d310",
   "metadata": {},
   "source": [
    "### 5. Lottery Ticket Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d8b5e",
   "metadata": {},
   "source": [
    "![](imgs/LTH.png \"Lottery Ticket Hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b13459",
   "metadata": {},
   "source": [
    "Find the winning ticket in you network, *i.e.* the initial subnetwork able to attain at least similar performances than the network as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85868f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5xvp6sdy6d",
   "metadata": {},
   "source": "## The FasterAI Ecosystem\n\nfasterai is part of a family of libraries designed to make neural network optimization accessible:\n\n| Package | Purpose | When to Use |\n|---------|---------|-------------|\n| **fasterai** | Compression techniques | Pruning, sparsification, distillation, quantization during training |\n| **fasterbench** | Benchmarking | Measuring model size, speed, memory, compute, and energy |\n| **fasterlatency** | Latency prediction | Hardware-aware neural architecture search |\n| **fasterrecipes** | High-level workflows | Quick compression with sensible defaults |\n\n### Typical Workflow\n\n1. **Benchmark** your model with `fasterbench` to identify bottlenecks\n2. **Compress** using `fasterai` techniques (pruning, distillation, quantization)\n3. **Validate** compression impact with `fasterbench`\n4. **Deploy** the optimized model\n\nOr use `fasterrecipes` for one-line compression with sensible defaults!"
  },
  {
   "cell_type": "markdown",
   "id": "ce70c57f",
   "metadata": {},
   "source": [
    "##  Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6715dd",
   "metadata": {},
   "source": [
    "### 0. Import fasterai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc96fda",
   "metadata": {},
   "source": [
    "```python\n",
    "from fasterai.sparse.all import *\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4eb8d",
   "metadata": {},
   "source": [
    "### 1. Create your model with fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fd842",
   "metadata": {},
   "source": [
    "```python\n",
    "learn = cnn_learner(dls, model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be58c4f",
   "metadata": {},
   "source": [
    "### 2. Get you Fasterai Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cba1a2f",
   "metadata": {},
   "source": [
    "```python\n",
    "sp_cb=SparsifyCallback(sparsity, granularity, context, criteria, schedule)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7204ead4",
   "metadata": {},
   "source": [
    "### 3. Train you model to make it sparse !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8c884",
   "metadata": {},
   "source": [
    "```python\n",
    "learn.fit_one_cycle(n_epochs, cbs=sp_cb)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86880e92",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897d7368",
   "metadata": {},
   "source": [
    "##  Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f6291",
   "metadata": {},
   "source": [
    "\n",
    "```sh\n",
    "pip install git+https://github.com/nathanhubens/fasterai.git\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```sh\n",
    "pip install fasterai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94793f86",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58170c73",
   "metadata": {},
   "source": [
    "## Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95adea6",
   "metadata": {},
   "source": [
    "- [Get Started with FasterAI](https://nathanhubens.github.io/fasterai/tutorial.using_fasterai.html)\n",
    "- [Create your own pruning schedule](https://nathanhubens.github.io/fasterai/tutorial.schedules.html)\n",
    "- [Find winning tickets using the Lottery Ticket Hypothesis](https://nathanhubens.github.io/fasterai/tutorial.lottery_ticket.html)\n",
    "- [Use Knowledge Distillation to help a student model to reach higher performance](https://nathanhubens.github.io/fasterai/tutorial.knowledge_distillation.html)\n",
    "- [Sparsify Transformers](https://nathanhubens.github.io/fasterai/tutorial.transformers.html)\n",
    "- More to come..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c2350",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff49eae1",
   "metadata": {},
   "source": [
    "##  Citing\n",
    "```latex\n",
    "@software{Hubens,\n",
    "  author       = {Nathan Hubens},\n",
    "  title        = {fasterai},\n",
    "  year         = 2022,\n",
    "  publisher    = {Zenodo},\n",
    "  version      = {v0.1.6},\n",
    "  doi          = {10.5281/zenodo.6469868},\n",
    "  url          = {https://doi.org/10.5281/zenodo.6469868}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c18f446",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fbc5c2",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9498c",
   "metadata": {},
   "source": [
    "[Apache-2.0](https://www.apache.org/licenses/) License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4323f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "![](https://capsule-render.vercel.app/api?type=waving&color=008080&height=100&section=footer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f197eed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
