{
 "cells": [
  {
   "cell_type": "raw",
   "id": "91f08845",
   "metadata": {},
   "source": [
    "---\n",
    "description: Which parameter is important in a neural network ?\n",
    "output-file: criteria.html\n",
    "title: Criteria\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core.criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.basics import *\n",
    "from fastcore.imports import *\n",
    "from fasterai.core.granularity import *\n",
    "from typing import Callable, Optional, Union\n",
    "from enum import Enum, auto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-league",
   "metadata": {},
   "source": [
    "The criteria implemented come from [this paper](https://arxiv.org/pdf/1905.01067.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34145910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from fastai.vision.all import *\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(context='poster', style='white',\n",
    "        font='sans-serif', font_scale=1, color_codes=True, rc=None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "limit = np.linspace(-1, 1, 100)\n",
    "\n",
    "def demo_model(criteria, sparsity=50):\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    \n",
    "    #sp = Sparsifier(model, 'weight', 'local', criteria)\n",
    "    \n",
    "    pt = model.conv1.weight.clone().view(-1).detach().numpy()\n",
    "    model.conv1._init_weights =  model.conv1.weight.clone()\n",
    "    model.conv1.weight.data += 0.05*torch.randn(model.conv1.weight.shape)\n",
    "    ft = model.conv1.weight.clone().view(-1).detach().numpy()\n",
    "    \n",
    "    \n",
    "    pruned_weights = criteria(model.conv1, 'weight')\n",
    "    threshold = torch.quantile(pruned_weights.view(-1), sparsity/100)\n",
    "    mask = pruned_weights.ge(threshold).to(dtype=pruned_weights.dtype)\n",
    "    \n",
    "    \n",
    "    keep = np.where(mask.view(-1)==1)\n",
    "    pruned = np.where(mask.view(-1)==0)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4,4), dpi=100)\n",
    "    fig.patch.set_alpha(0.)\n",
    "    ax.patch.set_alpha(0.)\n",
    "    x1, x2, y1, y2 = -0.4, 0.4, -0.4, 0.4 # specify the limits\n",
    "    ax.set_xlim(x1, x2) # apply the x-limits\n",
    "    ax.set_ylim(y1, y2) # apply the x-limits\n",
    "    ax.scatter(pt[pruned], ft[pruned], s=5, c='lightgrey')\n",
    "    ax.scatter(pt[keep], ft[keep], s=5, c='#89d6c9')\n",
    "    ax.plot(limit, limit, c='black', linestyle=':', linewidth=3)\n",
    "    ax.set_xlabel(\"Pretrained Weights\", fontsize=15)\n",
    "    ax.set_ylabel(\"Fine-Tuned Weights\", fontsize=15)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    for axis in ['bottom','left']:\n",
    "        ax.spines[axis].set_linewidth(2)\n",
    "    plt.tick_params(axis='x', labelsize=15, width=2)\n",
    "    plt.tick_params(axis='y', labelsize=15, width=2)\n",
    "    ax.spines['bottom'].set_color('#808080')\n",
    "    ax.spines['top'].set_color('#808080') \n",
    "    ax.spines['right'].set_color('#808080')\n",
    "    ax.spines['left'].set_color('#808080')\n",
    "    ax.tick_params(axis='x', colors='#808080')\n",
    "    ax.tick_params(axis='y', colors='#808080')\n",
    "    ax.yaxis.label.set_color('#808080')\n",
    "    ax.xaxis.label.set_color('#808080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7739ca4c-6644-4f19-9c15-d1bb57c2cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "EPS = torch.finfo(torch.float32).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09b055-e69f-450a-b054-1b6305fe5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Reducer:\n",
    "    @staticmethod\n",
    "    def sum(scores, dim):\n",
    "        return scores[None].sum(dim=dim, keepdim=True).squeeze(0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean(scores, dim):\n",
    "        return scores[None].mean(dim=dim, keepdim=True).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fd75e-e0de-4e86-9522-f52e5a2c0c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Normalizer:\n",
    "    @staticmethod\n",
    "    def sum(scores):\n",
    "        return scores / scores.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def standardization(scores):\n",
    "        return (scores - scores.min()) / (scores.max() - scores.min() + EPS)\n",
    "    \n",
    "    @staticmethod\n",
    "    def mean(scores):\n",
    "        return scores / scores.mean()\n",
    "    \n",
    "    @staticmethod\n",
    "    def max(scores):\n",
    "        return scores / scores.max()\n",
    "    \n",
    "    @staticmethod\n",
    "    def gaussian(scores):\n",
    "        return (scores - scores.mean()) / (scores.std() + EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01499c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Criteria():\n",
    "    def __init__(self, \n",
    "                 f:Callable[[torch.Tensor], torch.Tensor],                                         # Function that transforms weights (e.g., torch.abs, torch.square)\n",
    "                 reducer: Callable = Reducer.mean,                                                 # Method to reduce dimensions ('mean' or 'sum')\n",
    "                 normalizer: Optional[Callable] = None,                                            # Method to normalize scores (None, 'sum', 'standardization', 'mean', 'max', 'gaussian')\n",
    "                 needs_init:bool=False,                                                            # Whether this criteria needs the initial weights\n",
    "                 needs_update:bool=False,                                                          # Whether this criteria needs to track weight updates between iterations\n",
    "                 output_fn:Optional[Callable[[torch.Tensor, torch.Tensor], torch.Tensor]] = None,  # Function to combine current and reference weights\n",
    "                 return_init=False,                                                                # Whether to return the transformed initial weights instead of final output\n",
    "    ):\n",
    "        \"Evaluates neural network parameters based on various criteria for pruning\"\n",
    "        store_attr()\n",
    "        assert (needs_init and needs_update)==False, \"The init values will be overwritten by the updating ones.\"\n",
    "   \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, \n",
    "                 m: nn.Module,  # The module to compute scores for\n",
    "                 g: str,        # Granularity specification\n",
    "                 squeeze=False  # Whether to squeeze singleton dimensions\n",
    "    ) -> torch.Tensor:\n",
    "        \"Compute criteria scores for module weights\"\n",
    "        try:\n",
    "            dim = listify(Granularities.get_dim(m, g))\n",
    "        except KeyError:\n",
    "            raise ValueError(f'Invalid granularity \"{g}\" for module type {type(m).__name__}')\n",
    "            \n",
    "        if self.needs_update and not hasattr(m, '_old_weights'):\n",
    "            m.register_buffer(\"_old_weights\", m._init_weights.clone()) # If the previous value of weights is not known, take the initial value\n",
    "            \n",
    "        wf = self.f(m.weight)\n",
    "        \n",
    "        if self.needs_init: wi = self.f(m._init_weights)\n",
    "        if self.needs_update: wi = self.f(m._old_weights)\n",
    "        \n",
    "        if self.output_fn: scores = self.output_fn(wf, wi)\n",
    "        elif self.return_init: scores = wi\n",
    "        else: scores = wf\n",
    "            \n",
    "        scores = self._rescale(scores)\n",
    "        if hasattr(m, '_mask'): scores.mul_(m._mask)\n",
    "        scores = self._reduce(scores, dim)\n",
    "        scores = self._normalize(scores)\n",
    "        if squeeze: scores = scores[None].squeeze((0,*dim))\n",
    "        return scores\n",
    "    \n",
    "    def _reduce(self, \n",
    "                scores: torch.Tensor,  # Input scores\n",
    "                dim: Union[int, list[int]]      # Dimensions to reduce\n",
    "    ) -> torch.Tensor:\n",
    "        \"Reduce scores along specified dimensions\"\n",
    "        return self.reducer(scores, dim)\n",
    "            \n",
    "    def _normalize(self, \n",
    "                   scores: torch.Tensor # Input scores to normalize\n",
    "    ) -> torch.Tensor:\n",
    "        \"Normalize scores using the specified method\"\n",
    "        if self.normalizer is None: return scores\n",
    "        return self.normalizer(scores)\n",
    "\n",
    "    def _rescale(self, \n",
    "                 scores: torch.Tensor # Input scores to rescale\n",
    "    ) -> torch.Tensor:\n",
    "        \"Ensure all scores are positive to maintain pruning behavior\"\n",
    "        min_val = scores.min()\n",
    "        if min_val < 0:\n",
    "            scores.add_(-min_val)\n",
    "        scores.add_(EPS)\n",
    "        return scores\n",
    "\n",
    "    def update_weights(self, \n",
    "                       m: nn.Module   # Module whose weights should be updated\n",
    "    ) -> None:\n",
    "        \"Update the reference weights for criteria that track changes\"\n",
    "        if self.needs_update: \n",
    "            m._old_weights = m.weight.data.clone() # The current value becomes the old one for the next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-cause",
   "metadata": {},
   "source": [
    "## Magnitude Based Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb02c7-d6b7-4666-aff4-449745f06ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def magnitude_criteria(transform_fn, **kwargs):\n",
    "     \"Create a criteria based on weight magnitude transformation.\"\n",
    "     return Criteria(transform_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-offset",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "random = magnitude_criteria(torch.randn_like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-cosmetic",
   "metadata": {},
   "source": [
    "### Large Final Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "large_final = magnitude_criteria(torch.abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(large_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6601ed8",
   "metadata": {},
   "source": [
    "### Squared Final Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "squared_final = magnitude_criteria(torch.square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88713867",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(squared_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-zealand",
   "metadata": {},
   "source": [
    "### Small Final Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "small_final = magnitude_criteria(compose(torch.abs, torch.neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(small_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa86b4-c5d5-41b0-9c8f-5131c5437158",
   "metadata": {},
   "source": [
    "## Init based criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2e298-cfd1-4c92-bf40-344a3ed7b1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_based_criteria(transform_fn, output_fn=None, return_init=False, **kwargs):\n",
    "     \"Create a criteria that compares current weights to initial weights.\"\n",
    "     return Criteria(transform_fn, needs_init=True, output_fn=output_fn, return_init=return_init, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-choir",
   "metadata": {},
   "source": [
    "### Large Init Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "large_init = init_based_criteria(torch.abs, return_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(large_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-billion",
   "metadata": {},
   "source": [
    "### Small Init Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "small_init = init_based_criteria(compose(torch.abs, torch.neg), return_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(small_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-behalf",
   "metadata": {},
   "source": [
    "### Large Init Large Final Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "large_init_large_final = init_based_criteria(torch.abs, output_fn=torch.min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(large_init_large_final, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-paper",
   "metadata": {},
   "source": [
    "### Small Init Small Final Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "small_init_small_final = init_based_criteria(torch.abs, output_fn=lambda x,y: torch.neg(torch.max(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(small_init_small_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-strap",
   "metadata": {},
   "source": [
    "### Increasing Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "magnitude_increase = init_based_criteria(torch.abs, output_fn= torch.sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(magnitude_increase, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-ratio",
   "metadata": {},
   "source": [
    "### Movement Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "movement = init_based_criteria(noop, output_fn= lambda x,y: torch.abs(torch.sub(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583e171-eed5-496f-8ae0-c310fe43a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "movmag = init_based_criteria(noop, output_fn=lambda x,y: torch.abs(torch.mul(x, torch.sub(x,y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59e0b5-5880-4ef0-9d00-85bd59c524a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(movmag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-expert",
   "metadata": {},
   "source": [
    "## Update based criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b7160-f05e-4fa8-ba48-3953bd15751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def update_based_criteria(transform_fn, output_fn=None, **kwargs):\n",
    "     \"Create a criteria that compares current weights to previous iteration weights.\"\n",
    "     return Criteria(transform_fn, needs_update=True, output_fn=output_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-landing",
   "metadata": {},
   "source": [
    "The following criteria use an updating value of the weights, i.e. the value from the previous iteration of training, instead of the initialization value to better capture the training dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-monthly",
   "metadata": {},
   "source": [
    "### Updating Magnitude Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "updating_magnitude_increase = update_based_criteria(torch.abs, output_fn= lambda x,y: torch.sub(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(updating_magnitude_increase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-poster",
   "metadata": {},
   "source": [
    "### Updating Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "updating_movement = update_based_criteria(noop, output_fn= lambda x,y: torch.abs(torch.sub(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-explorer",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(updating_movement, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9b827",
   "metadata": {},
   "source": [
    "### Updating mov-magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c1d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "updating_movmag = update_based_criteria(noop, output_fn=lambda x,y: torch.abs(torch.mul(x, torch.sub(x,y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_model(updating_movmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "criterias = (\n",
    "    'random',              # Random scores\n",
    "    'large_final',         # Large absolute weight values\n",
    "    'small_final',         # Small absolute weight values\n",
    "    'squared_final',       # Squared weight values\n",
    "    'large_init',          # Large initial weight values\n",
    "    'small_init',          # Small initial weight values\n",
    "    'large_init_large_final',  # Minimum of initial and final magnitude\n",
    "    'small_init_small_final',  # Maximum of initial and final magnitude (negated)\n",
    "    'magnitude_increase',      # Increase in magnitude from init\n",
    "    'movement',                # Absolute change from init\n",
    "    'updating_magnitude_increase',  # Increase in magnitude from previous step\n",
    "    'updating_movement',           # Absolute change from previous step\n",
    "    'movmag',                      # Movement * magnitude from init\n",
    "    'updating_movmag'              # Movement * magnitude from previous step\n",
    " )\n",
    "\n",
    "def available_criterias():\n",
    "    \"Return the list of available criteria names\"\n",
    "    return criterias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71214133",
   "metadata": {},
   "source": [
    "# New Ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e948e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_magnitude_increase = Criteria(torch.abs, needs_update=True, output_fn= lambda x,y: torch.abs(torch.sub(x,y)))\n",
    "\n",
    "demo_model(updating_magnitude_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b99556",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_magnitude_increase = Criteria(torch.abs, needs_update=True, output_fn= lambda x,y: torch.sub(x,y))\n",
    "\n",
    "demo_model(updating_magnitude_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b08fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_magnitude_increase = Criteria(torch.square, needs_update=True, output_fn= lambda x,y: torch.abs(torch.sub(x,y)))\n",
    "\n",
    "demo_model(updating_magnitude_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movmag = Criteria(noop, needs_update=True, output_fn=lambda x,y: torch.abs(torch.mul(x, torch.sub(x,y))))\n",
    "demo_model(updating_movmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movmag = Criteria(noop, needs_update=True, output_fn=lambda x,y: torch.abs(torch.mul(torch.square(x), torch.sub(x,y))))\n",
    "demo_model(updating_movmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b7ef51",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movmag = Criteria(torch.square, needs_update=True, output_fn=lambda x,y: torch.abs(torch.mul(x, torch.sub(x,y))))\n",
    "#updating_movmag = Criteria(noop, needs_update=True, output_fn=lambda x,y: torch.mul(x, torch.sub(x,y)))\n",
    "demo_model(updating_movmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a8ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movmag = Criteria(torch.abs, needs_update=True, output_fn=lambda x,y: torch.abs(torch.mul(x, torch.sub(x,y))))\n",
    "#updating_movmag = Criteria(noop, needs_update=True, output_fn=lambda x,y: torch.mul(x, torch.sub(x,y)))\n",
    "demo_model(updating_movmag, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155c971",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movmag = Criteria(torch.abs, needs_update=True, output_fn=lambda x,y: torch.mul(x, torch.sub(x,y)))\n",
    "\n",
    "demo_model(updating_movmag, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb533b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movmag = Criteria(torch.square, needs_update=True, output_fn=lambda x,y: torch.mul(x, torch.sub(x,y)))\n",
    "\n",
    "demo_model(updating_movmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e354ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movmag = Criteria(noop, needs_update=True, output_fn=lambda x,y: torch.mul(x, torch.sub(x,y)))\n",
    "\n",
    "demo_model(updating_movmag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movement = Criteria(noop, needs_update=True, output_fn= lambda x,y: torch.abs(torch.sub(-x,y)))\n",
    "demo_model(updating_movement, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a7897",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movement = Criteria(torch.abs, needs_update=True, output_fn= lambda x,y: torch.abs(torch.sub(-x,y)))\n",
    "demo_model(updating_movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87942af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movement = Criteria(torch.abs, needs_update=True, output_fn= lambda x,y: torch.abs(torch.cosh(torch.sub(x,y))))\n",
    "demo_model(updating_movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82977616",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movement = Criteria(torch.square, needs_update=True, output_fn= lambda x,y: torch.abs(torch.sub(x,y)))\n",
    "demo_model(updating_movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4bd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "updating_movement = Criteria(noop, needs_update=True, output_fn= lambda x,y: torch.sub(x,y))\n",
    "demo_model(updating_movement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d336a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = partial(torch.pow, exponent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee1deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_final = Criteria(torch.frac)\n",
    "demo_model(large_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-deputy",
   "metadata": {},
   "source": [
    "### First order Taylor expansion on the weight (as per [Nvidia Taylor Pruning](https://github.com/NVlabs/Taylor_pruning/blob/master/pruning_engine.py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def grad_crit(\n",
    "    m: nn.Module,  # module to compute gradient-based importance for\n",
    "    g: str,        # granularity specification\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"First order Taylor expansion criterion for weight importance (Nvidia Taylor Pruning).\"\"\"\n",
    "    try:\n",
    "        dim = listify(Granularities.get_dim(m, g))\n",
    "    except KeyError:\n",
    "        raise ValueError(f'Invalid granularity \"{g}\" for module type {type(m).__name__}')\n",
    "    \n",
    "    if m.weight.grad is not None:\n",
    "        return (m.weight * m.weight.grad)[None].pow(2).mean(dim=dim, keepdim=True).squeeze(0)\n",
    "    else:\n",
    "        return m.weight[None].pow(2).mean(dim=dim, keepdim=True).squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7gx55qqfam4",
   "metadata": {},
   "source": "---\n\n## See Also\n\n- [Sparsifier](../sparse/sparsifier.html) - Apply sparsification using these criteria\n- [Pruner](../prune/pruner.html) - Structured pruning with importance scoring\n- [Granularity](granularity.html) - Control what gets pruned (weights, filters, etc.)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
