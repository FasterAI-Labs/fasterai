{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9ffb4353",
   "metadata": {},
   "source": [
    "---\n",
    "description: What block of parameter to remove in a neural network ?\n",
    "output-file: granularity.html\n",
    "title: Granularity\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core.granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastcore.basics import *\n",
    "from fastcore.imports import *\n",
    "from typing import Union, Type, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbfc982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(context='poster', style='white',\n",
    "        font='sans-serif', font_scale=1, color_codes=True, rc=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a78289",
   "metadata": {},
   "source": [
    "## Conv2d Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9602698b-b5e6-4087-83ee-370cb62616e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Granularities:\n",
    "    _granularities_Conv2d = {'weight':0, 'shared_weight':1, 'channel':2, 'column':3, 'row':4, 'kernel':(3,4), 'filter':(2,3,4), 'shared_channel':(1,2), 'shared_column': (1,3), 'shared_row': (1,4), 'vertical_slice': (2,3), 'horizontal_slice': (2,4), 'shared_vertical_slice': (1,2,3), 'shared_horizontal_slice': (1,2,4), 'shared_kernel': (1,3,4), 'layer':(1,2,3,4)}\n",
    "    _granularities_ConvT2d = {'weight':0, 'shared_weight':2, 'channel':1, 'column':3, 'row':4, 'kernel':(3,4), 'filter':(1,3,4), 'shared_channel':(1,2), 'shared_column': (2,3), 'shared_row': (2,4), 'vertical_slice': (1,3), 'horizontal_slice': (1,4), 'shared_vertical_slice': (1,2,3), 'shared_horizontal_slice': (1,2,4), 'shared_kernel': (2,3,4), 'layer':(1,2,3,4)}\n",
    "    _granularities_Linear = {'weight':0, 'column':1, 'row':2, 'layer':(1,2)}\n",
    "    _granularities: dict[Type[nn.Module], dict[str, Union[int, tuple]]] = {\n",
    "        torch.nn.Conv2d: _granularities_Conv2d,\n",
    "        torch.nn.ConvTranspose2d: _granularities_ConvT2d,\n",
    "        torch.nn.Conv1d: _granularities_Linear,\n",
    "        torch.nn.Linear: _granularities_Linear\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def get_dim(cls, \n",
    "        m: nn.Module, # The module to get dimensions for\n",
    "        g: str        # The name of the granularity\n",
    "    ) -> Union[int, list[int]]:\n",
    "        \"Get the dimensions associated with a granularity for a module\"\n",
    "        for k in cls._granularities:\n",
    "            if isinstance(m, k):\n",
    "                return listify(cls._granularities[k][g])\n",
    "        raise ValueError(f\"Unsupported module type: {type(m).__name__}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def add_granularity(cls, \n",
    "                        m_type: Type[nn.Module],    # The module type to add granularities for\n",
    "                        g: str                      # Mapping from granularity names to dimensions\n",
    "    ) -> None:\n",
    "        \"Add granularity specifications for a new module type\"\n",
    "        cls._granularities[m_type] = g\n",
    "        \n",
    "    @classmethod\n",
    "    def allowed_granularities(cls, \n",
    "                              m: nn.Module # The module to get granularities for\n",
    "    ) -> dict[str, Union[int, tuple]]:\n",
    "        \"Get all allowed granularities for a module\"\n",
    "        for module_type, granularities in cls._granularities.items():\n",
    "            if isinstance(m, module_type):\n",
    "                return granularities\n",
    "        supported_types = [t.__name__ for t in cls._granularities.keys()]\n",
    "        raise ValueError(f\"Unsupported module type: {type(m).__name__}. \"\n",
    "                        f\"Supported types: {supported_types}\")\n",
    "    \n",
    "    @classmethod\n",
    "    def available_granularities(cls) -> list[Type[nn.Module]]:\n",
    "        \"Get all module types that have defined granularities\"\n",
    "        return list(cls._granularities.keys())\n",
    "\n",
    "    @classmethod\n",
    "    def available_modules(cls) -> tuple[Type[nn.Module], ...]:\n",
    "        \"Get all module types that support compression (for isinstance checks)\"\n",
    "        return tuple(cls._granularities.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11280819",
   "metadata": {},
   "source": [
    "A `Conv2d` layer possess a 4d-tensor as weights. This means that there exist many ways of removing blocks from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94820c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "def get_pruned_conv(granularity):\n",
    "    conv = nn.Conv2d(3, 16, 7, 1)\n",
    "    dim = Granularities.get_dim(conv, granularity)\n",
    "    \n",
    "    pruned_weights = conv.weight[None].mean(dim=dim, keepdim=True).squeeze(0)\n",
    "    threshold = torch.quantile(pruned_weights.view(-1), 0.8)\n",
    "    mask = pruned_weights.ge(threshold).to(dtype=pruned_weights.dtype)\n",
    "    plot_kernels(conv.weight.data.mul_(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c184b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "def plot_kernels(weights, save=None):\n",
    "    kernels = abs(weights)\n",
    "    kernels = kernels - kernels.min()\n",
    "    kernels = kernels/kernels.max()\n",
    "    \n",
    "    fig = plt.figure(figsize=(17,4), dpi=100)\n",
    "    for i in range(1, len(kernels)+1):\n",
    "        plt.subplot(2,8, i)\n",
    "        plt.xticks([])        \n",
    "        plt.yticks([])              \n",
    "        plt.imshow(kernels[i-1].detach().permute(1,2,0).cpu())\n",
    "        plt.axis('off')\n",
    "    \n",
    "    fig.patch.set_alpha(0.)\n",
    "    if save: plt.savefig(f'{save}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db76dc",
   "metadata": {},
   "source": [
    "### 0-D Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e202c38",
   "metadata": {},
   "source": [
    "In the case of convolution filters, removing 0-D elements is equivalent to removing individual weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f78964",
   "metadata": {},
   "source": [
    "* `weight` granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eba524",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254de366",
   "metadata": {},
   "source": [
    "### 1-D Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06acce",
   "metadata": {},
   "source": [
    "1-D blocks of elements is equivalent to removing vectors from the convolution filters. There are several ways to chose the vectors, that will be represented below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc9105",
   "metadata": {},
   "source": [
    "* `shared_weight`: this granularity is very particular as it removes individual weights from a filter, but with a pattern that is shared across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec006156",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('shared_weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b66c4a3",
   "metadata": {},
   "source": [
    "* `channel`: remove vector of weights along the channel axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1da982",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35168ce3",
   "metadata": {},
   "source": [
    "* `column`: remove vector of weights along the height axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636af5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d056f067",
   "metadata": {},
   "source": [
    "* `row`: remove vector of weights along the width axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e352f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('row')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c48a0e9",
   "metadata": {},
   "source": [
    "### 2-D Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22a0577",
   "metadata": {},
   "source": [
    "* `shared_channel`: remove vector of weight along the channel axis, but with a pattern that is shared across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7834a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('shared_channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0596a",
   "metadata": {},
   "source": [
    "* `shared_column`: remove vector of weight along the height axis, but with a pattern that is shared across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae8190",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('shared_column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd37ed",
   "metadata": {},
   "source": [
    "* `shared_row`: remove vector of weight along the width axis, but with a pattern that is shared across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('shared_row')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65b4c5",
   "metadata": {},
   "source": [
    "* `vertical_slice`: remove vertical slices of weight along the height axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('vertical_slice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49d214",
   "metadata": {},
   "source": [
    "* `horizontal_slice`: remove vertical slices of weight along the width axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e7b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('horizontal_slice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fe09a8",
   "metadata": {},
   "source": [
    "* `kernel`: remove kernels of from the convolution filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c22998",
   "metadata": {},
   "source": [
    "### 3-D Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64db966",
   "metadata": {},
   "source": [
    "* `shared_vertical_slice`: remove vertical slices of weight along the height axis, with a pattern that is shared across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('shared_vertical_slice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def5128",
   "metadata": {},
   "source": [
    "* `shared_horizontal_slice`: remove horizontal slices of weight along the width axis, with a pattern that is shared across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('shared_horizontal_slice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a1f487",
   "metadata": {},
   "source": [
    "* `shared_kernel`: remove kernels of weight from the convolution filters, with a pattern that is shared across all filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57399da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('shared_kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846baf87",
   "metadata": {},
   "source": [
    "* `filter`: remove entire filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_conv('filter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab446229",
   "metadata": {},
   "source": [
    "## Linear Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceba56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "def get_pruned_linear(granularity):\n",
    "    lin = nn.Linear(32,16)\n",
    "    dim = Granularities.get_dim(lin, granularity)\n",
    "    \n",
    "    pruned_weights = lin.weight[None].mean(dim=dim, keepdim=True).squeeze(0)\n",
    "    threshold = torch.quantile(pruned_weights.view(-1), 0.8)\n",
    "    mask = pruned_weights.ge(threshold).to(dtype=pruned_weights.dtype)\n",
    "    plot_matrix(lin.weight.data.mul_(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4907e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "def plot_matrix(weights, save=None):\n",
    "    kernels = abs(weights)\n",
    "    kernels = kernels - kernels.min()\n",
    "    kernels = kernels/kernels.max()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6,6), dpi=100)\n",
    "    fig.patch.set_alpha(0.)\n",
    "    ax.patch.set_alpha(0.)\n",
    "    img = make_grid(kernels, nrow=8, padding=1, pad_value=1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.detach().permute(1,2,0).cpu())\n",
    "    if save: plt.savefig(f'{save}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33dd697",
   "metadata": {},
   "source": [
    "### 0-D Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f957d6",
   "metadata": {},
   "source": [
    "As for the convolution filters, weights from a Linear layer can be removed independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae315aa",
   "metadata": {},
   "source": [
    "* `weight`: remove individual weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_linear('weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6674de38",
   "metadata": {},
   "source": [
    "### 1-D Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804a4bd",
   "metadata": {},
   "source": [
    "* `column`: remove column of weight, which corresponds to removing input neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_linear('column')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6547df",
   "metadata": {},
   "source": [
    "* `row`: remove rows of weight, which corresponds to removing output neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pruned_linear('row')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70767b4f",
   "metadata": {},
   "source": [
    "## Transformer Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a1bbf",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "This is an experimental part of the library\n",
    "\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
