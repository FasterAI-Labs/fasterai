{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3fef4a5c",
   "metadata": {},
   "source": [
    "---\n",
    "description: Perform Group Regularization in fastai Callback system\n",
    "output-file: regularizer.html\n",
    "title: Regularize Callback\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp regularize.regularize_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9314896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d82f5",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nfrom __future__ import annotations\nfrom fastai.callback.all import *\nfrom fastcore.basics import store_attr, listify\nfrom fasterai.core.criteria import *\nfrom fasterai.core.granularity import *\nfrom fasterai.core.schedule import *\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom typing import Union, Optional, Type"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6973d",
   "metadata": {},
   "outputs": [],
   "source": "#| export\nclass RegularizeCallback(Callback):\n    def __init__(self, \n                 criteria: Union[Criteria, list[Criteria]],            # Criteria(s) to use for regularization\n                 granularity: Union[str, list[str]],                   # Granularity level(s) for grouping\n                 weight: float = 0.01,                                 # Regularization weight\n                 layer_types: Union[Type, list[Type]] = nn.Conv2d,     # Layer types to apply regularization to\n                 schedule: Optional[Schedule] = None,                  # Optional schedule for regularization weight\n                 per_layer_weights: Optional[dict[str, float]] = None, # Optional per-layer weights\n                 verbose: bool = False                                 # Whether to report regularization weight\n    ):\n        \"Callback to apply regularization using criteria during training\"\n        store_attr()\n        self.criteria = listify(criteria)\n        self.granularity = listify(granularity)\n        self.layer_types = listify(layer_types)\n        self.per_layer_weights = per_layer_weights or {}\n        self.current_weight = weight\n        \n    def before_batch(self) -> None:\n        \"Update regularization weight if scheduled\"\n        if self.schedule is not None:\n            self.current_weight = self.schedule([self.weight], self.pct_train)[0]\n        \n    def after_loss(self) -> None:\n        \"Apply regularization after computing the main loss\"\n        reg = self.get_norm()\n        self.learn.loss_grad += reg\n        self.learn.loss = self.learn.loss_grad.clone()\n            \n    def get_norm(self) -> torch.Tensor:\n        \"Compute regularization using the specified criteria and granularities\"\n        total_reg = 0.0\n        \n        for crit in self.criteria:\n            for g in self.granularity:\n                layer_regs = []\n                \n                for m in self.learn.model.modules():\n                    if any(isinstance(m, lt) for lt in self.layer_types) and hasattr(m, 'weight'):\n                        try:\n                            scores = crit.f(m.weight)[None].abs().sum(Granularities.get_dim(m, g))\n                            layer_reg = self.current_weight * scores.sum()\n                            layer_regs.append(layer_reg)\n                            \n                        except (KeyError, ValueError) as e:\n                            # Skip unsupported granularities for this module type\n                            import warnings\n                            warnings.warn(f\"Skipping regularization for {type(m).__name__}: {e}\")\n                            continue\n                        except RuntimeError as e:\n                            # Handle tensor operation errors\n                            import warnings\n                            warnings.warn(f\"Runtime error in regularization for {type(m).__name__}: {e}\")\n                            continue\n                \n                if layer_regs:\n                    total_reg += torch.stack(layer_regs).sum()\n        \n        return total_reg\n    \n    def after_epoch(self) -> None:\n        \"Report current regularization weight if verbose\"\n        if self.verbose:\n            print(f\"Current regularization weight: {self.current_weight:.6f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd300f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(RegularizeCallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd44a5fa",
   "metadata": {},
   "source": [
    "The `RegularizeCallback`can be used to perform $l_1$ regularization on any granularity available in the `criteria` class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
