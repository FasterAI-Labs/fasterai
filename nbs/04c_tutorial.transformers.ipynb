{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mounted-racing",
   "metadata": {},
   "source": [
    "# Prune Transformers\n",
    "\n",
    "> How to prune a transformer with fasterai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-naples",
   "metadata": {},
   "source": [
    "> Note: This example code is taken from the fastai [docs](https://docs.fast.ai/tutorial.transformers.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = 'gpt2'\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-auction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/HubensN/.fastai/data/wikitext-2/train.csv'),Path('/home/HubensN/.fastai/data/wikitext-2/test.csv')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.WIKITEXT_TINY)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the &lt;unk&gt; season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n = Big Boy ( song ) = \\n \\n \" Big Boy \" &lt;unk&gt; \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and &lt;unk&gt; composit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica &lt;unk&gt; and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will &lt;unk&gt; ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family &lt;unk&gt; . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf &lt;unk&gt; cup , &lt;unk&gt; &lt;unk&gt; cup , or pixie cup . The small , &lt;unk&gt; @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         0\n",
       "0   \\n = 2013 – 14 York City F.C. season = \\n \\n The 2013 – 14 season was the <unk> season of competitive association football and 77th season in the Football League played by York City Football Club , a professional football club based in York , North Yorkshire , England . Their 17th @-@ place finish in 2012 – 13 meant it was their second consecutive season in League Two . The season ran from 1 July 2013 to 30 June 2014 . \\n Nigel Worthington , starting his first full season as York manager , made eight permanent summer signings . By the turn of the year York were only above the relegation z...\n",
       "1   \\n = Big Boy ( song ) = \\n \\n \" Big Boy \" <unk> \" I 'm A Big Boy Now \" was the first single ever recorded by the Jackson 5 , which was released by Steeltown Records in January 1968 . The group played instruments on many of their Steeltown compositions , including \" Big Boy \" . The song was neither a critical nor commercial success , but the Jackson family were delighted with the outcome nonetheless . \\n The Jackson 5 would release a second single with Steeltown Records before moving to Motown Records . The group 's recordings at Steeltown Records were thought to be lost , but they were re...\n",
       "2   \\n = The Remix ( Lady Gaga album ) = \\n \\n The Remix is a remix album by American recording artist Lady Gaga . Released in Japan on March 3 , 2010 , it contains remixes of the songs from her first studio album , The Fame ( 2008 ) , and her third extended play , The Fame Monster ( 2009 ) . A revised version of the track list was prepared for release in additional markets , beginning with Mexico on May 3 , 2010 . A number of recording artists have produced the songs , including Pet Shop Boys , Passion Pit and The Sound of Arrows . The remixed versions feature both uptempo and <unk> composit...\n",
       "3   \\n = New Year 's Eve ( Up All Night ) = \\n \\n \" New Year 's Eve \" is the twelfth episode of the first season of the American comedy television series Up All Night . The episode originally aired on NBC in the United States on January 12 , 2012 . It was written by Erica <unk> and was directed by Beth McCarthy @-@ Miller . The episode also featured a guest appearance from Jason Lee as Chris and Reagan 's neighbor and Ava 's boyfriend , Kevin . \\n During Reagan ( Christina Applegate ) and Chris 's ( Will <unk> ) first New Year 's Eve game night , Reagan 's competitiveness comes out causing Ch...\n",
       "4   \\n = Geopyxis carbonaria = \\n \\n Geopyxis carbonaria is a species of fungus in the genus Geopyxis , family <unk> . First described to science in 1805 , and given its current name in 1889 , the species is commonly known as the charcoal loving elf @-@ cup , dwarf <unk> cup , <unk> <unk> cup , or pixie cup . The small , <unk> @-@ shaped fruitbodies of the fungus are reddish @-@ brown with a whitish fringe and measure up to 2 cm ( 0 @.@ 8 in ) across . They have a short , tapered stalk . Fruitbodies are commonly found on soil where brush has recently been burned , sometimes in great numbers ...."
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(path/'train.csv', header=None)\n",
    "df_valid = pd.read_csv(path/'test.csv', header=None)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = np.concatenate([df_train[0].values, df_valid[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-phrase",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4576 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "splits = [range_of(df_train), list(range(len(df_train), len(all_texts)))]\n",
    "tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 4,256\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-lawsuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='662' class='' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [662/662 00:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-graph",
   "metadata": {},
   "source": [
    "Let's create our fastai `Learner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-tuner",
   "metadata": {},
   "source": [
    "And let's try to extend a given prompt with the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "preds = learn.model.generate(inp, max_length=40, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-grill",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn on its head.\\n\\nA unicorn is a magical creature with a rainbow tail and a horn'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasterai.sparse.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-mounting",
   "metadata": {},
   "source": [
    "As we only want to prune the Conv1d layers in the model, we need to change the `prune` and `mask_grad` methods of the `Sparsifier` class accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(Sparsifier)\n",
    "def prune(self, sparsity):\n",
    "    for k, m in enumerate(self.model.modules()):\n",
    "        if m.__class__.__name__ == 'Conv1D':\n",
    "            weight = self.criteria(m, self.granularity)\n",
    "            mask = self._compute_mask(self.model, weight, sparsity)\n",
    "            m.register_buffer(\"_mask\", mask) # Put the mask into a buffer\n",
    "            self._apply(m)\n",
    "            \n",
    "@patch_to(Sparsifier)\n",
    "def mask_grad(self):\n",
    "    for k, m in enumerate(self.model.modules()):\n",
    "        if m.__class__.__name__ == 'Conv1D':\n",
    "            mask = getattr(m, \"_mask\")\n",
    "            if m.weight.grad is not None: # In case some layers are freezed\n",
    "                m.weight.grad.mul_(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-marsh",
   "metadata": {},
   "source": [
    "Also, when working with text, fastai defines the number of processed batches differently, so we have to adjust our `SparsifyCallback` accordingly (luckily, fastai makes it available as the `n_batches` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch_to(SparsifyCallback)\n",
    "def before_fit(self):\n",
    "    print(f'Pruning of {self.granularity} until a sparsity of {self.end_sparsity}%')\n",
    "    self.sparsifier = Sparsifier(self.learn.model, self.granularity, self.method, self.criteria)\n",
    "\n",
    "    self.total_iters = self.n_epoch * self.dls.n_batches\n",
    "    self.start_iter = self.start_epoch * self.dls.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [3.695716381072998,40.2744140625]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-lithuania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.105212</td>\n",
       "      <td>2.847042</td>\n",
       "      <td>17.236725</td>\n",
       "      <td>07:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn @-@ shaped head. It is the most common type of unicorn in the United States.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]\n",
    "\n",
    "preds = learn.model.generate(inp.cuda(), max_length=40, num_beams=5, temperature=1.5)\n",
    "\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-breach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of 30%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.276928</td>\n",
       "      <td>2.875845</td>\n",
       "      <td>17.740412</td>\n",
       "      <td>17:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Weights at epoch 0\n",
      "Sparsity at the end of epoch 0: 30.00%\n",
      "Final Sparsity: 30.00\n"
     ]
    }
   ],
   "source": [
    "sp_cb = SparsifyCallback(end_sparsity=30, granularity='weight', method='local', criteria=large_final, sched_func=sched_agp)\n",
    "\n",
    "learn.fit_one_cycle(1, 1e-4, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn on its head. The unicorn is a member of the <unk> <unk> family,'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]\n",
    "\n",
    "preds = learn.model.generate(inp.cuda(), max_length=40, num_beams=5, temperature=1.5)\n",
    "\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in Conv1D 9: 30.00%\n",
      "Sparsity in Conv1D 10: 30.00%\n",
      "Sparsity in Conv1D 15: 30.00%\n",
      "Sparsity in Conv1D 16: 30.00%\n",
      "Sparsity in Conv1D 21: 30.00%\n",
      "Sparsity in Conv1D 22: 30.00%\n",
      "Sparsity in Conv1D 27: 30.00%\n",
      "Sparsity in Conv1D 28: 30.00%\n",
      "Sparsity in Conv1D 33: 30.00%\n",
      "Sparsity in Conv1D 34: 30.00%\n",
      "Sparsity in Conv1D 39: 30.00%\n",
      "Sparsity in Conv1D 40: 30.00%\n",
      "Sparsity in Conv1D 45: 30.00%\n",
      "Sparsity in Conv1D 46: 30.00%\n",
      "Sparsity in Conv1D 51: 30.00%\n",
      "Sparsity in Conv1D 52: 30.00%\n",
      "Sparsity in Conv1D 57: 30.00%\n",
      "Sparsity in Conv1D 58: 30.00%\n",
      "Sparsity in Conv1D 63: 30.00%\n",
      "Sparsity in Conv1D 64: 30.00%\n",
      "Sparsity in Conv1D 69: 30.00%\n",
      "Sparsity in Conv1D 70: 30.00%\n",
      "Sparsity in Conv1D 75: 30.00%\n",
      "Sparsity in Conv1D 76: 30.00%\n",
      "Sparsity in Conv1D 81: 30.00%\n",
      "Sparsity in Conv1D 82: 30.00%\n",
      "Sparsity in Conv1D 87: 30.00%\n",
      "Sparsity in Conv1D 88: 30.00%\n",
      "Sparsity in Conv1D 93: 30.00%\n",
      "Sparsity in Conv1D 94: 30.00%\n",
      "Sparsity in Conv1D 99: 30.00%\n",
      "Sparsity in Conv1D 100: 30.00%\n",
      "Sparsity in Conv1D 105: 30.00%\n",
      "Sparsity in Conv1D 106: 30.00%\n",
      "Sparsity in Conv1D 111: 30.00%\n",
      "Sparsity in Conv1D 112: 30.00%\n",
      "Sparsity in Conv1D 117: 30.00%\n",
      "Sparsity in Conv1D 118: 30.00%\n",
      "Sparsity in Conv1D 123: 30.00%\n",
      "Sparsity in Conv1D 124: 30.00%\n",
      "Sparsity in Conv1D 129: 30.00%\n",
      "Sparsity in Conv1D 130: 30.00%\n",
      "Sparsity in Conv1D 135: 30.00%\n",
      "Sparsity in Conv1D 136: 30.00%\n",
      "Sparsity in Conv1D 141: 30.00%\n",
      "Sparsity in Conv1D 142: 30.00%\n",
      "Sparsity in Conv1D 147: 30.00%\n",
      "Sparsity in Conv1D 148: 30.00%\n"
     ]
    }
   ],
   "source": [
    "for k,m in enumerate(learn.model.modules()):\n",
    "    if m.__class__.__name__ == 'Conv1D':\n",
    "        print(f\"Sparsity in {m.__class__.__name__} {k}: {100. * float(torch.sum(m.weight == 0))/ float(m.weight.nelement()):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
