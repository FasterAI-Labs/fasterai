package:
  name: fasterai
  version: 0.1.13
source:
  sha256: 61fd53a32080b08543a91cfceaaf28423a5bdf48bfd047bc95704c5fdc10b555
  url: https://files.pythonhosted.org/packages/59/17/5ace7091abdcf7f8c5e53a84c87d099a77ae6a22eb252c51ce0a28aaae76/fasterai-0.1.13.tar.gz
about:
  description: "# Fasterai\n\n\n\n![header](https://capsule-render.vercel.app/api?type=waving&color=008080&height=300&section=header&text=fasterai%20&fontSize=90&animation=fadeIn&fontAlignY=38&desc=A%20Library%20to%20make%20smaller%20and%20faster%20neural%20networks&descAlignY=51&descAlign=62)\n\
    \n<p align=\"center\">\n    <a href=\"https://pypi.org/project/fasterai/\"><img\
    \ src=\"https://img.shields.io/pypi/v/fasterai?color=%235BAFAF\"></a>\n    <a\
    \ href=\"https://pypi.org/project/fasterai/\"><img src=\"https://static.pepy.tech/personalized-badge/fasterai?color=%235BAFAFperiod=total&units=international_system&left_color=grey&right_color=%235BAFAF&left_text=downloads\"\
    ></a>\n    <a href=\"https://opensource.org/licenses/MIT\"><img src=\"https://img.shields.io/github/license/nathanhubens/fasterai?color=%235bafaf\"\
    ></a>\n    <a href=\"https://pypi.org/project/fasterai/\"><img src=\"https://img.shields.io/badge/DOI-10.5281%2Fzenodo.6469868-y?color=%235BAFAF\"\
    ></a>\n</p>\n\n\n<p align=\"center\">\n  <a href=\"#methods\">Methods</a> \u2022\
    \n  <a href=\"#features\">Features</a> \u2022\n  <a href=\"#installation\">Installation</a>\
    \ \u2022\n  <a href=\"#tutorials\">Tutorials</a> \u2022\n  <a href=\"#citing\"\
    >Citing</a> \u2022\n  <a href=\"#license\">License</a>\n</p>\n\n`fasterai` is\
    \ a library created to make neural network **smaller** and **faster**. It essentially\
    \ relies on common compression techniques for networks such as pruning, knowledge\
    \ distillation, Lottery Ticket Hypothesis, ...\n\nThe core feature of `fasterai`\
    \ is its Sparsifying capabilities, constructed on 4 main modules: **granularity**,\
    \ **context**, **criteria**, **schedule**. Each of these modules is highly customizable,\
    \ allowing you to change them according to your needs or even to come up with\
    \ your own !\n\n## Project Documentation\n\nVisit [Read The Docs Project Page](https://nathanhubens.github.io/fasterai/)\
    \ or read following README to know more about using `fasterai`.\n\n---\n\n## \
    \ Features\n\n### 1. Sparsifying\n\n![alt text](nbs/imgs/sparsification.png \"\
    Sparsification\")\n\nMake your model sparse (*i.e.* prune it) according to a:\n\
    - <b>Sparsity: </b> the percentage of weights that will be replaced by 0\n- <b>Granularity:\
    \ </b> the granularity at which you operate the pruning (removing weights, vectors,\
    \ kernels, filters)\n- <b>Context: </b> prune either each layer independantly\
    \ (local pruning) or the whole model (global pruning)\n- <b>Criteria: </b> the\
    \ criteria used to select the weights to remove (magnitude, movement, ...)\n-\
    \ <b>Schedule: </b> which schedule you want to use for pruning (one shot, iterative,\
    \ gradual, ...)\n\nThis can be achieved by using the `SparsifyCallback(sparsity,\
    \ granularity, context, criteria, schedule)`\n\n### 2. Pruning\n\n![alt text](nbs/imgs/pruning_readme.png\
    \ \"Pruning\")\n\nOnce your model has useless nodes due to zero-weights, they\
    \ can be removed to not be a part of the network anymore.\n\nThis can be achieved\
    \ by using the `Pruner()` method\n\n### 3. Regularization\n\n![alt text](nbs/imgs/regularization.png\
    \ \"Regularization\")\n\nInstead of explicitely make your network sparse, let\
    \ it train towards sparse connections by pushing the weights to be as small as\
    \ possible.\n\nRegularization can be applied to groups of weights, following the\
    \ same granularities as for sparsifying, i.e.:\n- <b>Granularity: </b> the granularity\
    \ at which you operate the regularization (weights, vectors, kernels, filters,\
    \ ...)\n\nThis can be achieved by using the `RegularizationCallback(granularity)`\n\
    \n### 4. Knowledge Distillation\n\n![alt text](nbs/imgs/distillation.png \"Distillation\"\
    )\n\nDistill the knowledge acquired by a big model into a smaller one, by using\
    \ the `KnowledgeDistillation` callback.\n\n### 5. Lottery Ticket Hypothesis\n\n\
    ![alt text](nbs/imgs/LTH.png \"Lottery Ticket Hypothesis\")\n\nFind the winning\
    \ ticket in you network, *i.e.* the initial subnetwork able to attain at least\
    \ similar performances than the network as a whole.\n\n---\n\n##  Quick Start\n\
    \n### 0. Import fasterai\n\n```python\nfrom fasterai.sparse.all import *\n```\n\
    \n### 1. Create your model with fastai\n\n```python\nlearn = cnn_learner(dls,\
    \ model)\n```\n\n### 2. Get you Fasterai Callback\n\n```python\nsp_cb=SparsifyCallback(sparsity,\
    \ granularity, context, criteria, schedule)\n```\n\n### 3. Train you model to\
    \ make it sparse !\n\n```python\nlearn.fit_one_cycle(n_epochs, cbs=sp_cb)\n```\n\
    \n---\n\n##  Installation\n\n\n```\npip install git+https://github.com/nathanhubens/fasterai.git\n\
    ```\n\nor \n\n```\npip install fasterai\n```\n\n---\n\n## Tutorials\n\n- [Get\
    \ Started with FasterAI](https://nathanhubens.github.io/fasterai/quickstart.html)\n\
    - [Create your own pruning schedule](https://nathanhubens.github.io/fasterai/tutorial.schedules.html)\n\
    - [Find winning tickets using the Lottery Ticket Hypothesis](https://nathanhubens.github.io/fasterai/tutorial.lottery_ticket.html)\n\
    - [Use Knowledge Distillation to help a student model to reach higher performance](https://nathanhubens.github.io/fasterai/tutorial.knowledge_distillation.html)\n\
    - [Sparsify Transformers](https://nathanhubens.github.io/fasterai/tutorial.transformers.html)\n\
    - More to come...\n\n---\n\n##  Citing\n```\n@software{Hubens,\n  author     \
    \  = {Nathan Hubens},\n  title        = {fasterai},\n  year         = 2022,\n\
    \  publisher    = {Zenodo},\n  version      = {v0.1.6},\n  doi          = {10.5281/zenodo.6469868},\n\
    \  url          = {https://doi.org/10.5281/zenodo.6469868}\n}\n```\n\n---\n\n\
    ## License\n\n[Apache-2.0](https://www.apache.org/licenses/) License.\n\n![footer](https://capsule-render.vercel.app/api?type=waving&color=008080&height=100&section=footer)\n"
  dev_url: https://github.com/nathanhubens/fasterai/tree/master/
  doc_url: https://nathanhubens.github.io/fasterai/
  home: https://github.com/nathanhubens/fasterai/tree/master/
  license: Apache Software
  license_family: APACHE
  summary: A library to make neural networks lighter and faster with fastai
build:
  noarch: python
  number: '0'
  script: '{{ PYTHON }} -m pip install . -vv'
extra:
  recipe-maintainers:
  - nathanhubens
requirements:
  host:
  - pip
  - python
  - packaging
  - fastai>=2.2
  run:
  - pip
  - python
  - packaging
  - fastai>=2.2
test:
  imports:
  - fasterai
