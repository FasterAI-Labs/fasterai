# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/core/schedules.ipynb.

# %% ../../nbs/core/schedules.ipynb #experienced-subsection
from __future__ import annotations
import numpy as np
import matplotlib.pyplot as plt
from fastcore.basics import *
from fastai.callback.schedule import *
import math
from typing import Callable

# %% auto #0
__all__ = ['one_shot', 'iterative', 'agp', 'one_cycle', 'cos', 'lin', 'dsd', 'schedules', 'Schedule', 'sched_oneshot',
           'sched_iterative', 'sched_agp', 'sched_onecycle', 'sched_dsd', 'available_schedules']

# %% ../../nbs/core/schedules.ipynb #a46d12a3
class Schedule():
    "Base class to create schedules that return progress (0→1)"
    def __init__(self,
                 sched_func: Callable,  # Function that computes progress at given training percentage
                 start_pct: float = 0., # Percentage of training to start schedule
                 end_pct: float = 1.,   # Percentage of training to end schedule
                 start_val: float = 0., # Starting value for progress range
                 end_val: float = 1.    # Ending value for progress range
    ):
        "Base class to create schedules for pruning, regularization, distillation, etc."
        store_attr()
        self._current_progress = start_val
        self._previous_progress = start_val

    def progress(self, pct_train: float) -> float:
        "Return progress value based on training progress"
        if pct_train < self.start_pct:
            self._current_progress = self.start_val
        elif pct_train >= self.end_pct:
            self._current_progress = self.sched_func(self.start_val, self.end_val, 1.)
        else:
            normalized = (pct_train - self.start_pct) / (self.end_pct - self.start_pct)
            self._current_progress = self.sched_func(self.start_val, self.end_val, normalized)
        return self._current_progress

    @property
    def changed(self) -> bool:
        "Check if progress changed since last step"
        return self._previous_progress != self._current_progress

    # Backward compatibility alias
    @property
    def pruned(self) -> bool:
        "Deprecated: use `.changed` instead"
        return self.changed

    def after_step(self) -> None:
        "Update previous progress after action applied"
        self._previous_progress = self._current_progress

    # Backward compatibility alias
    def after_pruned(self) -> None:
        "Deprecated: use `after_step()` instead"
        self.after_step()

    def reset(self) -> None:
        "Reset to initial state"
        self._current_progress = self.start_val
        self._previous_progress = self.start_val

    def plot(self,
             target: float = 100,    # Target value to visualize (e.g., sparsity percentage)
             num_points: int = 1000  # Number of points to plot
    ) -> None:
        "Plot the schedule showing how target value changes over training"
        pcts = np.linspace(0, 1, num_points)
        values = [self.progress(p) * target for p in pcts]
        fig, ax = plt.subplots(1, 1, figsize=(8,6), dpi=100)
        plt.plot(pcts, values, c='teal', linewidth=2)
        plt.xlabel('training iterations (Normalized)')
        plt.ylabel('value')
        self.reset()

# %% ../../nbs/core/schedules.ipynb #corresponding-religious
def sched_oneshot(
    start: float, # Starting sparsity level
    end: float,   # Target sparsity level
    pos: float    # Current position in schedule (0-1)
) -> float:
    "One-shot pruning: jump directly to target sparsity"
    return end

one_shot = Schedule(sched_oneshot, start_pct=0.5)

# %% ../../nbs/core/schedules.ipynb #4fb3ead4
def sched_iterative(
    start: float, # Starting sparsity level
    end: float,   # Target sparsity level
    pos: float,   # Current position in schedule (0-1)
    n_steps: int = 3  # Number of pruning steps
) -> float:
    "Perform iterative pruning in discrete steps"
    return start + ((end-start)/n_steps) * (np.ceil(pos * n_steps))

iterative = Schedule(sched_iterative, start_pct=0.2)

# %% ../../nbs/core/schedules.ipynb #electronic-trainer
def sched_agp(
    start: float, # Starting sparsity level
    end: float,   # Target sparsity level
    pos: float    # Current position in schedule (0-1)
) -> float:
    "Automated gradual pruning schedule with cubic decay"
    return end + (start - end) * (1 - pos)**3

agp = Schedule(sched_agp, start_pct=0.2)

# %% ../../nbs/core/schedules.ipynb #6d4f11c9
def sched_onecycle(
    start: float,  # Starting sparsity level
    end: float,    # Target sparsity level
    pos: float,    # Current position in schedule (0-1)
    α: float = 14, # Steepness parameter
    β: float = 6   # Offset parameter
) -> float:
    "One-cycle schedule based on logistic function"
    out = (1+np.exp(-α+β)) / (1 + (np.exp((-α*pos)+β)))
    return start + (end-start)*out

one_cycle = Schedule(sched_onecycle)

# %% ../../nbs/core/schedules.ipynb #e89d1f70
cos = Schedule(sched_cos)
lin = Schedule(sched_lin)

# %% ../../nbs/core/schedules.ipynb #decent-savannah
def sched_dsd(
    start: float, # Starting sparsity level
    end: float,   # Target sparsity level
    pos: float    # Current position in schedule (0-1)
) -> float:
    "Dense-Sparse-Dense schedule: increase then decrease sparsity"
    if pos<0.5:
        return start + (1 + math.cos(math.pi*(1-pos*2))) * (end-start) / 2
    else:
        return end + (1 - math.cos(math.pi*(1-pos*2))) * (start-end) / 2
    
dsd = Schedule(sched_dsd)

# %% ../../nbs/core/schedules.ipynb #cb923e44
schedules = ('one_shot', 'iterative', 'agp', 'one_cycle', 'cos', 'lin', 'dsd')
def available_schedules() -> list[str]:
    "Return list of available pruning schedules"
    return list(schedules)
