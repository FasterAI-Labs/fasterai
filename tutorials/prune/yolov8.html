<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="YOLOV8">

<title>YOLOV8 – fasterai</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-707d8167ce6003fca903bfe2be84ab7f.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-11812d3bc142aca4717562015a1909d7.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-3c8ca0cc7bbe25650b9aaaacd4d5c9ab.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-424WWZFZ5F"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-424WWZFZ5F', { 'anonymize_ip': true});
</script>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="YOLOV8 – fasterai">
<meta property="og:description" content="YOLOV8">
<meta property="og:site_name" content="fasterai">
<meta name="twitter:title" content="YOLOV8 – fasterai">
<meta name="twitter:description" content="YOLOV8">
<meta name="twitter:creator" content="@nathanhubens">
<meta name="twitter:site" content="@fasterai">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed quarto-dark"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = true;
    const darkModeDefault = authorPrefersDark;
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">fasterai</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="mailto:nathan.hubens@gmail.com?subject=Hello"> <i class="bi bi-chat-right-text" role="img">
</i> 
<span class="menu-text">Contact Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/nathanhubens/fasterai/issues"> <i class="bi bi-bug" role="img">
</i> 
<span class="menu-text">Report an Issue</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://discord.gg/32BwhJSB9u"> <i class="bi bi-discord" role="img">
</i> 
<span class="menu-text">Join the Community</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/nathanhubens/fasterai"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/fasterai"> <i class="bi bi-twitter" role="img" aria-label="FasterAI Twitter">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../tutorials/walkthrough.html">Tutorials</a></li><li class="breadcrumb-item"><a href="../../tutorials/prune/prune_callback.html">Prune</a></li><li class="breadcrumb-item"><a href="../../tutorials/prune/yolov8.html">YOLOV8</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="../../index.html" class="sidebar-logo-link">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Overview</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../quickstart.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quick Start</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Tutorials</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/walkthrough.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Walkthrough</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Sparse</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/sparse/schedules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedules</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/sparse/sparsifier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sparsifier</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/sparse/sparsify_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sparsify Callback</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/sparse/lottery_ticket.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Lottery Ticket Hypothesis</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/sparse/transformers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prune Transformers</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Prune</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/prune/prune_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prune Callback</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/prune/yolov8.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">YOLOV8</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Distill</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/distill/distill_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KnowledgeDistillation Callback</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Regularize</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/regularize/regularize_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regularize Callback</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Misc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/misc/bn_folding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">BatchNorm Folding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../tutorials/misc/fc_decomposer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fully-Connected layers decomposition</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Core</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../core/granularity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Granularity</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../core/criteria.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Criteria</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../core/schedules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Schedules</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">Sparse</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../sparse/sparsifier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sparsifier</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../sparse/sparsify_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Sparsify Callback</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Prune</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prune/pruner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Pruner</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../prune/prune_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prune Callback</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Distill</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../distill/distillation_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Knowledge Distillation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false">
 <span class="menu-text">Quantize</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-11" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-11" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../quantize/quantizer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantizer</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../quantize/quantize_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantize Callback</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false">
 <span class="menu-text">Regularize</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-12" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-12" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../regularize/regularize_callback.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Regularize Callback</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false">
 <span class="menu-text">Misc</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-13" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-13" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../misc/bn_folding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Batch Norm Folding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../misc/fc_decomposer.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fully-Connected Layers Decomposer</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#helpers" id="toc-helpers" class="nav-link active" data-scroll-target="#helpers">Helpers</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a></li>
  <li><a href="#post-training-checks" id="toc-post-training-checks" class="nav-link" data-scroll-target="#post-training-checks">Post-Training Checks</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/FasterAI-Labs/fasterai/tree/master/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../tutorials/walkthrough.html">Tutorials</a></li><li class="breadcrumb-item"><a href="../../tutorials/prune/prune_callback.html">Prune</a></li><li class="breadcrumb-item"><a href="../../tutorials/prune/yolov8.html">YOLOV8</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">YOLOV8</h1>
</div>

<div>
  <div class="description">
    YOLOV8
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<section id="helpers" class="level2">
<h2 class="anchored" data-anchor-id="helpers">Helpers</h2>
</section>
<section id="training" class="level2">
<h2 class="anchored" data-anchor-id="training">Training</h2>
<div id="30b08319-6d07-4e42-9528-3e09a0558e93" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Args(argparse.Namespace):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  model <span class="op">=</span> <span class="st">'yolov8l.pt'</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  cfg <span class="op">=</span> <span class="st">'default.yaml'</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  iterative_steps <span class="op">=</span> <span class="dv">15</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  target_prune_rate <span class="op">=</span> <span class="fl">0.15</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  max_map_drop <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  sched <span class="op">=</span> Schedule(partial(sched_onecycle,  α<span class="op">=</span><span class="dv">10</span>, β<span class="op">=</span><span class="dv">4</span>))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>args<span class="op">=</span>Args()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>prune(args)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.731      0.768      0.828      0.658

Speed: 0.1ms preprocess, 7.5ms inference, 0.0ms loss, 0.8ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/val39</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Before Pruning: MACs= 82.72641 G, #Params= 43.69152 M, mAP= 0.65799</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/train33

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)

<span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/train33/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/train33</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10        12G     0.9535     0.9388      1.178    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.824      0.712      0.832      0.665



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.2G     0.9172     0.8093      1.161    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.836      0.755      0.842      0.682



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.6G     0.9013     0.7191      1.099    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.874      0.756      0.852      0.691



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      12.1G     0.9249     0.7495      1.118    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.858      0.793      0.863      0.699



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.8G     0.8319     0.6796      1.082    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.859       0.81      0.882      0.717



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.9G     0.8412     0.6843      1.096    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.848      0.828      0.892      0.729



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      12.1G      0.814     0.6248      1.067    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.88      0.825      0.898      0.737



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.9G     0.8093      0.615      1.067    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.905      0.819      0.897      0.748



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.8G     0.7573     0.5698      1.036    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.905       0.83      0.901      0.755



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      12.1G     0.7934     0.6052      1.075    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.894      0.835        0.9      0.758



10 epochs completed in 0.029 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/train33/weights/last.pt, 175.3MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/train33/weights/best.pt, 175.3MB



Validating /home/HubensN/ultralytics/runs/detect/train33/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.894      0.835        0.9      0.758

Speed: 0.1ms preprocess, 4.2ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/train33</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 43668288 parameters, 0 gradients, 165.2 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.892      0.826      0.901      0.751

Speed: 0.2ms preprocess, 10.8ms inference, 0.0ms loss, 0.5ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/baseline_val28</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Before Pruning: MACs= 82.72641 G, #Params= 43.69152 M, mAP= 0.75140
Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.0027046189978777607
After Pruning
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 43081939 parameters, 74176 gradients, 162.7 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929        0.9      0.825      0.906      0.734

Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_0_pre_val17</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_0_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_0_finetune16

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 1: MACs=81.5020432 G, #Params=43.105009 M, mAP=0.7335178809742455, speed up=1.0150224847369225</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_0_finetune16/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_0_finetune16</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      12.7G     0.7839       0.65      1.053    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.886      0.849      0.906      0.752



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.7G     0.7319      0.499      1.036    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.901      0.856      0.914      0.756



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      12.5G     0.7449     0.4985      1.014    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.896      0.864      0.915       0.76



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      12.6G     0.7679     0.5147      1.027    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.896      0.864      0.912      0.758



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      12.7G     0.6996     0.4846      1.015    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.909      0.863      0.915      0.761



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      12.8G     0.7258      0.516      1.026    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.908      0.869      0.916      0.766



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      12.8G     0.7541     0.5142      1.024    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.919      0.863      0.915      0.771



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      12.8G     0.7233     0.5094      1.014    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.912      0.868      0.917      0.776



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      12.8G       0.69     0.4918     0.9917    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.909      0.869      0.919      0.778



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      12.8G     0.7366     0.5463      1.035    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.919      0.865      0.918      0.779



10 epochs completed in 0.029 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_0_finetune16/weights/last.pt, 173.0MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_0_finetune16/weights/best.pt, 173.0MB



Validating /home/HubensN/ultralytics/runs/detect/step_0_finetune16/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 43081939 parameters, 0 gradients, 162.7 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.919      0.865      0.918      0.778

Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_0_finetune16</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 43081939 parameters, 0 gradients, 162.7 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.909      0.865      0.915      0.776

Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_0_post_val12</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.775721307939776
After post fine-tuning validation
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.005179586515491673
After Pruning
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 42712366 parameters, 74176 gradients, 161.3 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.923      0.859      0.916      0.767

Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_1_pre_val9</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_1_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_1_finetune9

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 2: MACs=80.7933916 G, #Params=42.735334 M, mAP=0.7671079746246661, speed up=1.0239254072854147</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)

<span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_1_finetune9/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_1_finetune9</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      13.6G     0.6788     0.5264     0.9988    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.91      0.873      0.918      0.777



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.7G     0.6175     0.4036     0.9705    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.93      0.863       0.92      0.783



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      12.6G      0.646     0.4189     0.9632    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.918      0.863      0.922      0.782



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      12.7G     0.6623     0.4434     0.9798    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.925       0.86      0.923      0.785



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      12.8G     0.6136     0.4164     0.9643    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.861      0.926      0.787



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      12.8G     0.6421     0.4466     0.9727    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.928      0.862      0.928      0.794



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      12.8G     0.6767      0.457     0.9847    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.934      0.865      0.931      0.795



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      12.9G     0.6599     0.4573     0.9827    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.877      0.934      0.797



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      12.8G     0.6616     0.4547     0.9732    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.928      0.872      0.935      0.802



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      12.7G     0.6991     0.5169      1.008    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.934      0.869      0.936      0.803



10 epochs completed in 0.039 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_1_finetune9/weights/last.pt, 171.5MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_1_finetune9/weights/best.pt, 171.5MB



Validating /home/HubensN/ultralytics/runs/detect/step_1_finetune9/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 42712366 parameters, 0 gradients, 161.3 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.933      0.871      0.935      0.803

Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_1_finetune9</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 42712366 parameters, 0 gradients, 161.3 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929       0.91      0.872       0.93      0.792

Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_1_post_val9</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.7924603103645905
After post fine-tuning validation
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.009769531739708686
After Pruning
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 42094706 parameters, 74176 gradients, 158.8 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.908      0.868      0.924      0.779

Speed: 0.1ms preprocess, 13.4ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_2_pre_val9</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_2_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_2_finetune9

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 63, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 3: MACs=79.5541908 G, #Params=42.117503 M, mAP=0.7792330059497833, speed up=1.0398749024796818</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_2_finetune9/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_2_finetune9</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10        13G     0.6418     0.5222     0.9767    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.914      0.885      0.929      0.796



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.6G     0.5453      0.368     0.9336    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.92      0.884      0.938      0.802



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      12.5G     0.5814     0.3836     0.9312    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.925      0.884      0.937      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      12.6G     0.6058     0.3976     0.9452    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.949       0.87      0.937      0.807



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      12.6G     0.5516     0.3755     0.9373    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.948      0.867      0.939       0.81



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      12.7G     0.5859     0.4033     0.9496    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.929      0.887      0.942      0.811



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      12.6G      0.635     0.4225     0.9698    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.942      0.883      0.941      0.809



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      12.7G     0.6191     0.4212     0.9639    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.937      0.888      0.941      0.815



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      12.7G      0.631     0.4236     0.9608    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.936      0.889      0.942       0.82



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      12.6G     0.6808     0.5085      1.003    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.935      0.889      0.942      0.821



10 epochs completed in 0.040 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_2_finetune9/weights/last.pt, 169.0MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_2_finetune9/weights/best.pt, 169.0MB



Validating /home/HubensN/ultralytics/runs/detect/step_2_finetune9/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 42094706 parameters, 0 gradients, 158.8 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.935       0.89      0.942      0.821

Speed: 0.1ms preprocess, 4.4ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_2_finetune9</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 42094706 parameters, 0 gradients, 158.8 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.883      0.942      0.811

Speed: 0.2ms preprocess, 13.5ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_2_post_val9</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8108994344622686
After post fine-tuning validation
Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.017924759478681728
After Pruning
Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 40919781 parameters, 74176 gradients, 154.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.911      0.866      0.928      0.771

Speed: 0.2ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_3_pre_val8</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_3_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_3_finetune8

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 4: MACs=77.3600192 G, #Params=40.942254 M, mAP=0.7714194636333309, speed up=1.0693690003634333</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_3_finetune8/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_3_finetune8</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      12.6G     0.6354     0.4858     0.9676    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.931       0.87      0.936      0.788



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.6G     0.5377     0.3467     0.9207    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.933      0.878      0.939      0.795



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      12.5G      0.588     0.3751     0.9277    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.939      0.875      0.939      0.801



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      12.6G     0.5795     0.3872     0.9303    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.944       0.87      0.937      0.805



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      12.6G     0.5511     0.3675     0.9235    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.943      0.872      0.937      0.812



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      12.7G     0.5638     0.3974     0.9317    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.925      0.879      0.939      0.812



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      12.6G     0.6183     0.4048     0.9559    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.915      0.885      0.939      0.812



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      12.7G     0.6064     0.4156     0.9551    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.888       0.94       0.81



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      12.7G     0.6126     0.4111     0.9473    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.928      0.898      0.943      0.819



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      12.6G     0.6751     0.4922      1.001    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.898      0.942       0.82



10 epochs completed in 0.027 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_3_finetune8/weights/last.pt, 164.3MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_3_finetune8/weights/best.pt, 164.3MB



Validating /home/HubensN/ultralytics/runs/detect/step_3_finetune8/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 40919781 parameters, 0 gradients, 154.4 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.898      0.942       0.82

Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_3_finetune8</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 40919781 parameters, 0 gradients, 154.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.919      0.891      0.941      0.813

Speed: 0.1ms preprocess, 13.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_3_post_val7</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.813335254805048
After post fine-tuning validation
Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>0.03136884242508382
After Pruning
Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 39455305 parameters, 74176 gradients, 149.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.853       0.93      0.771

Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_4_pre_val7</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_4_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_4_finetune7

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 61, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 5: MACs=74.8418608 G, #Params=39.477376 M, mAP=0.7709511018059185, speed up=1.1053494062777232</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_4_finetune7/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_4_finetune7</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      12.8G     0.6393     0.4996     0.9632    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.91      0.879      0.934      0.787



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.7G     0.5385     0.3464     0.9142    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.915      0.879      0.936      0.801



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      12.5G     0.5725     0.3758     0.9139    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.916      0.899      0.943      0.805



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      12.6G     0.5814     0.3863     0.9212    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.923        0.9      0.948      0.812



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      12.7G     0.5392     0.3637     0.9171    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.901      0.948      0.811



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      12.9G     0.5582     0.4023     0.9233    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.93      0.898       0.95      0.813



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      12.8G     0.6234     0.4091     0.9585    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.905      0.951      0.816



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      12.8G     0.6062     0.4115     0.9444    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.908      0.953      0.816



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      12.7G     0.6105     0.4111     0.9411    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.906      0.949      0.818



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      12.6G     0.6834      0.498      1.001    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.926      0.906       0.95      0.819



10 epochs completed in 0.027 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_4_finetune7/weights/last.pt, 158.5MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_4_finetune7/weights/best.pt, 158.5MB



Validating /home/HubensN/ultralytics/runs/detect/step_4_finetune7/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 39455305 parameters, 0 gradients, 149.4 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.905       0.95      0.819

Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_4_finetune7</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 39455305 parameters, 0 gradients, 149.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.921      0.909      0.951      0.816

Speed: 0.2ms preprocess, 13.4ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_4_post_val6</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8155992309783842
After post fine-tuning validation
Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.051012679818528694
After Pruning
Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 37708749 parameters, 74176 gradients, 143.2 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.902      0.862      0.927      0.764

Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_5_pre_val6</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_5_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_5_finetune6

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 60, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 6: MACs=71.732976 G, #Params=37.730325 M, mAP=0.7640629035267851, speed up=1.1532549046898597</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)

<span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_5_finetune6/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_5_finetune6</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      13.1G     0.6622     0.5187     0.9815    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.911      0.878      0.936      0.782



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.7G     0.5412     0.3602       0.91    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.908      0.899       0.94      0.793



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      12.6G     0.5946     0.3883     0.9197    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.918      0.893      0.941      0.799



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      12.7G     0.5856      0.396     0.9263    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.937       0.88      0.942      0.805



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      12.7G     0.5495     0.3637     0.9176    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.93      0.873      0.944      0.808



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      12.8G     0.5562      0.396     0.9231    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.938      0.872      0.945      0.805



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      12.7G     0.6301     0.4115     0.9537    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.883      0.942      0.808



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      12.8G     0.6138     0.4093      0.944    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.919      0.894      0.946       0.81



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      12.8G     0.6297     0.4207     0.9478    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.926      0.898      0.949      0.813



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      12.7G      0.703     0.5027      1.009    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.898       0.95      0.814



10 epochs completed in 0.037 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_5_finetune6/weights/last.pt, 151.5MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_5_finetune6/weights/best.pt, 151.5MB



Validating /home/HubensN/ultralytics/runs/detect/step_5_finetune6/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 37708749 parameters, 0 gradients, 143.2 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.898       0.95      0.814

Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_5_finetune6</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 37708749 parameters, 0 gradients, 143.2 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.888      0.946       0.81

Speed: 0.1ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_5_post_val6</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8104708131787314
After post fine-tuning validation
Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.07518590641324997
After Pruning
Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 35995675 parameters, 74176 gradients, 136.7 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.878      0.799      0.907       0.74

Speed: 0.2ms preprocess, 12.7ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_6_pre_val6</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_6_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_6_finetune6

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 59, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 7: MACs=68.4860368 G, #Params=36.016747 M, mAP=0.7398590274182758, speed up=1.207930992438447</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_6_finetune6/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_6_finetune6</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      11.7G     0.6993     0.5584     0.9858    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.902      0.841      0.921      0.764



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.8G     0.5531     0.3752     0.9125    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.91      0.849      0.927      0.782



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.7G     0.6039     0.4089     0.9216    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.926       0.86       0.93      0.788



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.5G     0.6132      0.414     0.9289    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.906      0.882      0.933      0.796



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.5G     0.5718      0.383     0.9257    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.909      0.879      0.938      0.789



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.9G     0.5734     0.4089     0.9254    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.928      0.877      0.942      0.797



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.5G     0.6396     0.4206     0.9589    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.929      0.883      0.945        0.8



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.6G     0.6347     0.4307     0.9533    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.932      0.879      0.946      0.807



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.6G     0.6589     0.4376     0.9609    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.931      0.885      0.947      0.808



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.8G     0.7121     0.5232      1.016    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.93      0.886      0.945       0.81



10 epochs completed in 0.025 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_6_finetune6/weights/last.pt, 144.6MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_6_finetune6/weights/best.pt, 144.6MB



Validating /home/HubensN/ultralytics/runs/detect/step_6_finetune6/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 35995675 parameters, 0 gradients, 136.7 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.929      0.887      0.945      0.808

Speed: 0.1ms preprocess, 4.7ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_6_finetune6</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 35995675 parameters, 0 gradients, 136.7 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.887      0.943      0.804

Speed: 0.1ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_6_post_val5</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8040926175515907
After post fine-tuning validation
Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.09935913300797124
After Pruning
Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 34583399 parameters, 74176 gradients, 131.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.915      0.829      0.917      0.733

Speed: 0.1ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_7_pre_val5</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_7_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_7_finetune5

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 57, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 8: MACs=65.8289424 G, #Params=34.604045 M, mAP=0.7333194226117398, speed up=1.2566874597092115</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_7_finetune5/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_7_finetune5</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      11.2G     0.6839     0.5488     0.9811    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.931      0.847      0.932      0.764



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.5G     0.5602     0.3693     0.9134    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.92      0.869      0.936      0.781



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.4G     0.5984     0.3895     0.9188    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.905      0.879      0.936      0.782



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.6G     0.6034      0.418     0.9248    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.899      0.886      0.936      0.782



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.4G     0.5658     0.3782      0.928    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.925      0.872      0.938      0.788



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.7G     0.5917     0.4156     0.9288    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.92      0.882      0.939      0.794



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.4G     0.6339     0.4252     0.9516    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.933      0.876      0.944      0.798



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.4G     0.6471     0.4304     0.9604    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.933      0.878      0.945        0.8



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.4G      0.668     0.4424      0.959    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.884      0.944      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.6G     0.7304     0.5445      1.031    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.919      0.887      0.943      0.802



10 epochs completed in 0.024 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_7_finetune5/weights/last.pt, 139.0MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_7_finetune5/weights/best.pt, 139.0MB



Validating /home/HubensN/ultralytics/runs/detect/step_7_finetune5/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 34583399 parameters, 0 gradients, 131.4 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.884      0.944      0.802

Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_7_finetune5</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 34583399 parameters, 0 gradients, 131.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.915       0.88       0.94      0.793

Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_7_post_val5</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.7931599917268005
After post fine-tuning validation
Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.11900297040141611
After Pruning
Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 33747610 parameters, 74176 gradients, 128.5 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.919      0.861       0.93      0.769

Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_8_pre_val5</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_8_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_8_finetune5

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 56, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 9: MACs=64.3900056 G, #Params=33.768007 M, mAP=0.7690853683854553, speed up=1.2847709148203583</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)

<span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_8_finetune5/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_8_finetune5</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10        12G     0.6504     0.5212     0.9696    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.934       0.87      0.935      0.782



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.6G     0.5047     0.3425     0.8995    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.908      0.889      0.936      0.791



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.5G     0.5622     0.3725     0.9046    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.913      0.892      0.938      0.788



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.7G     0.5558     0.3856     0.9139    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.925      0.894      0.941      0.791



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.7G     0.5481     0.3728       0.92    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.92      0.886      0.939       0.79



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.2G     0.5576     0.4045     0.9157    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.928      0.888      0.943      0.792



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.1G      0.635      0.429     0.9474    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.935      0.891      0.947      0.794



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.2G     0.6145     0.4019     0.9449    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.939      0.887      0.949        0.8



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.2G     0.6569     0.4243     0.9517    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.945      0.881      0.949      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.6G     0.7253     0.5226      1.024    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.945      0.883      0.948      0.802



10 epochs completed in 0.034 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_8_finetune5/weights/last.pt, 135.6MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_8_finetune5/weights/best.pt, 135.6MB



Validating /home/HubensN/ultralytics/runs/detect/step_8_finetune5/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 33747610 parameters, 0 gradients, 128.5 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.946      0.881      0.949      0.803

Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_8_finetune5</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 33747610 parameters, 0 gradients, 128.5 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.937      0.875      0.942      0.796

Speed: 0.2ms preprocess, 11.9ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_8_post_val5</span>
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.7963247276929302
After post fine-tuning validation
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.1324470533478182
After Pruning
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 33209910 parameters, 74176 gradients, 126.7 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.935      0.847      0.931      0.768

Speed: 0.2ms preprocess, 11.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_9_pre_val3</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_9_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_9_finetune3

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 10: MACs=63.4942128 G, #Params=33.230145 M, mAP=0.7676251325156896, speed up=1.302896795658832</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_9_finetune3/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_9_finetune3</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      12.2G      0.627     0.5006     0.9614    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.92      0.879       0.94      0.792



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      12.4G     0.4757     0.3198     0.8867    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.935      0.878      0.944      0.798



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.7G     0.5402     0.3563     0.8958    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.931      0.877      0.941      0.798



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.8G     0.5459     0.3752     0.9083    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.934      0.882      0.945      0.796



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.8G     0.5164     0.3487     0.9079    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.923      0.893      0.943      0.795



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.9G     0.5421      0.385     0.9102    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.918      0.896      0.942      0.793



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.8G     0.6251     0.4038     0.9468    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.926       0.89      0.945      0.795



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.9G     0.5953     0.3998      0.934    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.918      0.905      0.946      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.9G     0.6388     0.4184     0.9476    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.92      0.898      0.947      0.802



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.7G     0.7187     0.5164      1.018    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.93      0.895      0.947      0.806



10 epochs completed in 0.031 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_9_finetune3/weights/last.pt, 133.4MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_9_finetune3/weights/best.pt, 133.4MB



Validating /home/HubensN/ultralytics/runs/detect/step_9_finetune3/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 33209910 parameters, 0 gradients, 126.7 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.932      0.893      0.947      0.805

Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_9_finetune3</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 33209910 parameters, 0 gradients, 126.7 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.936      0.889      0.945      0.801

Speed: 0.2ms preprocess, 11.3ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_9_post_val3</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8009899904343383
After post fine-tuning validation
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.14060228108679124
After Pruning
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32703049 parameters, 74176 gradients, 124.6 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.847      0.937      0.771

Speed: 0.1ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_10_pre_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_10_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_10_finetune2

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 55, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 11: MACs=62.4345712 G, #Params=32.723122 M, mAP=0.7711514639154989, speed up=1.3250096030130178</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_10_finetune2/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_10_finetune2</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10        12G     0.6334     0.5193     0.9605    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.931      0.852       0.94      0.788



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.5G      0.466     0.3067     0.8851    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.942      0.847      0.937      0.796



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.4G     0.5156      0.342     0.8852    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.946      0.868      0.938      0.793



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.5G     0.5392     0.3641     0.9066    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.934      0.884      0.937      0.791



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.5G     0.5117     0.3557     0.9081    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.909      0.894      0.941      0.796



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.6G      0.515      0.373     0.9027    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.911      0.889      0.939      0.796



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.5G     0.6053     0.4073     0.9379    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.905      0.884      0.939      0.797



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.6G     0.5829       0.39     0.9326    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.881      0.944      0.801



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.5G     0.6332     0.4096      0.942    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.929      0.886      0.945      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.5G     0.7178     0.5183      1.015    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.941      0.877      0.945      0.808



10 epochs completed in 0.033 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_10_finetune2/weights/last.pt, 131.4MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_10_finetune2/weights/best.pt, 131.4MB



Validating /home/HubensN/ultralytics/runs/detect/step_10_finetune2/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 32703049 parameters, 0 gradients, 124.6 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.941      0.876      0.945      0.809

Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_10_finetune2</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32703049 parameters, 0 gradients, 124.6 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929       0.92      0.896       0.95      0.808

Speed: 0.2ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_10_post_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8081809745840371
After post fine-tuning validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.14519222631100823
After Pruning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32669140 parameters, 74176 gradients, 124.6 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.917      0.899       0.95       0.81

Speed: 0.2ms preprocess, 12.6ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_11_pre_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_11_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_11_finetune2

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 12: MACs=62.4070664 G, #Params=32.689204 M, mAP=0.8098376035512942, speed up=1.325593577332454</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_11_finetune2/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_11_finetune2</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      11.5G     0.5624     0.4578     0.9404    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.905      0.907      0.946      0.813



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.6G      0.399     0.2726      0.865    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.931      0.879      0.941      0.807



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.4G     0.4809     0.3212      0.879    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.929      0.892      0.941      0.811



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.5G     0.4806      0.334     0.8879    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.945      0.881       0.94      0.804



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.6G     0.4862     0.3288     0.8994    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.938      0.883      0.942      0.806



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.6G     0.4887     0.3584      0.893    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.929       0.89      0.943       0.81



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.6G     0.5702     0.3791     0.9254    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.937      0.888      0.943      0.815



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.6G     0.5531     0.3689     0.9184    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.933      0.896      0.946      0.812



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.6G      0.588     0.3884      0.923    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.926        0.9       0.95      0.815



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.5G     0.7003     0.4962      1.007    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.899      0.949      0.814



10 epochs completed in 0.019 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_11_finetune2/weights/last.pt, 131.3MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_11_finetune2/weights/best.pt, 131.3MB



Validating /home/HubensN/ultralytics/runs/detect/step_11_finetune2/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 32669140 parameters, 0 gradients, 124.6 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.925        0.9       0.95      0.815

Speed: 0.1ms preprocess, 4.0ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_11_finetune2</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32669140 parameters, 0 gradients, 124.6 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.932      0.884      0.943      0.809

Speed: 0.2ms preprocess, 12.5ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_11_post_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.80867019892426
After post fine-tuning validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.14766719382862217
After Pruning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32416863 parameters, 74176 gradients, 123.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.884      0.943      0.793

Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_12_pre_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_12_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_12_finetune2

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 13: MACs=61.8488912 G, #Params=32.436843 M, mAP=0.7929855954557918, speed up=1.3375568226839933</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_12_finetune2/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_12_finetune2</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      11.7G     0.5728     0.4693     0.9395    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.935      0.885      0.944      0.813



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.6G      0.403      0.267     0.8612    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.934      0.876      0.946      0.813



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.4G     0.4806     0.3161     0.8771    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.885      0.945      0.815



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.5G     0.4954     0.3358     0.8895    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.923      0.898      0.946       0.81



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.5G     0.4868     0.3256     0.8983    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.927      0.889      0.945      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.5G     0.5005     0.3485      0.893    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.923      0.901      0.946      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.5G     0.5637     0.3694     0.9171    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.923      0.898      0.946      0.803



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.6G     0.5525      0.361     0.9134    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.94      0.892      0.945      0.809



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.6G     0.5873     0.3731      0.923    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.94      0.897      0.945      0.815



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.5G     0.7004     0.4849      1.012    

                 Class     Images  Instances      Box(P    

                   all        128        929       0.94      0.898      0.946      0.813



10 epochs completed in 0.030 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_12_finetune2/weights/last.pt, 130.3MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_12_finetune2/weights/best.pt, 130.3MB



Validating /home/HubensN/ultralytics/runs/detect/step_12_finetune2/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.921      0.886      0.945      0.814

Speed: 0.1ms preprocess, 4.0ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_12_finetune2</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.931      0.889      0.946       0.81

Speed: 0.2ms preprocess, 12.1ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_12_post_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.81035824268819
After post fine-tuning validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.14897095513156428
After Pruning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32416863 parameters, 74176 gradients, 123.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.921      0.899      0.946      0.809

Speed: 0.1ms preprocess, 12.1ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_13_pre_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_13_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_13_finetune2

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 14: MACs=61.8488912 G, #Params=32.436843 M, mAP=0.8094708031863412, speed up=1.3375568226839933</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre><span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_13_finetune2/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_13_finetune2</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      11.2G     0.5243     0.4358     0.9284    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.922      0.904      0.948      0.817



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.3G     0.3797     0.2496     0.8509    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.926      0.903      0.949      0.819



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.2G     0.4293     0.2921     0.8642    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.939       0.89      0.948      0.821



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.2G     0.4573     0.3141     0.8773    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.936      0.899      0.949      0.816



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.3G     0.4667     0.3122     0.8898    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.929      0.897      0.947      0.811



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.4G     0.4877     0.3356     0.8894    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.932      0.889      0.945      0.802



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.3G     0.5567     0.3642     0.9154    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.937      0.882      0.947      0.807



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.4G      0.522     0.3407     0.9033    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.945      0.885      0.947      0.816



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.3G       0.59     0.3656     0.9174    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.946      0.884      0.947      0.818



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.3G     0.7007      0.488      1.009    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.941      0.887      0.949      0.824



10 epochs completed in 0.020 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_13_finetune2/weights/last.pt, 130.3MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_13_finetune2/weights/best.pt, 130.3MB



Validating /home/HubensN/ultralytics/runs/detect/step_13_finetune2/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929      0.941      0.887      0.949      0.823

Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_13_finetune2</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.923      0.902      0.949      0.818

Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_13_post_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8178296276387611
After post fine-tuning validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
0.14964931342467439
After Pruning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32416863 parameters, 74176 gradients, 123.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.926      0.897      0.949      0.817

Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_14_pre_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">yolo/engine/trainer: </span>task=detect, mode=train, model=None, data=coco128.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=step_14_finetune, exist_ok=False, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=/home/HubensN/ultralytics/runs/detect/step_14_finetune2

<span class="ansi-blue-fg ansi-bold">AMP: </span>running Automatic Mixed Precision (AMP) checks with YOLOv8n...

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After post-pruning Validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
After pruning iter 15: MACs=61.8488912 G, #Params=32.436843 M, mAP=0.8171226992562459, speed up=1.3375568226839933</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/utils/checks.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(True):

<span class="ansi-blue-fg ansi-bold">AMP: </span>checks passed ✅

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:224: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.

  self.scaler = amp.GradScaler(enabled=self.amp)

<span class="ansi-blue-fg ansi-bold">train: </span>Scanning /home/HubensN/datasets/coco128/labels/train

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

Plotting labels to /home/HubensN/ultralytics/runs/detect/step_14_finetune2/labels.jpg... 

<span class="ansi-blue-fg ansi-bold">optimizer:</span> AdamW(lr=0.000119, momentum=0.9) with parameter groups 105 weight(decay=0.0), 112 weight(decay=0.0005), 111 bias(decay=0.0)

Image sizes 640 train, 640 val

Using 8 dataloader workers

Logging results to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_14_finetune2</span>

Starting training for 10 epochs...



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

  0%|          | 0/8 [00:00&lt;?, ?it/s]/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/yolo/engine/trainer.py:330: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.

  with torch.cuda.amp.autocast(self.amp):

       1/10      11.3G     0.5084     0.4275     0.9241    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.943      0.886      0.945      0.824



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       2/10      11.3G     0.3449     0.2386     0.8452    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.939      0.889      0.948      0.826



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       3/10      11.2G     0.4181     0.2863     0.8581    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.945       0.89      0.948      0.821



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       4/10      11.5G     0.4197     0.3033     0.8692    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.954      0.903      0.952       0.82



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       5/10      11.3G     0.4552     0.3053     0.8846    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.949      0.905       0.95      0.819



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       6/10      11.4G     0.4572     0.3242      0.878    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.941      0.904      0.955      0.816



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       7/10      11.3G     0.5533     0.3546     0.9156    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.928      0.905      0.948      0.818



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       8/10      11.7G     0.5238     0.3388     0.9018    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.934      0.909      0.949       0.82



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

       9/10      11.6G     0.5513     0.3486     0.9081    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.943      0.912      0.952      0.821



      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size

      10/10      11.3G     0.6869      0.468     0.9985    

                 Class     Images  Instances      Box(P    

                   all        128        929      0.944      0.913      0.952       0.82



10 epochs completed in 0.018 hours.

/tmp/ipykernel_4010773/2763320149.py:114: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  x = torch.load(f, map_location=torch.device('cpu'))

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/last.pt, 130.3MB

Optimizer stripped from /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt, 130.3MB



Validating /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt...

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load

YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs

                 Class     Images  Instances      Box(P    

                   all        128        929       0.94      0.889      0.948      0.826

Speed: 0.1ms preprocess, 4.1ms inference, 0.0ms loss, 0.3ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_14_finetune2</span>

/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/nn/tasks.py:518: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.

  return torch.load(file, map_location='cpu'), file  # load
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine-tuning
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.924      0.896      0.945       0.82

Speed: 0.2ms preprocess, 12.0ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_14_post_val2</span>

Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CPU
</pre>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>After fine tuning mAP=0.8199030883902761
After post fine-tuning validation
Model Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
Pruner Conv2d(3, 54, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>YOLOv8l summary (fused): 285 layers, 32416863 parameters, 0 gradients, 123.4 GFLOPs



<span class="ansi-blue-fg ansi-bold">PyTorch:</span> starting from /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (124.2 MB)



<span class="ansi-blue-fg ansi-bold">ONNX:</span> starting export with onnx 1.17.0 opset 19...

<span class="ansi-blue-fg ansi-bold">ONNX:</span> export success ✅ 2.2s, saved as /home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.onnx (123.9 MB)



Export complete (2.9s)

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights</span>

Predict:         yolo predict task=detect model=/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.onnx imgsz=640 

Validate:        yolo val task=detect model=/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.onnx imgsz=640 data=/home/HubensN/miniconda3/envs/fasterai20/lib/python3.10/site-packages/ultralytics/datasets/coco128.yaml 

Visualize:       https://netron.app
</pre>
</div>
</div>
</div>
</section>
<section id="post-training-checks" class="level2">
<h2 class="anchored" data-anchor-id="post-training-checks">Post-Training Checks</h2>
<div id="17c4390e-038c-42a5-a80a-872e35bf1b9b" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> YOLO(<span class="st">'/home/HubensN/ultralytics/runs/detect/step_14_finetune2/weights/best.pt'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="883c68d4-e374-4a2d-b1cd-80374a804725" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>example_inputs <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">640</span>, <span class="dv">640</span>).to(model.device)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<div id="5d3527bf-bdca-40f0-93d3-42af28b01b6e" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>base_macs, base_nparams <span class="op">=</span> tp.utils.count_ops_and_params(model.model, example_inputs)<span class="op">;</span> base_macs, base_nparams</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>(61848891200.0, 32436843)</code></pre>
</div>
</div>
<div id="39190b40-3d3b-4844-9da7-c41e9b9aa6c9" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> model.val(</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>                data<span class="op">=</span><span class="st">'coco128.yaml'</span>,</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>                batch<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>                imgsz<span class="op">=</span><span class="dv">640</span>,</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>                verbose<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a>            )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<div class="ansi-escaped-output">
<pre>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce RTX 3090, 24253MiB)

<span class="ansi-blue-fg ansi-bold">val: </span>Scanning /home/HubensN/datasets/coco128/labels/train20

                 Class     Images  Instances      Box(P    

                   all        128        929      0.941      0.891      0.948      0.828

Speed: 0.1ms preprocess, 9.9ms inference, 0.0ms loss, 0.4ms postprocess per image

Results saved to <span class="ansi-bold">/home/HubensN/ultralytics/runs/detect/val41</span>
</pre>
</div>
</div>
</div>
<div id="feb54734-cf16-4051-ae58-1e0b03435c3d" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<pre><code>ultralytics.yolo.utils.metrics.DetMetrics object with attributes:

ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 79])
box: ultralytics.yolo.utils.metrics.Metric object
confusion_matrix: &lt;ultralytics.yolo.utils.metrics.ConfusionMatrix object&gt;
fitness: 0.8398465728578197
keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']
maps: array([    0.80663,     0.56166,     0.46391,     0.97747,     0.97261,     0.92577,      0.9079,     0.78266,     0.69041,     0.39913,      0.8278,      0.8955,      0.8278,     0.86033,     0.85892,       0.995,       0.962,     0.92662,      0.8278,      0.8278,     0.93661,       0.995,     0.96237,     0.85834,
           0.78541,     0.86574,     0.69715,     0.81464,     0.94304,      0.7515,      0.8955,     0.81395,     0.34834,     0.52181,     0.74658,     0.37593,     0.74195,      0.8278,     0.64171,     0.66705,     0.73098,     0.83937,      0.7376,     0.65567,     0.71183,     0.84817,       0.995,      0.8278,
             0.995,      0.8408,     0.68827,      0.8293,     0.92344,      0.9785,       0.995,     0.92662,      0.8607,     0.91091,     0.86934,       0.995,     0.91683,      0.8603,      0.9501,     0.95359,     0.80117,     0.84734,      0.8278,     0.69016,     0.95773,     0.96025,      0.8278,     0.83127,
             0.977,     0.58867,     0.88629,       0.995,       0.995,     0.93602,      0.8278,      0.9465])
names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}
plot: True
results_dict: {'metrics/precision(B)': 0.9410256301337474, 'metrics/recall(B)': 0.8911335314866058, 'metrics/mAP50(B)': 0.9482558527722713, 'metrics/mAP50-95(B)': 0.8278010973117694, 'fitness': 0.8398465728578197}
save_dir: Path('/home/HubensN/ultralytics/runs/detect/val41')
speed: {'preprocess': 0.14928914606571198, 'inference': 9.854648262262344, 'loss': 0.004881992936134338, 'postprocess': 0.43218769133090973}</code></pre>
</div>
</div>
<div id="ef36d64b-13ff-4480-ae1b-7d302a7857e8" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>model.export(<span class="bu">format</span> <span class="op">=</span> <span class="st">'onnx'</span>, half <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>Ultralytics YOLOv8.0.124 🚀 Python-3.10.15 torch-2.5.1+cu124 CPU
WARNING ⚠️ half=True only compatible with GPU export, i.e. use device=0

KeyboardInterrupt
</code></pre>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/FasterAI-Labs\.github\.io\/fasterai\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© By Nathan Hubens</p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/FasterAI-Labs/fasterai/tree/master/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>