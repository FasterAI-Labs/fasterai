---

title: SparsifyCallback


keywords: fastai
sidebar: home_sidebar

summary: "Use the sparsifier in fastai Callback system"
description: "Use the sparsifier in fastai Callback system"
nb_path: "nbs/02_sparsify_callback.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02_sparsify_callback.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">PETS</span><span class="p">)</span>
<span class="n">files</span> <span class="o">=</span> <span class="n">get_image_files</span><span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s2">&quot;images&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">label_func</span><span class="p">(</span><span class="n">f</span><span class="p">):</span> <span class="k">return</span> <span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">ImageDataLoaders</span><span class="o">.</span><span class="n">from_name_func</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">files</span><span class="p">,</span> <span class="n">label_func</span><span class="p">,</span> <span class="n">item_tfms</span><span class="o">=</span><span class="n">Resize</span><span class="p">(</span><span class="mi">64</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SparsifyCallback" class="doc_header"><code>class</code> <code>SparsifyCallback</code><a href="https://github.com/nathanhubens/fasterai/tree/master/fasterai/sparse/sparsify_callback.py#L16" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SparsifyCallback</code>(<strong><code>end_sparsity</code></strong>, <strong><code>granularity</code></strong>, <strong><code>method</code></strong>, <strong><code>criteria</code></strong>, <strong><code>sched_func</code></strong>, <strong><code>start_sparsity</code></strong>=<em><code>0</code></em>, <strong><code>start_epoch</code></strong>=<em><code>0</code></em>, <strong><code>end_epoch</code></strong>=<em><code>None</code></em>, <strong><code>lth</code></strong>=<em><code>False</code></em>, <strong><code>rewind_epoch</code></strong>=<em><code>0</code></em>, <strong><code>reset_end</code></strong>=<em><code>False</code></em>, <strong><code>model</code></strong>=<em><code>None</code></em>, <strong><code>layer_type</code></strong>=<em><code>Conv2d</code></em>) :: <code>Callback</code></p>
</blockquote>
<p>Basic class handling tweaks of the training loop by changing a <code>Learner</code> in various events</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The most important part of our <code>Callback</code> happens in <code>before_batch</code>. There, we first compute the sparsity of our network according to our schedule and then we remove the parameters accordingly.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.677123</td>
      <td>0.685160</td>
      <td>0.805142</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.361229</td>
      <td>0.217795</td>
      <td>0.913396</td>
      <td>00:09</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.190402</td>
      <td>0.177331</td>
      <td>0.929635</td>
      <td>00:09</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's now try adding some sparsity in our model</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">resnet18</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">accuracy</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <a href="/fasterai/sparsify_callback.html#SparsifyCallback"><code>SparsifyCallback</code></a> requires a new argument compared to the <a href="/fasterai/sparsifier.html#Sparsifier"><code>Sparsifier</code></a>. Indeed, we need to know the pruning schedule that we should follow during training in order to prune the parameters accordingly.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can use any scheduling function already <a href="https://docs.fast.ai/callback.schedule.html#Annealing">available</a> in fastai or come up with your own ! For more information about the pruning schedules, take a look at the <a href="https://nathanhubens.github.io/fasterai/schedules.html">Schedules section</a>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sp_cb</span> <span class="o">=</span> <span class="n">SparsifyCallback</span><span class="p">(</span><span class="n">end_sparsity</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;local&#39;</span><span class="p">,</span> <span class="n">criteria</span><span class="o">=</span><span class="n">large_final</span><span class="p">,</span> <span class="n">sched_func</span><span class="o">=</span><span class="n">sched_cos</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">cbs</span><span class="o">=</span><span class="n">sp_cb</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Pruning of weight until a sparsity of 50%
Saving Weights at epoch 0
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.640421</td>
      <td>0.460828</td>
      <td>0.815968</td>
      <td>00:10</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.359529</td>
      <td>0.207824</td>
      <td>0.916103</td>
      <td>00:10</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.194987</td>
      <td>0.186922</td>
      <td>0.924222</td>
      <td>00:10</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sparsity at the end of epoch 0: 12.50%
Sparsity at the end of epoch 1: 37.50%
Sparsity at the end of epoch 2: 50.00%
Final Sparsity: 50.00
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Surprisinlgy, our network that is composed of $50 \%$ of zeroes performs reasonnably well when compared to our plain and dense network.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On top of that, the <a href="/fasterai/sparsify_callback.html#SparsifyCallback"><code>SparsifyCallback</code></a>can also take many optionnal arguments:</p>
<ul>
<li><code>start_sparsity</code>: the sparsity that the schedule will use as a starting point (default to 0)</li>
<li><code>start_epoch</code>: the epoch at which the schedule will start pruning (default to 0)</li>
<li><code>end_epoch</code>: the epoch at which the schedule will stop pruning (default to the training epochs passed in <code>fit</code>)</li>
<li><code>lth</code>: whether training using the Lottery Ticket Hypothesis, i.e. reset the weights to their original value at each pruning step (more information in the Lottery Ticket Hypothesis section)</li>
<li><code>rewind_epoch</code>: the epoch used as a reference for the Lottery Ticket Hypothesis with Rewinding (default to 0)</li>
<li><code>reset_end</code>: whether you want to reset the weights to their original values after training (pruning masks are still applied)</li>
<li><code>model</code>: pass a model or a part of the model if you don't want to apply pruning on the whole model trained.</li>
<li><code>layer_type</code>: specify the type of layer that you want to apply pruning to (default to nn.Conv2d)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For example, we correctly pruned the convolution layers of our model, but we could imagine pruning the Linear Layers of even only the BatchNorm ones !</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">print_sparsity</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sparsity in Conv2d 2: 50.00%
Sparsity in BatchNorm2d 3: 0.00%
Sparsity in Conv2d 8: 50.00%
Sparsity in BatchNorm2d 9: 0.00%
Sparsity in Conv2d 11: 50.00%
Sparsity in BatchNorm2d 12: 0.00%
Sparsity in Conv2d 14: 50.00%
Sparsity in BatchNorm2d 15: 0.00%
Sparsity in Conv2d 17: 50.00%
Sparsity in BatchNorm2d 18: 0.00%
Sparsity in Conv2d 21: 50.00%
Sparsity in BatchNorm2d 22: 0.00%
Sparsity in Conv2d 24: 50.00%
Sparsity in BatchNorm2d 25: 0.00%
Sparsity in Conv2d 27: 50.00%
Sparsity in BatchNorm2d 28: 0.00%
Sparsity in Conv2d 30: 50.00%
Sparsity in BatchNorm2d 31: 0.00%
Sparsity in Conv2d 33: 50.00%
Sparsity in BatchNorm2d 34: 0.00%
Sparsity in Conv2d 37: 50.00%
Sparsity in BatchNorm2d 38: 0.00%
Sparsity in Conv2d 40: 50.00%
Sparsity in BatchNorm2d 41: 0.00%
Sparsity in Conv2d 43: 50.00%
Sparsity in BatchNorm2d 44: 0.00%
Sparsity in Conv2d 46: 50.00%
Sparsity in BatchNorm2d 47: 0.00%
Sparsity in Conv2d 49: 50.00%
Sparsity in BatchNorm2d 50: 0.00%
Sparsity in Conv2d 53: 50.00%
Sparsity in BatchNorm2d 54: 0.00%
Sparsity in Conv2d 56: 50.00%
Sparsity in BatchNorm2d 57: 0.00%
Sparsity in Conv2d 59: 50.00%
Sparsity in BatchNorm2d 60: 0.00%
Sparsity in Conv2d 62: 50.00%
Sparsity in BatchNorm2d 63: 0.00%
Sparsity in Conv2d 65: 50.00%
Sparsity in BatchNorm2d 66: 0.00%
Sparsity in BatchNorm1d 72: 0.00%
Sparsity in Linear 74: 0.00%
Sparsity in BatchNorm1d 76: 0.00%
Sparsity in Linear 78: 0.00%
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

