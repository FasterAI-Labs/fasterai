{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Remove useless filters to recreate a dense network\n",
    "output-file: tutorial.pruner.html\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "title: Pruner\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-miller",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *\n",
    "\n",
    "from fasterai.sparse.all import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce321e7",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "\n",
    "The Pruner method currently works on fully-feedforward ConvNets, e.g. VGG16. Support for residual connections, e.g. ResNets is under development.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b5a0d",
   "metadata": {},
   "source": [
    "When our network has filters containing zero values, there is an additional step that we may take. Indeed, those zero-filters can be **physically** removed from our network, allowing us to get a new, dense, architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf84c3e",
   "metadata": {},
   "source": [
    "This can be done by reexpressing each layer, reducing the number of filter, to match the number of non-zero filters. However, when we remove a filter in a layer, this means that there will be a missing activation map, which should be used by all the filters in the next layer. So, not only should we physically remove the filter, but also its corresponding kernel in each of the filters in the next layer (see Fig. below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e028277",
   "metadata": {},
   "source": [
    "![](imgs/pruning_filters.png \"Pruning Filters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18b0d8d",
   "metadata": {},
   "source": [
    "Let's illustrate this with an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117784c2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "\n",
    "files = get_image_files(path/\"images\")\n",
    "\n",
    "def label_func(f): return f[0].isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-constraint",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(64))"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Pruner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-mystery",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, vgg16_bn(num_classes=2), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c62398",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829801d",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134277186"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07786f82",
   "metadata": {},
   "source": [
    "Our initial model, a VGG16, possess more than 134 million parameters. Let's see what happens when we make it sparse, on a filter level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5fa591",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sp_cb=SparsifyCallback(end_sparsity=50, granularity='filter', method='local', criteria=large_final, sched_func=sched_onecycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43a739",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of filter until a sparsity of 50%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.897482</td>\n",
       "      <td>0.611214</td>\n",
       "      <td>0.698241</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.658607</td>\n",
       "      <td>0.561114</td>\n",
       "      <td>0.706360</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.555238</td>\n",
       "      <td>0.527486</td>\n",
       "      <td>0.718539</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: 10.43%\n",
      "Sparsity at the end of epoch 1: 48.29%\n",
      "Sparsity at the end of epoch 2: 50.00%\n",
      "Final Sparsity: 50.00\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 3e-4, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b69a4",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134277186"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c6225",
   "metadata": {},
   "source": [
    "The total amount of parameters hasn't changed! This is because we only replaced the values by zeroes, leading to a sparse model, but they are still there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b62585",
   "metadata": {},
   "source": [
    "The `Pruner` will take care of removing those useless filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed54ed",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "pruner = Pruner()\n",
    "pruned_model = pruner.prune_model(learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2080fa",
   "metadata": {},
   "source": [
    "Done! Let's see if the performance is still the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d0ed7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "pruned_learn = Learner(dls, pruned_model.cuda(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff3fcc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [0.5265399813652039,0.7212449312210083]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968f57c8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71858210"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(pruned_learn.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd2b553",
   "metadata": {},
   "source": [
    "Now we have 71 million of parameters, approximately 50% of the initial parameters as we asked!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
