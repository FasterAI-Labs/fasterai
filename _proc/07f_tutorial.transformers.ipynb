{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Prune transformers architecture with fasterai\n",
    "output-file: tutorial.transformers.html\n",
    "skip_exec: true\n",
    "skip_showdoc: true\n",
    "title: Prune Transformers\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-naples",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "\n",
    "This example code is taken from the fastai [docs](https://docs.fast.ai/tutorial.transformers.html)\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46b01f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "from transformers.modeling_utils import Conv1D\n",
    "from fastai.text.all import *\n",
    "import fastcore\n",
    "from fasterai.sparse.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-mattress",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "pretrained_weights = 'gpt2'\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(pretrained_weights)\n",
    "model = GPT2LMHeadModel.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-auction",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.WIKITEXT_TINY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-sweden",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "df_train = pd.read_csv(path/'train.csv', header=None)\n",
    "df_valid = pd.read_csv(path/'test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-method",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "all_texts = np.concatenate([df_train[0].values, df_valid[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-talent",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-phrase",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4576 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "splits = [range_of(df_train), list(range(len(df_train), len(all_texts)))]\n",
    "tls = TfmdLists(all_texts, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-cabin",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "bs,sl = 4,256\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-lawsuit",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='662' class='' max='662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [662/662 00:06<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| include: false\n",
    "def tokenize(text):\n",
    "    toks = tokenizer.tokenize(text)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(all_texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-drama",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        return x if isinstance(x, Tensor) else tokenize(x)\n",
    "        \n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-minority",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "tls = TfmdLists(tokenized, TransformersTokenizer(tokenizer), splits=splits, dl_type=LMDataLoader)\n",
    "dls = tls.dataloaders(bs=bs, seq_len=sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-forty",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-graph",
   "metadata": {},
   "source": [
    "Let's create our fastai `Learner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-region",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-tuner",
   "metadata": {},
   "source": [
    "And let's try to extend a given prompt with the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-morrison",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "prompt = \"\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-jurisdiction",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-puzzle",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "preds = learn.model.generate(inp, max_length=40, num_beams=5, temperature=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-grill",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn on its head.\\n\\nA unicorn is a magical creature with a rainbow tail and a horn'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-trust",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(#2) [3.695716619491577,40.2744255065918]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-lithuania",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.124115</td>\n",
       "      <td>2.844266</td>\n",
       "      <td>17.188944</td>\n",
       "      <td>07:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-biology",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn on its head. It is a member of the <unk> family of <unk>,'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]\n",
    "\n",
    "preds = learn.model.generate(inp.cuda(), max_length=40, num_beams=5, temperature=1.5)\n",
    "\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f721f63e",
   "metadata": {},
   "source": [
    "## Make it sparse !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff50c46",
   "metadata": {},
   "source": [
    "Let's see now if we retrain our model, this time introducing sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95371238",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436e6673",
   "metadata": {},
   "source": [
    "Also, when working with text, fastai defines the number of processed batches differently, so we have to adjust our `SparsifyCallback` accordingly (luckily, fastai makes it available as the `n_batches` attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6012c87",
   "metadata": {},
   "source": [
    "@patch_to(SparsifyCallback)     \n",
    "def before_fit(self):\n",
    "    print(f'Pruning of {self.granularity} until a sparsity of {self.end_sparsity}%')\n",
    "    self.end_epoch = self.n_epoch if self.end_epoch is None else self.end_epoch\n",
    "    assert self.end_epoch <= self.n_epoch, 'Your end_epoch must be smaller than total number of epoch'\n",
    "\n",
    "    model = self.learn.model if self.model is None else self.model # Pass a model if you don't want the whole model to be pruned\n",
    "    self.sparsifier = Sparsifier(model, self.granularity, self.method, self.criteria, self.layer_type)\n",
    "    self.total_iters = self.end_epoch * self.dls.n_batches\n",
    "    self.start_iter = self.start_epoch * self.dls.n_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909377e6",
   "metadata": {},
   "source": [
    "Let's define our `SparsifyCallback`. Let's say we want to make our model 30% sparse, by removing the highest-norm weight in each attention head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ae3d7",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "sp_cb = SparsifyCallback(sparsity=30, granularity='weight', context='local', criteria=large_final, schedule=one_cycle, layer_type=Conv1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b21be",
   "metadata": {},
   "source": [
    "We now only have to pass our callback to fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-breach",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning of weight until a sparsity of [30]%\n",
      "Saving Weights at epoch 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.049835</td>\n",
       "      <td>2.859973</td>\n",
       "      <td>17.461063</td>\n",
       "      <td>09:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity at the end of epoch 0: [30.0]%\n",
      "Final Sparsity: [30.0]%\n",
      "Sparsity in Conv1D 9: 30.00%\n",
      "Sparsity in Conv1D 10: 30.00%\n",
      "Sparsity in Conv1D 15: 30.00%\n",
      "Sparsity in Conv1D 16: 30.00%\n",
      "Sparsity in Conv1D 22: 30.00%\n",
      "Sparsity in Conv1D 23: 30.00%\n",
      "Sparsity in Conv1D 28: 30.00%\n",
      "Sparsity in Conv1D 29: 30.00%\n",
      "Sparsity in Conv1D 34: 30.00%\n",
      "Sparsity in Conv1D 35: 30.00%\n",
      "Sparsity in Conv1D 40: 30.00%\n",
      "Sparsity in Conv1D 41: 30.00%\n",
      "Sparsity in Conv1D 46: 30.00%\n",
      "Sparsity in Conv1D 47: 30.00%\n",
      "Sparsity in Conv1D 52: 30.00%\n",
      "Sparsity in Conv1D 53: 30.00%\n",
      "Sparsity in Conv1D 58: 30.00%\n",
      "Sparsity in Conv1D 59: 30.00%\n",
      "Sparsity in Conv1D 64: 30.00%\n",
      "Sparsity in Conv1D 65: 30.00%\n",
      "Sparsity in Conv1D 70: 30.00%\n",
      "Sparsity in Conv1D 71: 30.00%\n",
      "Sparsity in Conv1D 76: 30.00%\n",
      "Sparsity in Conv1D 77: 30.00%\n",
      "Sparsity in Conv1D 82: 30.00%\n",
      "Sparsity in Conv1D 83: 30.00%\n",
      "Sparsity in Conv1D 88: 30.00%\n",
      "Sparsity in Conv1D 89: 30.00%\n",
      "Sparsity in Conv1D 94: 30.00%\n",
      "Sparsity in Conv1D 95: 30.00%\n",
      "Sparsity in Conv1D 100: 30.00%\n",
      "Sparsity in Conv1D 101: 30.00%\n",
      "Sparsity in Conv1D 106: 30.00%\n",
      "Sparsity in Conv1D 107: 30.00%\n",
      "Sparsity in Conv1D 112: 30.00%\n",
      "Sparsity in Conv1D 113: 30.00%\n",
      "Sparsity in Conv1D 118: 30.00%\n",
      "Sparsity in Conv1D 119: 30.00%\n",
      "Sparsity in Conv1D 124: 30.00%\n",
      "Sparsity in Conv1D 125: 30.00%\n",
      "Sparsity in Conv1D 130: 30.00%\n",
      "Sparsity in Conv1D 131: 30.00%\n",
      "Sparsity in Conv1D 136: 30.00%\n",
      "Sparsity in Conv1D 137: 30.00%\n",
      "Sparsity in Conv1D 142: 30.00%\n",
      "Sparsity in Conv1D 143: 30.00%\n",
      "Sparsity in Conv1D 148: 30.00%\n",
      "Sparsity in Conv1D 149: 30.00%\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4, cbs=sp_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49b313",
   "metadata": {},
   "source": [
    "And we can check the predicion to the same prompt as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-attribute",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n = Unicorn = \\n \\n A unicorn is a magical creature with a rainbow tail and a horn @-@ like head. It is a member of the <unk> family of unicorns'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = tokenizer.encode(prompt)\n",
    "inp = tensor(prompt_ids)[None]\n",
    "\n",
    "preds = learn.model.generate(inp.cuda(), max_length=40, num_beams=5, temperature=1.5)\n",
    "\n",
    "tokenizer.decode(preds[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1c34e5",
   "metadata": {},
   "source": [
    "That's it ! You now have a sparse Transformer as performant as the whole model. However, this model is currently not more efficient speed and storage wise. To have such a speed-up, I suggest you to look at the [granularity](https://nathanhubens.github.io/fasterai/granularity.html) section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
