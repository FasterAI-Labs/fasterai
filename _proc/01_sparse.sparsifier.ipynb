{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Make your neural network sparse\n",
    "output-file: sparse.sparsifier.html\n",
    "title: Sparsifier\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from nbdev.showdoc import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sparse vector, as opposed to a dense one, is a vector which contains a lot of zeroes. When we speak about making a neural network sparse, we thus mean that the network's weight are mostly zeroes.\n",
    "\n",
    "With fasterai, you can do that thanks to the `Sparsifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Sparsifier\n",
       "\n",
       ">      Sparsifier (model, granularity, context, criteria, layer_type=<class\n",
       ">                  'torch.nn.modules.conv.Conv2d'>)\n",
       "\n",
       "Class providing sparsifying capabilities"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Sparsifier\n",
       "\n",
       ">      Sparsifier (model, granularity, context, criteria, layer_type=<class\n",
       ">                  'torch.nn.modules.conv.Conv2d'>)\n",
       "\n",
       "Class providing sparsifying capabilities"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Sparsifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Sparsifier` class allows us to remove some weights, that are considered to be less useful than others. This can be done by first creating an instance of the class, specifying:\n",
    "\n",
    "- The `granularity`, i.e. the part of filters that you want to remove. Typically, we usually remove weights, vectors, kernels or even complete filters.\n",
    "- The `context`, i.e. if you want to consider each layer independently (`local`), or compare the parameters to remove across the whole network (`global`).\n",
    "- The `criteria`, i.e. the way to assess the usefulness of a parameter. Common methods compare parameters using their magnitude, the lowest magnitude ones considered to be less useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User can pass a single layer to prune by using the  `Sparsifier.prune_layer` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Sparsifier.prune_layer\n",
       "\n",
       ">      Sparsifier.prune_layer (m, sparsity, round_to=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Sparsifier.prune_layer\n",
       "\n",
       ">      Sparsifier.prune_layer (m, sparsity, round_to=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Sparsifier.prune_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, we may want to prune the whole model at once, using the `Sparsifier.prune_model` method, indicating the percentage of sparsity to you want to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### Sparsifier.prune_model\n",
       "\n",
       ">      Sparsifier.prune_model (sparsity, round_to=None)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### Sparsifier.prune_model\n",
       "\n",
       ">      Sparsifier.prune_model (sparsity, round_to=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|output: asis\n",
    "#| echo: false\n",
    "show_doc(Sparsifier.prune_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some case, you may want to impose the remaining amount of parameters to be a multiple of a given number (e.g. 8), this can be done by passing the `round_to` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, instead of passing a single value of sparsity, a list of sparsities can also be provided. In that case, each value in the list is the sparsity that will be applied to all layers.\n",
    "\n",
    "**Example**: I have a 4-layer network and want to remove half of the parameters from the layers 2 and 3, I can provide the list: `sparsity = [0, 50, 50, 0]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
